{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_on_steroids_training_default_for_cpu_gpu_tpu_training (time)",
      "provenance": [],
      "mount_file_id": "1_CwhtDptSc2e5o2TW5nLkWaCxF_oM6i6",
      "authorship_tag": "ABX9TyM863meXLMjaYzuNLsHbFIS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanZter/BERT_framework/blob/master/BERT_on_steroids_training_default_for_cpu_gpu_tpu_training_(time).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W556H78Zy8FR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4ET5biCy9XX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "e5c9f992-745c-4650-9be8-1e49d271b74d"
      },
      "source": [
        "pip install torch===1.5.1 torchvision===0.6.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch===1.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/01/457b49d790b6c4b9720e6f9dbbb617692f6ce8afdaadf425c055c41a7416/torch-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (753.2MB)\n",
            "\u001b[K     |████████████████████████████████| 753.2MB 20kB/s \n",
            "\u001b[?25hCollecting torchvision===0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/f1/535a407b4a265adf2dd7c2c2458217e37c5fe83ec97234e66c564592a9a0/torchvision-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 33.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch===1.5.1) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch===1.5.1) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision===0.6.1) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Successfully installed torch-1.5.1 torchvision-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQUfaPGwy9sE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98e18542-8087-4c96-ccb7-659ac0acb969"
      },
      "source": [
        "VERSION = \"1.5\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4139  100  4139    0     0  53064      0 --:--:-- --:--:-- --:--:-- 53753\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-1.5 ...\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "Uninstalling torch-1.5.1:\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████▍   | 51kB 3.4MB/s eta 0:00:01  Successfully uninstalled torch-1.5.1\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (1.12.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (4.6)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.3)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (47.3.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.1.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.52.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.9)\n",
            "\u001b[31mERROR: Error checking for conflicts.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3012, in _parsed_pkg_info\n",
            "    return self._pkg_info\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _pkg_info\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py\", line 568, in _warn_about_conflicts\n",
            "    package_set, _dep_info = check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/operations/check.py\", line 114, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/operations/check.py\", line 53, in create_package_set_from_installed\n",
            "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3032, in _compute_dependencies\n",
            "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3014, in _parsed_pkg_info\n",
            "    metadata = self.get_metadata(self.PKG_INFO)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 1420, in get_metadata\n",
            "    value = self._get(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 1616, in _get\n",
            "    with open(path, 'rb') as stream:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/usr/local/lib/python3.6/dist-packages/torch-1.5.1.dist-info/METADATA'\u001b[0m\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Found existing installation: google-api-python-client 1.7.12\n",
            "    Uninstalling google-api-python-client-1.7.12:\n",
            "      Successfully uninstalled google-api-python-client-1.7.12\n",
            "Uninstalling torchvision-0.6.1:\n",
            "  Successfully uninstalled torchvision-0.6.1\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "Copying gs://tpu-pytorch/wheels/torch-1.5-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 79.0 MiB/ 79.0 MiB]                                                \n",
            "Operation completed over 1 objects/79.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-1.5-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][106.6 MiB/106.6 MiB]                                                \n",
            "Operation completed over 1 objects/106.6 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-1.5-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.5 MiB/  2.5 MiB]                                                \n",
            "Operation completed over 1 objects/2.5 MiB.                                      \n",
            "Processing ./torch-1.5-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (1.18.5)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.5.0a0+ab660ae\n",
            "Processing ./torch_xla-1.5-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Done updating TPU runtime\n",
            "Successfully installed torch-xla-1.5\n",
            "Processing ./torchvision-1.5-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (1.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (1.5.0a0+ab660ae)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==1.5) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.6.0a0+3c254fb\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (325 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okaexjJuy9pT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports pytorch\n",
        "import torch\n",
        "\n",
        "# imports the torch_xla package\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DcVfJzGy9mu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "d069aee7-1aee-4514-83df-5e9c8f1d00c5"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0\n",
            "Running on TPU  ['10.68.239.138:8470']\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JCT1_lPy9jt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "3c49f438-7012-4e44-93de-6ae80d8d2698"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 3.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 21.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 21.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 32.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=2ffe1b497098144a3e7851c850b7d74fd557eb2ea8069b4f9db50483be3fe644\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSuPBETpy9hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch.nn as nn\n",
        "from sklearn import model_selection\n",
        "from scipy import stats\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3pmpNNiy2se",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cad1e488-7d33-4f47-c43e-94745c7fdfdd"
      },
      "source": [
        "class BERTBaseUncased(nn.Module):\n",
        "    def __init__(self, bert_path):\n",
        "        super(BERTBaseUncased, self).__init__()\n",
        "        self.bert_path = bert_path\n",
        "        self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n",
        "        self.bert_drop = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(768, 30)       # pool output has 768 features, 30 targets\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, o2 = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)  # not using o1 - Sequential Output\n",
        "        bo = self.bert_drop(o2)                                                     # using o2 - Pooled Output\n",
        "        return self.out(bo)\n",
        "\n",
        "class BERTDatasetTraining:\n",
        "    def __init__(self, qtitle, qbody, answer, targets, tokenizer, max_len):\n",
        "        self.qtitle = qtitle\n",
        "        self.qbody = qbody\n",
        "        self.answer = answer\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.targets = targets                   # numpy array of size: no. of samples * 30(targets)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.answer)                  # returns length of title or body or answer\n",
        "\n",
        "    def __getitem__(self, item):                 # takes in index and returns output\n",
        "        question_title = str(self.qtitle[item])\n",
        "        question_body = str(self.qbody[item])\n",
        "        answer = str(self.answer[item])\n",
        "\n",
        "        # [CLS] [Q-TITLE] [Q-BODY] [SEP] [ANSWER] [SEP]\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            question_title + \" \" + question_body,\n",
        "            answer,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "\n",
        "        padding_len = self.max_len - len(ids)\n",
        "        ids = ids + ([0] * padding_len)\n",
        "        token_type_ids = token_type_ids + ([0] * padding_len)\n",
        "        mask = mask + ([0] * padding_len)\n",
        "\n",
        "        return {\n",
        "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
        "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
        "            \"targets\": torch.tensor(self.targets[item, :], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "def loss_fn(outputs, targets):\n",
        "    return nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "def train_loop_fn(data_loader, model, optimizer, device, scheduler=None):\n",
        "    model.train()\n",
        "    for bi, d in enumerate(data_loader):\n",
        "        ids = d[\"ids\"]\n",
        "        mask = d[\"mask\"]\n",
        "        token_type_ids = d[\"token_type_ids\"]\n",
        "        targets = d[\"targets\"]\n",
        "\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        # optimizer.step()                                         # cuda or tpu\n",
        "        xm.optimizer_step(optimizer, barrier=True)                 # tpu\n",
        "        # print(f\"batch index {bi}, loss={loss}\")\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        if bi== 0:\n",
        "            print(f\"starting_batch_index={bi}, loss={loss}\")\n",
        "    print(f\"ending_batch_idex={bi}, loss={loss}\")\n",
        "\n",
        "def eval_loop_fn(data_loader, model, optimizer, device):\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    for bi, d in enumerate(data_loader):\n",
        "        ids = d[\"ids\"]\n",
        "        mask = d[\"mask\"]\n",
        "        token_type_ids = d[\"token_type_ids\"]\n",
        "        targets = d[\"targets\"]\n",
        "\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "        outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        fin_targets.append(targets.cpu().detach().numpy())\n",
        "        fin_outputs.append(outputs.cpu().detach().numpy())        # Linear Layer: can apply sigmoid here\n",
        "\n",
        "        return np.vstack(fin_outputs), np.vstack(fin_targets)\n",
        "\n",
        "def run():\n",
        "    MAX_LEN = 512\n",
        "    TRAIN_BATCH_SIZE = 4\n",
        "    EPOCHS = 20\n",
        "\n",
        "    dfx = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/input/google_quest_train.csv\").fillna(\"none\")\n",
        "    df_train, df_valid = model_selection.train_test_split(dfx, random_state = 42, test_size = 0.1)\n",
        "    df_train = df_train.reset_index(drop=True)\n",
        "    df_valid = df_valid.reset_index(drop=True)\n",
        "\n",
        "    sample = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/input/google_quest_sample_submission.csv\")\n",
        "    target_cols = list(sample.drop(\"qa_id\", axis=1).columns)\n",
        "    train_targets = df_train[target_cols].values\n",
        "    valid_targets = df_valid[target_cols].values\n",
        "\n",
        "    tokenizer =transformers.BertTokenizer.from_pretrained(\"/content/drive/My Drive/Colab Notebooks/input/bert_base_uncased\")\n",
        "\n",
        "    train_dataset = BERTDatasetTraining(\n",
        "        qtitle=df_train.question_title.values,\n",
        "        qbody=df_train.question_body.values,\n",
        "        answer=df_train.answer.values,\n",
        "        targets=train_targets,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=MAX_LEN\n",
        "    )\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "          train_dataset,\n",
        "          batch_size= TRAIN_BATCH_SIZE,\n",
        "          shuffle=True\n",
        "        )\n",
        "        ############\n",
        "    valid_dataset = BERTDatasetTraining(\n",
        "        qtitle=df_valid.question_title.values,\n",
        "        qbody=df_valid.question_body.values,\n",
        "        answer=df_valid.answer.values,\n",
        "        targets=valid_targets,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=MAX_LEN\n",
        "    )\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=4,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    # device = \"cuda\"                   # cuda or cpu\n",
        "    device = xm.xla_device()            # tpu\n",
        "    lr = 3e-5\n",
        "    num_train_steps = int(len(train_dataset)/ TRAIN_BATCH_SIZE * EPOCHS)\n",
        "    model = BERTBaseUncased(\"/content/drive/My Drive/Colab Notebooks/input/bert_base_uncased\").to(device)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_train_steps\n",
        "    )\n",
        "    for epoch in tqdm(range(EPOCHS), total=EPOCHS):\n",
        "        print(\"X\"*20, \"EPOCH :\", epoch, \"X\"*100)\n",
        "        train_loop_fn(train_data_loader, model, optimizer, device, scheduler)\n",
        "        o, t = eval_loop_fn(valid_data_loader, model, optimizer, device)\n",
        "\n",
        "        spear = []\n",
        "        for jj in range(t.shape[1]):\n",
        "            p1 = list(t[:,jj])\n",
        "            p2 = list(o[:, jj])\n",
        "            coef, _ = np.nan_to_num(stats.spearmanr(p1,p2))\n",
        "            spear.append(coef)\n",
        "        spear = np.mean(spear)\n",
        "        print(f\"epoch = {epoch}, spearman = {spear}\")\n",
        "        # xm.save(model.state_dict(), \"model.bin\")            # TPU\n",
        "        # torch.save(model.state_dict(), \"model.bin\")          # cuda or cpu\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    run()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 0 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.7391597032546997\n",
            "ending_batch_idex=1367, loss=0.3135463297367096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 1/20 [05:11<1:38:42, 311.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch = 0, spearman = 0.1238692377329464\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 1 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.43637391924858093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 2/20 [09:51<1:30:36, 302.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.33762165904045105\n",
            "epoch = 1, spearman = 0.14170042525710033\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 2 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.3936406373977661\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 3/20 [14:30<1:23:36, 295.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.3559664487838745\n",
            "epoch = 2, spearman = 0.26556966299004675\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 3 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.3111087381839752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 4/20 [19:11<1:17:34, 290.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.4267962574958801\n",
            "epoch = 3, spearman = -0.02581988897471611\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 4 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.23747345805168152\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 5/20 [23:51<1:11:56, 287.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.22838419675827026\n",
            "epoch = 4, spearman = 0.17950336640765968\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 5 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.22407206892967224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 6/20 [28:32<1:06:38, 285.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.17958815395832062\n",
            "epoch = 5, spearman = 0.21854216397357215\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 6 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.1207055151462555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 7/20 [33:17<1:01:50, 285.42s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.29840415716171265\n",
            "epoch = 6, spearman = 0.11357439681590543\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 7 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.18746612966060638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 8/20 [38:02<57:04, 285.36s/it]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.18763673305511475\n",
            "epoch = 7, spearman = 0.170896736749421\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 8 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.14173798263072968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 9/20 [42:45<52:12, 284.80s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.17465560138225555\n",
            "epoch = 8, spearman = 0.07284738799119071\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 9 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.1296982616186142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 10/20 [47:31<47:30, 285.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.18339784443378448\n",
            "epoch = 9, spearman = 0.16752031423181643\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 10 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.11637244373559952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 11/20 [52:19<42:53, 285.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.10772585868835449\n",
            "epoch = 10, spearman = 0.22023037523237443\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 11 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.09184698015451431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 12/20 [57:07<38:13, 286.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.08895429223775864\n",
            "epoch = 11, spearman = 0.13309379559886164\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 12 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.06565026938915253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 13/20 [1:01:52<33:22, 286.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.11649774014949799\n",
            "epoch = 12, spearman = 0.21392988504061453\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 13 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.16848434507846832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 14/20 [1:06:33<28:27, 284.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.07568873465061188\n",
            "epoch = 13, spearman = 0.26219324047244214\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 14 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.05169200524687767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 15/20 [1:11:17<23:41, 284.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.038264840841293335\n",
            "epoch = 14, spearman = 0.18642178480709612\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 15 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.13121023774147034\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 16/20 [1:15:56<18:51, 282.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.0789160430431366\n",
            "epoch = 15, spearman = 0.007988701450562156\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 16 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.11278215795755386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 17/20 [1:20:37<14:06, 282.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.0892123132944107\n",
            "epoch = 16, spearman = 0.1858038565994196\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 17 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.05772551894187927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 18/20 [1:25:19<09:23, 281.99s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.07463228702545166\n",
            "epoch = 17, spearman = 0.20993553431533343\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 18 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.057259779423475266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 19/20 [1:30:02<04:42, 282.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.04366913065314293\n",
            "epoch = 18, spearman = 0.07515352745766953\n",
            "XXXXXXXXXXXXXXXXXXXX EPOCH : 19 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "starting_batch_index=0, loss=0.022761182859539986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [1:35:08<00:00, 285.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ending_batch_idex=1367, loss=0.03885024040937424\n",
            "epoch = 19, spearman = 0.18012129461533624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}