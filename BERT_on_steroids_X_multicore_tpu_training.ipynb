{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_on_steroids X multicore_tpu_training",
      "provenance": [],
      "mount_file_id": "1TLYWfi3AjfQ5zJECU5ig2HiKKR5MtJpt",
      "authorship_tag": "ABX9TyN6N+ORsj2mKg+QRqOb0crL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanZter/BERT_framework/blob/master/BERT_on_steroids_X_multicore_tpu_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyG9T5pIE-V9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhKmNQeffvJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "6c3bc69f-a888-48c2-dc84-e5b06ae3fcc5"
      },
      "source": [
        "pip install torch===1.5.1 torchvision===0.6.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch===1.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/01/457b49d790b6c4b9720e6f9dbbb617692f6ce8afdaadf425c055c41a7416/torch-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (753.2MB)\n",
            "\u001b[K     |████████████████████████████████| 753.2MB 23kB/s \n",
            "\u001b[?25hCollecting torchvision===0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/f1/535a407b4a265adf2dd7c2c2458217e37c5fe83ec97234e66c564592a9a0/torchvision-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch===1.5.1) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch===1.5.1) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision===0.6.1) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Successfully installed torch-1.5.1 torchvision-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-2vw7hhFKPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c2991c2-e124-40d0-d162-54d4622594ce"
      },
      "source": [
        "VERSION = \"1.5\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4139  100  4139    0     0  67852      0 --:--:-- --:--:-- --:--:-- 67852\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-1.5 ...\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Uninstalling torch-1.5.1:\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "  Successfully uninstalled torch-1.5.1\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (4.6)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (1.12.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.17.2)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.1.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (47.3.1)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.10.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.52.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.9)\n",
            "Uninstalling torchvision-0.6.1:\n",
            "  Successfully uninstalled torchvision-0.6.1\n",
            "\u001b[31mERROR: Error checking for conflicts.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3012, in _parsed_pkg_info\n",
            "    return self._pkg_info\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _pkg_info\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py\", line 568, in _warn_about_conflicts\n",
            "    package_set, _dep_info = check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/operations/check.py\", line 114, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/operations/check.py\", line 53, in create_package_set_from_installed\n",
            "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3032, in _compute_dependencies\n",
            "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3014, in _parsed_pkg_info\n",
            "    metadata = self.get_metadata(self.PKG_INFO)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 1420, in get_metadata\n",
            "    value = self._get(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 1616, in _get\n",
            "    with open(path, 'rb') as stream:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/usr/local/lib/python3.6/dist-packages/torchvision-0.6.1.dist-info/METADATA'\u001b[0m\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Found existing installation: google-api-python-client 1.7.12\n",
            "    Uninstalling google-api-python-client-1.7.12:\n",
            "      Successfully uninstalled google-api-python-client-1.7.12\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "Copying gs://tpu-pytorch/wheels/torch-1.5-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 79.0 MiB/ 79.0 MiB]                                                \n",
            "Operation completed over 1 objects/79.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-1.5-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][106.6 MiB/106.6 MiB]                                                \n",
            "Operation completed over 1 objects/106.6 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-1.5-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.5 MiB/  2.5 MiB]                                                \n",
            "Operation completed over 1 objects/2.5 MiB.                                      \n",
            "Processing ./torch-1.5-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (0.16.0)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.5.0a0+ab660ae\n",
            "Processing ./torch_xla-1.5-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.5\n",
            "Processing ./torchvision-1.5-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (1.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (1.5.0a0+ab660ae)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==1.5) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.6.0a0+3c254fb\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Done updating TPU runtime\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (317 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnbbdbVsgW_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports pytorch\n",
        "import torch\n",
        "\n",
        "# imports the torch_xla package\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.distributed.parallel_loader as pl"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFP3k-CzZh-D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "05a38e3f-04b8-41c3-93a9-400b91d41285"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0\n",
            "Running on TPU  ['10.15.135.82:8470']\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6luKMbH_DQqN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "b73818b9-a236-4625-ae58-8a14a624a98e"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 15.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 22.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 32.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=f1352f6121064c447dc54f8ce5565ef81f603eca857254e0996a3bea0128184e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxDvwe7RDVka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip uninstall torchvision-nightly-cp36-cp36m-linux_x86_64.whl -y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7odoZNVDKvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch.nn as nn\n",
        "from sklearn import model_selection\n",
        "from scipy import stats\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# import logging\n",
        "# logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUS9aBCQ8wEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ee10aa3-e4dc-4e25-ce8f-d099c399ed8a"
      },
      "source": [
        "class BERTBaseUncased(nn.Module):\n",
        "    def __init__(self, bert_path):\n",
        "        super(BERTBaseUncased, self).__init__()\n",
        "        self.bert_path = bert_path\n",
        "        self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n",
        "        self.bert_drop = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(768, 30)       # pool output has 768 features, 30 targets\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, o2 = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)  # not using o1 - Sequential Output\n",
        "        bo = self.bert_drop(o2)                                                     # using o2 - Pooled Output\n",
        "        return self.out(bo)\n",
        "\n",
        "class BERTDatasetTraining:\n",
        "    def __init__(self, qtitle, qbody, answer, targets, tokenizer, max_len):\n",
        "        self.qtitle = qtitle\n",
        "        self.qbody = qbody\n",
        "        self.answer = answer\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.targets = targets                   # numpy array of size: no. of samples * 30(targets)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.answer)                  # returns length of title or body or answer\n",
        "\n",
        "    def __getitem__(self, item):                 # takes in index and returns output\n",
        "        question_title = str(self.qtitle[item])\n",
        "        question_body = str(self.qbody[item])\n",
        "        answer = str(self.answer[item])\n",
        "\n",
        "        # [CLS] [Q-TITLE] [Q-BODY] [SEP] [ANSWER] [SEP]\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            question_title + \" \" + question_body,\n",
        "            answer,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True \n",
        "        )\n",
        "\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "\n",
        "        padding_len = self.max_len - len(ids)\n",
        "        ids = ids + ([0] * padding_len)\n",
        "        token_type_ids = token_type_ids + ([0] * padding_len)\n",
        "        mask = mask + ([0] * padding_len)\n",
        "\n",
        "        return {\n",
        "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
        "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
        "            \"targets\": torch.tensor(self.targets[item, :], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "def loss_fn(outputs, targets):\n",
        "    return nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "def train_loop_fn(data_loader, model, optimizer, device, scheduler=None):\n",
        "    model.train()\n",
        "    for bi, d in enumerate(data_loader):\n",
        "        ids = d[\"ids\"]\n",
        "        mask = d[\"mask\"]\n",
        "        token_type_ids = d[\"token_type_ids\"]\n",
        "        targets = d[\"targets\"]\n",
        "\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        # optimizer.step()                                         # cuda\n",
        "        xm.optimizer_step(optimizer)                              # tpu\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        if bi % 10 == 0:\n",
        "            print(f\"bi={bi}, loss={loss}\")\n",
        "\n",
        "def eval_loop_fn(data_loader, model, device):\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    for bi, d in enumerate(data_loader):\n",
        "        ids = d[\"ids\"]\n",
        "        mask = d[\"mask\"]\n",
        "        token_type_ids = d[\"token_type_ids\"]\n",
        "        targets = d[\"targets\"]\n",
        "\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "        outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        fin_targets.append(targets.cpu().detach().numpy())\n",
        "        fin_outputs.append(outputs.cpu().detach().numpy())        # Linear Layer: can apply sigmoid here\n",
        "\n",
        "        return np.vstack(fin_outputs), np.vstack(fin_targets)\n",
        "\n",
        "def run(index, flags):\n",
        "\n",
        "    # MAX_LEN = 512\n",
        "    # TRAIN_BATCH_SIZE = 4\n",
        "    # EPOCHS = 20\n",
        "\n",
        "    flags['TRAIN_BATCH_SIZE'] = 4\n",
        "    flags['TEST_BATCH_SIZE'] = 4\n",
        "    flags['MAX_LEN'] = 512\n",
        "    flags['EPOCHS'] = 20\n",
        "    flags['seed'] = 1234  \n",
        "    torch.manual_seed(flags['seed'])\n",
        "\n",
        "    dfx = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/input/google_quest_train.csv\").fillna(\"none\")\n",
        "    df_train, df_valid = model_selection.train_test_split(dfx, random_state = 42, test_size = 0.1)\n",
        "    df_train = df_train.reset_index(drop=True)\n",
        "    df_valid = df_valid.reset_index(drop=True)\n",
        "\n",
        "    sample = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/input/google_quest_sample_submission.csv\")\n",
        "    target_cols = list(sample.drop(\"qa_id\", axis=1).columns)\n",
        "    train_targets = df_train[target_cols].values\n",
        "    valid_targets = df_valid[target_cols].values\n",
        "\n",
        "    tokenizer =transformers.BertTokenizer.from_pretrained(\"/content/drive/My Drive/Colab Notebooks/input/bert_base_uncased\")\n",
        "\n",
        "    train_dataset = BERTDatasetTraining(\n",
        "        qtitle=df_train.question_title.values,\n",
        "        qbody=df_train.question_body.values,\n",
        "        answer=df_train.answer.values,\n",
        "        targets=train_targets,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=flags['MAX_LEN']\n",
        "    )\n",
        "    train_sampler = torch.utils.data.DistributedSampler(\n",
        "       train_dataset,\n",
        "       num_replicas=xm.xrt_world_size(),\n",
        "       rank=xm.get_ordinal(),\n",
        "       shuffle=True \n",
        "    )\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size= flags['TRAIN_BATCH_SIZE'],\n",
        "        sampler=train_sampler\n",
        "    )\n",
        "    ############\n",
        "    valid_dataset = BERTDatasetTraining(\n",
        "        qtitle=df_valid.question_title.values,\n",
        "        qbody=df_valid.question_body.values,\n",
        "        answer=df_valid.answer.values,\n",
        "        targets=valid_targets,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=flags['MAX_LEN']\n",
        "    )\n",
        "    valid_sampler = torch.utils.data.DistributedSampler(\n",
        "       valid_dataset,\n",
        "       num_replicas=xm.xrt_world_size(),\n",
        "       rank=xm.get_ordinal()\n",
        "    )\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=flags['TEST_BATCH_SIZE'],\n",
        "        sampler=valid_sampler\n",
        "    )\n",
        "\n",
        "    # device = \"cuda\"                   # cuda\n",
        "    device = xm.xla_device()            # tpu\n",
        "    lr = 3e-5 *xm.xrt_world_size()\n",
        "    num_train_steps = int(len(train_dataset)/ flags['TRAIN_BATCH_SIZE'] / xm.xrt_world_size() * flags['EPOCHS'])\n",
        "    model = BERTBaseUncased(\"/content/drive/My Drive/Colab Notebooks/input/bert_base_uncased\").to(device)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_train_steps\n",
        "    )\n",
        "    for epoch in range(flags['EPOCHS']):\n",
        "      para_loader = pl.ParallelLoader(train_data_loader, [device])\n",
        "      train_loop_fn(para_loader.per_device_loader(device), model, optimizer, device, scheduler)\n",
        "\n",
        "      para_loader = pl.ParallelLoader(valid_data_loader, [device])\n",
        "      o, t = eval_loop_fn(para_loader.per_device_loader(device), model, device)\n",
        "\n",
        "      spear = []\n",
        "      for jj in range(t.shape[1]):\n",
        "          p1 = list(t[:,jj])\n",
        "          p2 = list(o[:, jj])\n",
        "          coef, _ = np.nan_to_num(stats.spearmanr(p1,p2))\n",
        "          spear.append(coef)\n",
        "      spear = np.mean(spear)\n",
        "      print(f\"epoch = {epoch}, spearman = {spear}\")\n",
        "      # torch.save(model.state_dict(), \"model.bin\")         # cuda\n",
        "      # xm.save(model.state_dict(), \"model.bin\")          # tpu\n",
        "\n",
        "# if __name__==\"__main__\":\n",
        "#   xmp.spawn(run, nprocs=1)\n",
        "\n",
        "# # Spawns eight of the map functions, one for each of the eight cores on\n",
        "# # the Cloud TPU\n",
        "# flags = {}\n",
        "# # Note: Colab only supports start_method='fork'\n",
        "# xmp.spawn(run, args=(flags,), nprocs=1, start_method='fork')\n",
        "\n",
        "# # xmp.spawn(run, args=(), start_method='fork', nprocs=1)\n",
        "flags = {}\n",
        "xmp.spawn(run, args=(flags,), nprocs=8, start_method='fork')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bi=0, loss=0.7525567412376404\n",
            "bi=0, loss=0.7461388111114502\n",
            "bi=0, loss=0.8078871965408325\n",
            "bi=0, loss=0.7887917757034302\n",
            "bi=0, loss=0.7751476168632507\n",
            "bi=0, loss=0.752004086971283\n",
            "bi=0, loss=0.7817627787590027\n",
            "bi=0, loss=0.7815744280815125\n",
            "bi=10, loss=0.5041784644126892\n",
            "bi=10, loss=0.3669978678226471\n",
            "bi=10, loss=0.3658598065376282\n",
            "bi=10, loss=0.45700758695602417\n",
            "bi=10, loss=0.4400368332862854\n",
            "bi=10, loss=0.40068110823631287\n",
            "bi=10, loss=0.4434146285057068\n",
            "bi=10, loss=0.3725464940071106\n",
            "bi=20, loss=0.3287964165210724\n",
            "bi=20, loss=0.41121095418930054\n",
            "bi=20, loss=0.28016239404678345\n",
            "bi=20, loss=0.33210667967796326\n",
            "bi=20, loss=0.38915687799453735\n",
            "bi=20, loss=0.3130435049533844\n",
            "bi=20, loss=0.4513082504272461\n",
            "bi=20, loss=0.4878334403038025\n",
            "bi=30, loss=0.4104171395301819\n",
            "bi=30, loss=0.33002346754074097\n",
            "bi=30, loss=0.3433081805706024\n",
            "bi=30, loss=0.3132987320423126\n",
            "bi=30, loss=0.41064614057540894\n",
            "bi=30, loss=0.5645810961723328\n",
            "bi=30, loss=0.2972920536994934\n",
            "bi=30, loss=0.3348168730735779\n",
            "bi=40, loss=0.330112099647522\n",
            "bi=40, loss=0.5345263481140137\n",
            "bi=40, loss=0.3503173887729645\n",
            "bi=40, loss=0.3462386727333069\n",
            "bi=40, loss=0.3931807279586792\n",
            "bi=40, loss=0.41285666823387146\n",
            "bi=40, loss=0.34535250067710876\n",
            "bi=40, loss=0.381137490272522\n",
            "bi=50, loss=0.5562384724617004\n",
            "bi=50, loss=0.3128095269203186\n",
            "bi=50, loss=0.3279934227466583\n",
            "bi=50, loss=0.4198995530605316\n",
            "bi=50, loss=0.40267157554626465\n",
            "bi=50, loss=0.34941598773002625\n",
            "bi=50, loss=0.3351764976978302\n",
            "bi=50, loss=0.36524710059165955\n",
            "bi=60, loss=0.38384711742401123\n",
            "bi=60, loss=0.3387608826160431\n",
            "bi=60, loss=0.36053457856178284\n",
            "bi=60, loss=0.3108060359954834\n",
            "bi=60, loss=0.33318260312080383\n",
            "bi=60, loss=0.2897454500198364\n",
            "bi=60, loss=0.40923306345939636\n",
            "bi=60, loss=0.2955900728702545\n",
            "bi=70, loss=0.3541529178619385\n",
            "bi=70, loss=0.39842674136161804\n",
            "bi=70, loss=0.34593310952186584\n",
            "bi=70, loss=0.3299766480922699\n",
            "bi=70, loss=0.3818645179271698\n",
            "bi=70, loss=0.3533070683479309\n",
            "bi=70, loss=0.28430354595184326\n",
            "bi=70, loss=0.46566540002822876\n",
            "bi=80, loss=0.28780990839004517\n",
            "bi=80, loss=0.37521758675575256\n",
            "bi=80, loss=0.27442726492881775\n",
            "bi=80, loss=0.3541894257068634\n",
            "bi=80, loss=0.32191750407218933\n",
            "bi=80, loss=0.29887810349464417\n",
            "bi=80, loss=0.33644357323646545\n",
            "bi=80, loss=0.33456850051879883\n",
            "bi=90, loss=0.3063598871231079\n",
            "bi=90, loss=0.3472786843776703\n",
            "bi=90, loss=0.3868137001991272\n",
            "bi=90, loss=0.47216132283210754\n",
            "bi=90, loss=0.36596542596817017\n",
            "bi=90, loss=0.34554630517959595\n",
            "bi=90, loss=0.2860608398914337\n",
            "bi=90, loss=0.3982383608818054\n",
            "bi=100, loss=0.304386168718338\n",
            "bi=100, loss=0.3426421582698822\n",
            "bi=100, loss=0.2735704481601715\n",
            "bi=100, loss=0.31560251116752625\n",
            "bi=100, loss=0.3115746080875397\n",
            "bi=100, loss=0.3410489559173584\n",
            "bi=100, loss=0.2706855535507202\n",
            "bi=100, loss=0.31241485476493835\n",
            "bi=110, loss=0.3295995891094208\n",
            "bi=110, loss=0.30727508664131165\n",
            "bi=110, loss=0.2843039631843567\n",
            "bi=110, loss=0.3042375147342682\n",
            "bi=110, loss=0.3175511062145233\n",
            "bi=110, loss=0.34265586733818054\n",
            "bi=110, loss=0.369051456451416\n",
            "bi=110, loss=0.3832484185695648\n",
            "bi=120, loss=0.403239369392395\n",
            "bi=120, loss=0.37663039565086365\n",
            "bi=120, loss=0.2952386438846588\n",
            "bi=120, loss=0.3044174611568451\n",
            "bi=120, loss=0.2622143626213074\n",
            "bi=120, loss=0.3888107240200043\n",
            "bi=120, loss=0.3313106894493103\n",
            "bi=120, loss=0.4688016474246979\n",
            "bi=130, loss=0.29691144824028015\n",
            "bi=130, loss=0.37806761264801025\n",
            "bi=130, loss=0.4364573061466217\n",
            "bi=130, loss=0.40347176790237427\n",
            "bi=130, loss=0.27860042452812195\n",
            "bi=130, loss=0.47423839569091797\n",
            "bi=130, loss=0.47954854369163513\n",
            "bi=130, loss=0.28680816292762756\n",
            "bi=140, loss=0.3197929263114929\n",
            "bi=140, loss=0.32003456354141235\n",
            "bi=140, loss=0.31840240955352783\n",
            "bi=140, loss=0.29725179076194763\n",
            "bi=140, loss=0.43270164728164673\n",
            "bi=140, loss=0.32450219988822937\n",
            "bi=140, loss=0.420418918132782\n",
            "bi=140, loss=0.3721988797187805\n",
            "bi=150, loss=0.326338529586792\n",
            "bi=150, loss=0.4246855080127716\n",
            "bi=150, loss=0.24260884523391724\n",
            "bi=150, loss=0.3873864412307739\n",
            "bi=150, loss=0.27040860056877136\n",
            "bi=150, loss=0.3597760796546936\n",
            "bi=150, loss=0.35297712683677673\n",
            "bi=150, loss=0.3473115563392639\n",
            "bi=160, loss=0.35853543877601624\n",
            "bi=160, loss=0.35004764795303345\n",
            "bi=160, loss=0.36925363540649414\n",
            "bi=160, loss=0.30644774436950684\n",
            "bi=160, loss=0.35307806730270386\n",
            "bi=160, loss=0.3880680203437805\n",
            "bi=160, loss=0.34404075145721436\n",
            "bi=160, loss=0.34175238013267517\n",
            "bi=170, loss=0.42339351773262024\n",
            "bi=170, loss=0.37729883193969727\n",
            "bi=170, loss=0.35329470038414\n",
            "bi=170, loss=0.2849765419960022\n",
            "bi=170, loss=0.3108764886856079\n",
            "bi=170, loss=0.33694085478782654\n",
            "bi=170, loss=0.4514071047306061\n",
            "bi=170, loss=0.3808256983757019\n",
            "epoch = 0, spearman = -0.025819888974716106\n",
            "epoch = 0, spearman = 0.04241522008351698\n",
            "epoch = 0, spearman = 0.15491933384829668\n",
            "epoch = 0, spearman = 0.20824732305653118\n",
            "epoch = 0, spearman = 0.04072700882471471\n",
            "epoch = 0, spearman = 0.04595721596534887\n",
            "epoch = 0, spearman = -0.055634128674713304\n",
            "epoch = 0, spearman = -0.07745966692414832\n",
            "bi=0, loss=0.3111920952796936\n",
            "bi=0, loss=0.3554002046585083\n",
            "bi=0, loss=0.2720578908920288\n",
            "bi=0, loss=0.3209587037563324\n",
            "bi=0, loss=0.3217022716999054\n",
            "bi=0, loss=0.27584537863731384\n",
            "bi=0, loss=0.3414178192615509\n",
            "bi=0, loss=0.36453965306282043\n",
            "bi=10, loss=0.36980605125427246\n",
            "bi=10, loss=0.42512431740760803\n",
            "bi=10, loss=0.29564738273620605\n",
            "bi=10, loss=0.3691355288028717\n",
            "bi=10, loss=0.27493545413017273\n",
            "bi=10, loss=0.338321328163147\n",
            "bi=10, loss=0.4773656129837036\n",
            "bi=10, loss=0.2932414710521698\n",
            "bi=20, loss=0.38361597061157227\n",
            "bi=20, loss=0.47153884172439575\n",
            "bi=20, loss=0.2867788076400757\n",
            "bi=20, loss=0.3944246768951416\n",
            "bi=20, loss=0.2803517282009125\n",
            "bi=20, loss=0.3398217260837555\n",
            "bi=20, loss=0.26077181100845337\n",
            "bi=20, loss=0.31403034925460815\n",
            "bi=30, loss=0.5620641708374023\n",
            "bi=30, loss=0.3181343674659729\n",
            "bi=30, loss=0.3729249835014343\n",
            "bi=30, loss=0.3114887773990631\n",
            "bi=30, loss=0.2908617854118347\n",
            "bi=30, loss=0.36863550543785095\n",
            "bi=30, loss=0.3239598870277405\n",
            "bi=30, loss=0.2603384256362915\n",
            "bi=40, loss=0.2945510149002075\n",
            "bi=40, loss=0.39160677790641785\n",
            "bi=40, loss=0.34182339906692505\n",
            "bi=40, loss=0.3500519096851349\n",
            "bi=40, loss=0.3452270030975342\n",
            "bi=40, loss=0.4990002512931824\n",
            "bi=40, loss=0.28219619393348694\n",
            "bi=40, loss=0.3768451511859894\n",
            "bi=50, loss=0.3649108409881592\n",
            "bi=50, loss=0.3950919210910797\n",
            "bi=50, loss=0.31269150972366333\n",
            "bi=50, loss=0.3213731646537781\n",
            "bi=50, loss=0.3596354126930237\n",
            "bi=50, loss=0.5291325449943542\n",
            "bi=50, loss=0.2949761152267456\n",
            "bi=50, loss=0.3423212468624115\n",
            "bi=60, loss=0.3904944062232971\n",
            "bi=60, loss=0.3026565909385681\n",
            "bi=60, loss=0.26239654421806335\n",
            "bi=60, loss=0.2603525221347809\n",
            "bi=60, loss=0.3387962281703949\n",
            "bi=60, loss=0.3747129738330841\n",
            "bi=60, loss=0.3780161738395691\n",
            "bi=60, loss=0.27800559997558594\n",
            "bi=70, loss=0.28658586740493774\n",
            "bi=70, loss=0.39044249057769775\n",
            "bi=70, loss=0.32522183656692505\n",
            "bi=70, loss=0.369831919670105\n",
            "bi=70, loss=0.3138457238674164\n",
            "bi=70, loss=0.46987026929855347\n",
            "bi=70, loss=0.32264775037765503\n",
            "bi=70, loss=0.24475952982902527\n",
            "bi=80, loss=0.2510933578014374\n",
            "bi=80, loss=0.2652590870857239\n",
            "bi=80, loss=0.3055742383003235\n",
            "bi=80, loss=0.2637900114059448\n",
            "bi=80, loss=0.32081347703933716\n",
            "bi=80, loss=0.28714028000831604\n",
            "bi=80, loss=0.29600024223327637\n",
            "bi=80, loss=0.29279348254203796\n",
            "bi=90, loss=0.32711273431777954\n",
            "bi=90, loss=0.3686264753341675\n",
            "bi=90, loss=0.3083665072917938\n",
            "bi=90, loss=0.38936030864715576\n",
            "bi=90, loss=0.3146882951259613\n",
            "bi=90, loss=0.36278894543647766\n",
            "bi=90, loss=0.3384164571762085\n",
            "bi=90, loss=0.4493384063243866\n",
            "bi=100, loss=0.345297247171402\n",
            "bi=100, loss=0.32274556159973145\n",
            "bi=100, loss=0.28781360387802124\n",
            "bi=100, loss=0.24896740913391113\n",
            "bi=100, loss=0.3025476634502411\n",
            "bi=100, loss=0.3312619924545288\n",
            "bi=100, loss=0.28013721108436584\n",
            "bi=100, loss=0.27727851271629333\n",
            "bi=110, loss=0.37183877825737\n",
            "bi=110, loss=0.32979121804237366\n",
            "bi=110, loss=0.3037485182285309\n",
            "bi=110, loss=0.35258156061172485\n",
            "bi=110, loss=0.28341224789619446\n",
            "bi=110, loss=0.2721639573574066\n",
            "bi=110, loss=0.27640196681022644\n",
            "bi=110, loss=0.30528438091278076\n",
            "bi=120, loss=0.3940809667110443\n",
            "bi=120, loss=0.3717280924320221\n",
            "bi=120, loss=0.26408496499061584\n",
            "bi=120, loss=0.30433595180511475\n",
            "bi=120, loss=0.3649980127811432\n",
            "bi=120, loss=0.29323112964630127\n",
            "bi=120, loss=0.25222522020339966\n",
            "bi=120, loss=0.41604846715927124\n",
            "bi=130, loss=0.4124206304550171\n",
            "bi=130, loss=0.44098347425460815\n",
            "bi=130, loss=0.266098290681839\n",
            "bi=130, loss=0.46630194783210754\n",
            "bi=130, loss=0.3731016218662262\n",
            "bi=130, loss=0.2568201720714569\n",
            "bi=130, loss=0.27572497725486755\n",
            "bi=130, loss=0.4469452202320099\n",
            "bi=140, loss=0.3850504457950592\n",
            "bi=140, loss=0.33850347995758057\n",
            "bi=140, loss=0.2983457148075104\n",
            "bi=140, loss=0.4088563621044159\n",
            "bi=140, loss=0.41197049617767334\n",
            "bi=140, loss=0.34408044815063477\n",
            "bi=140, loss=0.30638355016708374\n",
            "bi=140, loss=0.25690922141075134\n",
            "bi=150, loss=0.38387805223464966\n",
            "bi=150, loss=0.24613410234451294\n",
            "bi=150, loss=0.31782209873199463\n",
            "bi=150, loss=0.3325401246547699\n",
            "bi=150, loss=0.23343603312969208\n",
            "bi=150, loss=0.3302498161792755\n",
            "bi=150, loss=0.32956209778785706\n",
            "bi=150, loss=0.36894822120666504\n",
            "bi=160, loss=0.33917829394340515\n",
            "bi=160, loss=0.36160117387771606\n",
            "bi=160, loss=0.3158678710460663\n",
            "bi=160, loss=0.3364975154399872\n",
            "bi=160, loss=0.35438549518585205\n",
            "bi=160, loss=0.2864797115325928\n",
            "bi=160, loss=0.3301750123500824\n",
            "bi=160, loss=0.36823657155036926\n",
            "bi=170, loss=0.36465659737586975\n",
            "bi=170, loss=0.3228110671043396\n",
            "bi=170, loss=0.36111241579055786\n",
            "bi=170, loss=0.30646511912345886\n",
            "bi=170, loss=0.3314434885978699\n",
            "bi=170, loss=0.4073539078235626\n",
            "bi=170, loss=0.43789198994636536\n",
            "bi=170, loss=0.2667373716831207\n",
            "epoch = 1, spearman = 0.02581988897471612\n",
            "epoch = 1, spearman = 0.10558569536534326\n",
            "epoch = 1, spearman = 0.12679330540710174\n",
            "epoch = 1, spearman = -0.006300490191759889\n",
            "epoch = 1, spearman = 0.029814239699997202\n",
            "epoch = 1, spearman = 0.026437817182392645\n",
            "epoch = 1, spearman = 0.13939428579062152\n",
            "epoch = 1, spearman = 0.023513749508237303\n",
            "bi=0, loss=0.3280268609523773\n",
            "bi=0, loss=0.32246458530426025\n",
            "bi=0, loss=0.26875948905944824\n",
            "bi=0, loss=0.3050651252269745\n",
            "bi=0, loss=0.29983171820640564\n",
            "bi=0, loss=0.26371079683303833\n",
            "bi=0, loss=0.3351536989212036\n",
            "bi=0, loss=0.3990180194377899\n",
            "bi=10, loss=0.25658005475997925\n",
            "bi=10, loss=0.42338308691978455\n",
            "bi=10, loss=0.3182102143764496\n",
            "bi=10, loss=0.24598091840744019\n",
            "bi=10, loss=0.37362128496170044\n",
            "bi=10, loss=0.49199798703193665\n",
            "bi=10, loss=0.3251930773258209\n",
            "bi=10, loss=0.2723417282104492\n",
            "bi=20, loss=0.4096244275569916\n",
            "bi=20, loss=0.2658179700374603\n",
            "bi=20, loss=0.3487315773963928\n",
            "bi=20, loss=0.38096633553504944\n",
            "bi=20, loss=0.28939148783683777\n",
            "bi=20, loss=0.34069496393203735\n",
            "bi=20, loss=0.25929102301597595\n",
            "bi=20, loss=0.31229838728904724\n",
            "bi=30, loss=0.37112799286842346\n",
            "bi=30, loss=0.3665674030780792\n",
            "bi=30, loss=0.3091382384300232\n",
            "bi=30, loss=0.4983358383178711\n",
            "bi=30, loss=0.2549726665019989\n",
            "bi=30, loss=0.2967938780784607\n",
            "bi=30, loss=0.3403065502643585\n",
            "bi=30, loss=0.2869769036769867\n",
            "bi=40, loss=0.33387434482574463\n",
            "bi=40, loss=0.3847162127494812\n",
            "bi=40, loss=0.3499840497970581\n",
            "bi=40, loss=0.39844170212745667\n",
            "bi=40, loss=0.47569552063941956\n",
            "bi=40, loss=0.35737329721450806\n",
            "bi=40, loss=0.3077799379825592\n",
            "bi=40, loss=0.27575603127479553\n",
            "bi=50, loss=0.5525650382041931\n",
            "bi=50, loss=0.28806376457214355\n",
            "bi=50, loss=0.3691122829914093\n",
            "bi=50, loss=0.2952844500541687\n",
            "bi=50, loss=0.3269973695278168\n",
            "bi=50, loss=0.3209933936595917\n",
            "bi=50, loss=0.38978108763694763\n",
            "bi=50, loss=0.3201199769973755\n",
            "bi=60, loss=0.35840359330177307\n",
            "bi=60, loss=0.2944182753562927\n",
            "bi=60, loss=0.3852270245552063\n",
            "bi=60, loss=0.28113895654678345\n",
            "bi=60, loss=0.3563026189804077\n",
            "bi=60, loss=0.24603700637817383\n",
            "bi=60, loss=0.25645244121551514\n",
            "bi=60, loss=0.276906281709671\n",
            "bi=70, loss=0.3493640720844269\n",
            "bi=70, loss=0.2546654939651489\n",
            "bi=70, loss=0.4031105637550354\n",
            "bi=70, loss=0.28660470247268677\n",
            "bi=70, loss=0.43974319100379944\n",
            "bi=70, loss=0.2931673228740692\n",
            "bi=70, loss=0.3144906461238861\n",
            "bi=70, loss=0.3994576632976532\n",
            "bi=80, loss=0.2511138617992401\n",
            "bi=80, loss=0.2914218306541443\n",
            "bi=80, loss=0.3153849244117737\n",
            "bi=80, loss=0.2763421833515167\n",
            "bi=80, loss=0.32379135489463806\n",
            "bi=80, loss=0.23377104103565216\n",
            "bi=80, loss=0.30616918206214905\n",
            "bi=80, loss=0.24810518324375153\n",
            "bi=90, loss=0.4485222101211548\n",
            "bi=90, loss=0.3455283045768738\n",
            "bi=90, loss=0.36893147230148315\n",
            "bi=90, loss=0.33507436513900757\n",
            "bi=90, loss=0.29348236322402954\n",
            "bi=90, loss=0.35920682549476624\n",
            "bi=90, loss=0.290094256401062\n",
            "bi=90, loss=0.3225552439689636\n",
            "bi=100, loss=0.28033483028411865\n",
            "bi=100, loss=0.31657469272613525\n",
            "bi=100, loss=0.3217262625694275\n",
            "bi=100, loss=0.26921963691711426\n",
            "bi=100, loss=0.30507442355155945\n",
            "bi=100, loss=0.2368629425764084\n",
            "bi=100, loss=0.25212764739990234\n",
            "bi=100, loss=0.3175891637802124\n",
            "bi=110, loss=0.27952224016189575\n",
            "bi=110, loss=0.3095799684524536\n",
            "bi=110, loss=0.30445680022239685\n",
            "bi=110, loss=0.27198436856269836\n",
            "bi=110, loss=0.3244871497154236\n",
            "bi=110, loss=0.3141750991344452\n",
            "bi=110, loss=0.364761620759964\n",
            "bi=110, loss=0.24695008993148804\n",
            "bi=120, loss=0.421414852142334\n",
            "bi=120, loss=0.2772287130355835\n",
            "bi=120, loss=0.4194433093070984\n",
            "bi=120, loss=0.2747867703437805\n",
            "bi=120, loss=0.34344223141670227\n",
            "bi=120, loss=0.3201116919517517\n",
            "bi=120, loss=0.23774075508117676\n",
            "bi=120, loss=0.3959351181983948\n",
            "bi=130, loss=0.4519007205963135\n",
            "bi=130, loss=0.3561666011810303\n",
            "bi=130, loss=0.2617380917072296\n",
            "bi=130, loss=0.24612972140312195\n",
            "bi=130, loss=0.3422743082046509\n",
            "bi=130, loss=0.4557670056819916\n",
            "bi=130, loss=0.2522459626197815\n",
            "bi=130, loss=0.40981316566467285\n",
            "bi=140, loss=0.2893451750278473\n",
            "bi=140, loss=0.3652675747871399\n",
            "bi=140, loss=0.29704976081848145\n",
            "bi=140, loss=0.24733252823352814\n",
            "bi=140, loss=0.350934237241745\n",
            "bi=140, loss=0.29054707288742065\n",
            "bi=140, loss=0.4101918339729309\n",
            "bi=140, loss=0.3469267785549164\n",
            "bi=150, loss=0.3486139178276062\n",
            "bi=150, loss=0.34080907702445984\n",
            "bi=150, loss=0.2294737547636032\n",
            "bi=150, loss=0.3252165615558624\n",
            "bi=150, loss=0.3441792130470276\n",
            "bi=150, loss=0.23470290005207062\n",
            "bi=150, loss=0.3105073869228363\n",
            "bi=150, loss=0.32455167174339294\n",
            "bi=160, loss=0.2902640402317047\n",
            "bi=160, loss=0.36261212825775146\n",
            "bi=160, loss=0.3511160910129547\n",
            "bi=160, loss=0.3289948105812073\n",
            "bi=160, loss=0.355752557516098\n",
            "bi=160, loss=0.32411330938339233\n",
            "bi=160, loss=0.32208892703056335\n",
            "bi=160, loss=0.31875500082969666\n",
            "bi=170, loss=0.345405250787735\n",
            "bi=170, loss=0.32596510648727417\n",
            "bi=170, loss=0.29753583669662476\n",
            "bi=170, loss=0.4072738587856293\n",
            "bi=170, loss=0.40539246797561646\n",
            "bi=170, loss=0.3692448139190674\n",
            "bi=170, loss=0.283475786447525\n",
            "bi=170, loss=0.34525996446609497\n",
            "epoch = 2, spearman = 0.17213259316477408\n",
            "epoch = 2, spearman = -0.008606629658238696\n",
            "epoch = 2, spearman = 0.045339287757672334\n",
            "epoch = 2, spearman = 0.1171163926977373\n",
            "epoch = 2, spearman = 0.17151466495709755\n",
            "epoch = 2, spearman = 0.07222945978351418\n",
            "epoch = 2, spearman = 0.12448716594062295\n",
            "epoch = 2, spearman = -0.043033148291193514\n",
            "bi=0, loss=0.32339444756507874\n",
            "bi=0, loss=0.2725584805011749\n",
            "bi=0, loss=0.28241050243377686\n",
            "bi=0, loss=0.2838360667228699\n",
            "bi=0, loss=0.29456230998039246\n",
            "bi=0, loss=0.2542489767074585\n",
            "bi=0, loss=0.3094687759876251\n",
            "bi=0, loss=0.344870001077652\n",
            "bi=10, loss=0.495090126991272\n",
            "bi=10, loss=0.3547682762145996\n",
            "bi=10, loss=0.4145148992538452\n",
            "bi=10, loss=0.23042093217372894\n",
            "bi=10, loss=0.3026481866836548\n",
            "bi=10, loss=0.27268263697624207\n",
            "bi=10, loss=0.2804550528526306\n",
            "bi=10, loss=0.3184753954410553\n",
            "bi=20, loss=0.3299795687198639\n",
            "bi=20, loss=0.37718430161476135\n",
            "bi=20, loss=0.33329343795776367\n",
            "bi=20, loss=0.2822549343109131\n",
            "bi=20, loss=0.24320173263549805\n",
            "bi=20, loss=0.2852321267127991\n",
            "bi=20, loss=0.3859928548336029\n",
            "bi=20, loss=0.3662967383861542\n",
            "bi=30, loss=0.2659188508987427\n",
            "bi=30, loss=0.25165367126464844\n",
            "bi=30, loss=0.28429025411605835\n",
            "bi=30, loss=0.4684961438179016\n",
            "bi=30, loss=0.2867872416973114\n",
            "bi=30, loss=0.29494088888168335\n",
            "bi=30, loss=0.3439875841140747\n",
            "bi=30, loss=0.3358762264251709\n",
            "bi=40, loss=0.2593873143196106\n",
            "bi=40, loss=0.350197434425354\n",
            "bi=40, loss=0.30830854177474976\n",
            "bi=40, loss=0.3566077649593353\n",
            "bi=40, loss=0.3273737132549286\n",
            "bi=40, loss=0.5239331126213074\n",
            "bi=40, loss=0.3592306971549988\n",
            "bi=40, loss=0.35334673523902893\n",
            "bi=50, loss=0.5399481058120728\n",
            "bi=50, loss=0.3113030195236206\n",
            "bi=50, loss=0.30110689997673035\n",
            "bi=50, loss=0.37594515085220337\n",
            "bi=50, loss=0.2624927759170532\n",
            "bi=50, loss=0.3115711808204651\n",
            "bi=50, loss=0.33633649349212646\n",
            "bi=50, loss=0.3947266638278961\n",
            "bi=60, loss=0.3518456220626831\n",
            "bi=60, loss=0.2699454426765442\n",
            "bi=60, loss=0.35932645201683044\n",
            "bi=60, loss=0.24056273698806763\n",
            "bi=60, loss=0.29248014092445374\n",
            "bi=60, loss=0.34414300322532654\n",
            "bi=60, loss=0.25438737869262695\n",
            "bi=60, loss=0.24725475907325745\n",
            "bi=70, loss=0.2619240880012512\n",
            "bi=70, loss=0.28692227602005005\n",
            "bi=70, loss=0.30021753907203674\n",
            "bi=70, loss=0.37078168988227844\n",
            "bi=70, loss=0.4579675495624542\n",
            "bi=70, loss=0.3635607063770294\n",
            "bi=70, loss=0.29740971326828003\n",
            "bi=70, loss=0.2511903941631317\n",
            "bi=80, loss=0.24387091398239136\n",
            "bi=80, loss=0.2157510221004486\n",
            "bi=80, loss=0.2797180414199829\n",
            "bi=80, loss=0.28920215368270874\n",
            "bi=80, loss=0.25900372862815857\n",
            "bi=80, loss=0.25761476159095764\n",
            "bi=80, loss=0.2884865701198578\n",
            "bi=80, loss=0.23521456122398376\n",
            "bi=90, loss=0.29657748341560364\n",
            "bi=90, loss=0.2586750388145447\n",
            "bi=90, loss=0.32723066210746765\n",
            "bi=90, loss=0.3425966203212738\n",
            "bi=90, loss=0.32211846113204956\n",
            "bi=90, loss=0.42231452465057373\n",
            "bi=90, loss=0.26055505871772766\n",
            "bi=90, loss=0.2648591697216034\n",
            "bi=100, loss=0.21922966837882996\n",
            "bi=100, loss=0.2736479640007019\n",
            "bi=100, loss=0.26684054732322693\n",
            "bi=100, loss=0.3023424446582794\n",
            "bi=100, loss=0.31888332962989807\n",
            "bi=100, loss=0.323803573846817\n",
            "bi=100, loss=0.2644328773021698\n",
            "bi=100, loss=0.2988443970680237\n",
            "bi=110, loss=0.3176521062850952\n",
            "bi=110, loss=0.308278352022171\n",
            "bi=110, loss=0.31418576836586\n",
            "bi=110, loss=0.26809588074684143\n",
            "bi=110, loss=0.2750307619571686\n",
            "bi=110, loss=0.23489710688591003\n",
            "bi=110, loss=0.28795039653778076\n",
            "bi=110, loss=0.30764034390449524\n",
            "bi=120, loss=0.2788124680519104\n",
            "bi=120, loss=0.23361992835998535\n",
            "bi=120, loss=0.28672462701797485\n",
            "bi=120, loss=0.40415793657302856\n",
            "bi=120, loss=0.3819388449192047\n",
            "bi=120, loss=0.25178614258766174\n",
            "bi=120, loss=0.3559917211532593\n",
            "bi=120, loss=0.3324623703956604\n",
            "bi=130, loss=0.40752100944519043\n",
            "bi=130, loss=0.3263118863105774\n",
            "bi=130, loss=0.3868256211280823\n",
            "bi=130, loss=0.42131170630455017\n",
            "bi=130, loss=0.2688542604446411\n",
            "bi=130, loss=0.26870033144950867\n",
            "bi=130, loss=0.4383162558078766\n",
            "bi=130, loss=0.23175905644893646\n",
            "bi=140, loss=0.32045263051986694\n",
            "bi=140, loss=0.293662428855896\n",
            "bi=140, loss=0.380536824464798\n",
            "bi=140, loss=0.2556597590446472\n",
            "bi=140, loss=0.3331170976161957\n",
            "bi=140, loss=0.29204457998275757\n",
            "bi=140, loss=0.3800378739833832\n",
            "bi=140, loss=0.22984008491039276\n",
            "bi=150, loss=0.30408135056495667\n",
            "bi=150, loss=0.21546220779418945\n",
            "bi=150, loss=0.22839556634426117\n",
            "bi=150, loss=0.3364347517490387\n",
            "bi=150, loss=0.3057481050491333\n",
            "bi=150, loss=0.2960253357887268\n",
            "bi=150, loss=0.39534395933151245\n",
            "bi=150, loss=0.3308905065059662\n",
            "bi=160, loss=0.28557100892066956\n",
            "bi=160, loss=0.30627238750457764\n",
            "bi=160, loss=0.35614046454429626\n",
            "bi=160, loss=0.3065476715564728\n",
            "bi=160, loss=0.3518328070640564\n",
            "bi=160, loss=0.28970977663993835\n",
            "bi=160, loss=0.31854942440986633\n",
            "bi=160, loss=0.34350651502609253\n",
            "bi=170, loss=0.2887513041496277\n",
            "bi=170, loss=0.32372862100601196\n",
            "bi=170, loss=0.3113865256309509\n",
            "bi=170, loss=0.3797648847103119\n",
            "bi=170, loss=0.2452254295349121\n",
            "bi=170, loss=0.3885025680065155\n",
            "bi=170, loss=0.33641481399536133\n",
            "bi=170, loss=0.3298770487308502\n",
            "epoch = 3, spearman = 0.13309379559886164\n",
            "epoch = 3, spearman = -0.005682561984083353\n",
            "epoch = 3, spearman = 0.060246407607670936\n",
            "epoch = 3, spearman = 0.12679330540710176\n",
            "epoch = 3, spearman = 0.1314055843400594\n",
            "epoch = 3, spearman = 0.10896211788294781\n",
            "epoch = 3, spearman = 0.12218102647414414\n",
            "epoch = 3, spearman = 0.008606629658238715\n",
            "bi=0, loss=0.30122122168540955\n",
            "bi=0, loss=0.2878139019012451\n",
            "bi=0, loss=0.3019614517688751\n",
            "bi=0, loss=0.26521676778793335\n",
            "bi=0, loss=0.2780081331729889\n",
            "bi=0, loss=0.2524215579032898\n",
            "bi=0, loss=0.3232957422733307\n",
            "bi=0, loss=0.3215477764606476\n",
            "bi=10, loss=0.49905532598495483\n",
            "bi=10, loss=0.2800443768501282\n",
            "bi=10, loss=0.3871557116508484\n",
            "bi=10, loss=0.24192030727863312\n",
            "bi=10, loss=0.3212309181690216\n",
            "bi=10, loss=0.22228164970874786\n",
            "bi=10, loss=0.3252411484718323\n",
            "bi=10, loss=0.31072619557380676\n",
            "bi=20, loss=0.31670278310775757\n",
            "bi=20, loss=0.379501610994339\n",
            "bi=20, loss=0.29662826657295227\n",
            "bi=20, loss=0.26576390862464905\n",
            "bi=20, loss=0.23277199268341064\n",
            "bi=20, loss=0.34455937147140503\n",
            "bi=20, loss=0.26561206579208374\n",
            "bi=20, loss=0.32258087396621704\n",
            "bi=30, loss=0.2810644805431366\n",
            "bi=30, loss=0.26473894715309143\n",
            "bi=30, loss=0.3484153747558594\n",
            "bi=30, loss=0.28111961483955383\n",
            "bi=30, loss=0.24963612854480743\n",
            "bi=30, loss=0.3387821614742279\n",
            "bi=30, loss=0.3005615770816803\n",
            "bi=30, loss=0.4869670271873474\n",
            "bi=40, loss=0.3126630485057831\n",
            "bi=40, loss=0.23763933777809143\n",
            "bi=40, loss=0.29946669936180115\n",
            "bi=40, loss=0.2929180860519409\n",
            "bi=40, loss=0.4808935523033142\n",
            "bi=40, loss=0.37660500407218933\n",
            "bi=40, loss=0.3306512236595154\n",
            "bi=40, loss=0.31998422741889954\n",
            "bi=50, loss=0.5086463689804077\n",
            "bi=50, loss=0.3067165017127991\n",
            "bi=50, loss=0.26973414421081543\n",
            "bi=50, loss=0.3928680121898651\n",
            "bi=50, loss=0.2732272744178772\n",
            "bi=50, loss=0.36649397015571594\n",
            "bi=50, loss=0.29197949171066284\n",
            "bi=50, loss=0.3312339186668396\n",
            "bi=60, loss=0.2544499933719635\n",
            "bi=60, loss=0.375777006149292\n",
            "bi=60, loss=0.34979116916656494\n",
            "bi=60, loss=0.24335260689258575\n",
            "bi=60, loss=0.25380685925483704\n",
            "bi=60, loss=0.2770651578903198\n",
            "bi=60, loss=0.32737064361572266\n",
            "bi=60, loss=0.23809008300304413\n",
            "bi=70, loss=0.3048492968082428\n",
            "bi=70, loss=0.24127531051635742\n",
            "bi=70, loss=0.2667117714881897\n",
            "bi=70, loss=0.4578438997268677\n",
            "bi=70, loss=0.27809658646583557\n",
            "bi=70, loss=0.31064555048942566\n",
            "bi=70, loss=0.3858308494091034\n",
            "bi=70, loss=0.3567034900188446\n",
            "bi=80, loss=0.25676432251930237\n",
            "bi=80, loss=0.34847187995910645\n",
            "bi=80, loss=0.26308169960975647\n",
            "bi=80, loss=0.24576564133167267\n",
            "bi=80, loss=0.25918692350387573\n",
            "bi=80, loss=0.2726879119873047\n",
            "bi=80, loss=0.22879846394062042\n",
            "bi=80, loss=0.26519566774368286\n",
            "bi=90, loss=0.3461088538169861\n",
            "bi=90, loss=0.33051806688308716\n",
            "bi=90, loss=0.25956159830093384\n",
            "bi=90, loss=0.3453506827354431\n",
            "bi=90, loss=0.4037908911705017\n",
            "bi=90, loss=0.27506551146507263\n",
            "bi=90, loss=0.2583634555339813\n",
            "bi=90, loss=0.2881666123867035\n",
            "bi=100, loss=0.2926752269268036\n",
            "bi=100, loss=0.28349778056144714\n",
            "bi=100, loss=0.3168255388736725\n",
            "bi=100, loss=0.2901122570037842\n",
            "bi=100, loss=0.27054956555366516\n",
            "bi=100, loss=0.25622135400772095\n",
            "bi=100, loss=0.33681827783584595\n",
            "bi=100, loss=0.22533102333545685\n",
            "bi=110, loss=0.27557259798049927\n",
            "bi=110, loss=0.24832811951637268\n",
            "bi=110, loss=0.2850756347179413\n",
            "bi=110, loss=0.3187856376171112\n",
            "bi=110, loss=0.296678751707077\n",
            "bi=110, loss=0.2844097912311554\n",
            "bi=110, loss=0.30991131067276\n",
            "bi=110, loss=0.2609124183654785\n",
            "bi=120, loss=0.2267366498708725\n",
            "bi=120, loss=0.347175657749176\n",
            "bi=120, loss=0.3581050932407379\n",
            "bi=120, loss=0.3258891701698303\n",
            "bi=120, loss=0.2849615216255188\n",
            "bi=120, loss=0.2560679018497467\n",
            "bi=120, loss=0.40185651183128357\n",
            "bi=120, loss=0.2834014296531677\n",
            "bi=130, loss=0.25725680589675903\n",
            "bi=130, loss=0.4084053337574005\n",
            "bi=130, loss=0.34056347608566284\n",
            "bi=130, loss=0.40628600120544434\n",
            "bi=130, loss=0.23998571932315826\n",
            "bi=130, loss=0.23337049782276154\n",
            "bi=130, loss=0.4394618570804596\n",
            "bi=130, loss=0.3085472583770752\n",
            "bi=140, loss=0.27830803394317627\n",
            "bi=140, loss=0.3084988296031952\n",
            "bi=140, loss=0.3570466935634613\n",
            "bi=140, loss=0.2960292398929596\n",
            "bi=140, loss=0.3295220136642456\n",
            "bi=140, loss=0.2719154953956604\n",
            "bi=140, loss=0.243423193693161\n",
            "bi=140, loss=0.30956462025642395\n",
            "bi=150, loss=0.31335416436195374\n",
            "bi=150, loss=0.32342618703842163\n",
            "bi=150, loss=0.3293677270412445\n",
            "bi=150, loss=0.2862282991409302\n",
            "bi=150, loss=0.2101600021123886\n",
            "bi=150, loss=0.30006498098373413\n",
            "bi=150, loss=0.27604448795318604\n",
            "bi=150, loss=0.22768642008304596\n",
            "bi=160, loss=0.34621965885162354\n",
            "bi=160, loss=0.3287501931190491\n",
            "bi=160, loss=0.30674439668655396\n",
            "bi=160, loss=0.26640480756759644\n",
            "bi=160, loss=0.2866411805152893\n",
            "bi=160, loss=0.2998562157154083\n",
            "bi=160, loss=0.30074572563171387\n",
            "bi=160, loss=0.3271012306213379\n",
            "bi=170, loss=0.297525554895401\n",
            "bi=170, loss=0.2864173948764801\n",
            "bi=170, loss=0.2926679253578186\n",
            "bi=170, loss=0.3085600733757019\n",
            "bi=170, loss=0.30972760915756226\n",
            "bi=170, loss=0.3733430504798889\n",
            "bi=170, loss=0.21874438226222992\n",
            "bi=170, loss=0.36298689246177673\n",
            "epoch = 4, spearman = 0.11188618555710315\n",
            "epoch = 4, spearman = 0.17612694389005515\n",
            "epoch = 4, spearman = 0.1675203142318165\n",
            "epoch = 4, spearman = 0.21224167378181225\n",
            "epoch = 4, spearman = 0.09405499803294921\n",
            "epoch = 4, spearman = 0.12218102647414412\n",
            "epoch = 4, spearman = 0.1519952661741413\n",
            "epoch = 4, spearman = 0.07515352745766954\n",
            "bi=0, loss=0.2679857611656189\n",
            "bi=0, loss=0.29307353496551514\n",
            "bi=0, loss=0.2641519606113434\n",
            "bi=0, loss=0.2706444263458252\n",
            "bi=0, loss=0.3017317056655884\n",
            "bi=0, loss=0.25530582666397095\n",
            "bi=0, loss=0.28656500577926636\n",
            "bi=0, loss=0.3058106303215027\n",
            "bi=10, loss=0.2881433665752411\n",
            "bi=10, loss=0.21212129294872284\n",
            "bi=10, loss=0.21263858675956726\n",
            "bi=10, loss=0.30995720624923706\n",
            "bi=10, loss=0.21155273914337158\n",
            "bi=10, loss=0.46498358249664307\n",
            "bi=10, loss=0.3608814477920532\n",
            "bi=10, loss=0.26704972982406616\n",
            "bi=20, loss=0.3287571370601654\n",
            "bi=20, loss=0.3173748850822449\n",
            "bi=20, loss=0.2469954490661621\n",
            "bi=20, loss=0.31173205375671387\n",
            "bi=20, loss=0.35077136754989624\n",
            "bi=20, loss=0.30775150656700134\n",
            "bi=20, loss=0.23092052340507507\n",
            "bi=20, loss=0.2544245719909668\n",
            "bi=30, loss=0.28991782665252686\n",
            "bi=30, loss=0.2960909903049469\n",
            "bi=30, loss=0.5485578179359436\n",
            "bi=30, loss=0.3138822317123413\n",
            "bi=30, loss=0.29477399587631226\n",
            "bi=30, loss=0.2551109194755554\n",
            "bi=30, loss=0.27896690368652344\n",
            "bi=30, loss=0.3416109085083008\n",
            "bi=40, loss=0.23108340799808502\n",
            "bi=40, loss=0.43632885813713074\n",
            "bi=40, loss=0.29518944025039673\n",
            "bi=40, loss=0.27905118465423584\n",
            "bi=40, loss=0.3128955364227295\n",
            "bi=40, loss=0.2922293543815613\n",
            "bi=40, loss=0.45289427042007446\n",
            "bi=40, loss=0.3113098442554474\n",
            "bi=50, loss=0.4741899073123932\n",
            "bi=50, loss=0.29567834734916687\n",
            "bi=50, loss=0.37850451469421387\n",
            "bi=50, loss=0.2874261140823364\n",
            "bi=50, loss=0.4055175483226776\n",
            "bi=50, loss=0.33468422293663025\n",
            "bi=50, loss=0.2700422704219818\n",
            "bi=50, loss=0.27260565757751465\n",
            "bi=60, loss=0.2211645543575287\n",
            "bi=60, loss=0.2278951108455658\n",
            "bi=60, loss=0.2420801967382431\n",
            "bi=60, loss=0.29956310987472534\n",
            "bi=60, loss=0.24807420372962952\n",
            "bi=60, loss=0.3350526988506317\n",
            "bi=60, loss=0.3485329747200012\n",
            "bi=60, loss=0.24212568998336792\n",
            "bi=70, loss=0.2885521352291107\n",
            "bi=70, loss=0.25825363397598267\n",
            "bi=70, loss=0.33642449975013733\n",
            "bi=70, loss=0.3841860592365265\n",
            "bi=70, loss=0.2506992220878601\n",
            "bi=70, loss=0.2201130986213684\n",
            "bi=70, loss=0.29487618803977966\n",
            "bi=70, loss=0.3925745487213135\n",
            "bi=80, loss=0.26039084792137146\n",
            "bi=80, loss=0.24271200597286224\n",
            "bi=80, loss=0.26748064160346985\n",
            "bi=80, loss=0.25776809453964233\n",
            "bi=80, loss=0.24991470575332642\n",
            "bi=80, loss=0.20300261676311493\n",
            "bi=80, loss=0.3021499514579773\n",
            "bi=80, loss=0.22903470695018768\n",
            "bi=90, loss=0.3377953767776489\n",
            "bi=90, loss=0.34575241804122925\n",
            "bi=90, loss=0.38175126910209656\n",
            "bi=90, loss=0.2742542028427124\n",
            "bi=90, loss=0.46741804480552673\n",
            "bi=90, loss=0.24337059259414673\n",
            "bi=90, loss=0.30766671895980835\n",
            "bi=90, loss=0.326286643743515\n",
            "bi=100, loss=0.2845384478569031\n",
            "bi=100, loss=0.2533198297023773\n",
            "bi=100, loss=0.22974540293216705\n",
            "bi=100, loss=0.2672594487667084\n",
            "bi=100, loss=0.26612502336502075\n",
            "bi=100, loss=0.3111301064491272\n",
            "bi=100, loss=0.32470786571502686\n",
            "bi=100, loss=0.2786976993083954\n",
            "bi=110, loss=0.27138596773147583\n",
            "bi=110, loss=0.2756446599960327\n",
            "bi=110, loss=0.2676240801811218\n",
            "bi=110, loss=0.30462756752967834\n",
            "bi=110, loss=0.32887300848960876\n",
            "bi=110, loss=0.2586609423160553\n",
            "bi=110, loss=0.24645943939685822\n",
            "bi=110, loss=0.27867695689201355\n",
            "bi=120, loss=0.27928856015205383\n",
            "bi=120, loss=0.3386420011520386\n",
            "bi=120, loss=0.239811971783638\n",
            "bi=120, loss=0.29710808396339417\n",
            "bi=120, loss=0.3641076683998108\n",
            "bi=120, loss=0.20175445079803467\n",
            "bi=120, loss=0.3535633385181427\n",
            "bi=120, loss=0.3837653398513794\n",
            "bi=130, loss=0.25582054257392883\n",
            "bi=130, loss=0.37606939673423767\n",
            "bi=130, loss=0.32089629769325256\n",
            "bi=130, loss=0.343420147895813\n",
            "bi=130, loss=0.28306692838668823\n",
            "bi=130, loss=0.22792217135429382\n",
            "bi=130, loss=0.25718334317207336\n",
            "bi=130, loss=0.38151952624320984\n",
            "bi=140, loss=0.31159794330596924\n",
            "bi=140, loss=0.2941199541091919\n",
            "bi=140, loss=0.2754029929637909\n",
            "bi=140, loss=0.27059417963027954\n",
            "bi=140, loss=0.34371012449264526\n",
            "bi=140, loss=0.21342024207115173\n",
            "bi=140, loss=0.30178406834602356\n",
            "bi=140, loss=0.27835187315940857\n",
            "bi=150, loss=0.3025459945201874\n",
            "bi=150, loss=0.21131069958209991\n",
            "bi=150, loss=0.26549068093299866\n",
            "bi=150, loss=0.32534995675086975\n",
            "bi=150, loss=0.3198217749595642\n",
            "bi=150, loss=0.2600941061973572\n",
            "bi=150, loss=0.30805620551109314\n",
            "bi=150, loss=0.2385871708393097\n",
            "bi=160, loss=0.32790789008140564\n",
            "bi=160, loss=0.2955001890659332\n",
            "bi=160, loss=0.2580992877483368\n",
            "bi=160, loss=0.33267632126808167\n",
            "bi=160, loss=0.2372690886259079\n",
            "bi=160, loss=0.3287249505519867\n",
            "bi=160, loss=0.2783745527267456\n",
            "bi=160, loss=0.3032931685447693\n",
            "bi=170, loss=0.34932824969291687\n",
            "bi=170, loss=0.289870947599411\n",
            "bi=170, loss=0.31113678216934204\n",
            "bi=170, loss=0.25066250562667847\n",
            "bi=170, loss=0.26409074664115906\n",
            "bi=170, loss=0.22883391380310059\n",
            "bi=170, loss=0.3426312208175659\n",
            "bi=170, loss=0.3268952965736389\n",
            "epoch = 5, spearman = 0.178433083356534\n",
            "epoch = 5, spearman = 0.24436205294828825\n",
            "epoch = 5, spearman = 0.07745966692414834\n",
            "epoch = 5, spearman = 0.20363504412357356\n",
            "epoch = 5, spearman = 0.10097341643238564\n",
            "epoch = 5, spearman = 0.04702749901647461\n",
            "epoch = 5, spearman = 0.2609573840570891\n",
            "epoch = 5, spearman = 0.17612694389005515\n",
            "bi=0, loss=0.22063684463500977\n",
            "bi=0, loss=0.25047147274017334\n",
            "bi=0, loss=0.28237831592559814\n",
            "bi=0, loss=0.2561928629875183\n",
            "bi=0, loss=0.26976504921913147\n",
            "bi=0, loss=0.27186357975006104\n",
            "bi=0, loss=0.22556926310062408\n",
            "bi=0, loss=0.2938617169857025\n",
            "bi=10, loss=0.233506977558136\n",
            "bi=10, loss=0.20767296850681305\n",
            "bi=10, loss=0.1725732982158661\n",
            "bi=10, loss=0.33227625489234924\n",
            "bi=10, loss=0.20928896963596344\n",
            "bi=10, loss=0.2773791253566742\n",
            "bi=10, loss=0.2977551817893982\n",
            "bi=10, loss=0.4110897481441498\n",
            "bi=20, loss=0.3538249731063843\n",
            "bi=20, loss=0.22921332716941833\n",
            "bi=20, loss=0.2914583683013916\n",
            "bi=20, loss=0.3186998963356018\n",
            "bi=20, loss=0.3179061710834503\n",
            "bi=20, loss=0.2676429748535156\n",
            "bi=20, loss=0.31150928139686584\n",
            "bi=20, loss=0.22225797176361084\n",
            "bi=30, loss=0.44405344128608704\n",
            "bi=30, loss=0.28370893001556396\n",
            "bi=30, loss=0.26331156492233276\n",
            "bi=30, loss=0.28112077713012695\n",
            "bi=30, loss=0.24927125871181488\n",
            "bi=30, loss=0.25055351853370667\n",
            "bi=30, loss=0.31300029158592224\n",
            "bi=30, loss=0.2797482907772064\n",
            "bi=40, loss=0.30488651990890503\n",
            "bi=40, loss=0.2512800693511963\n",
            "bi=40, loss=0.270393967628479\n",
            "bi=40, loss=0.41615888476371765\n",
            "bi=40, loss=0.3410845994949341\n",
            "bi=40, loss=0.4867764413356781\n",
            "bi=40, loss=0.2980649471282959\n",
            "bi=40, loss=0.2671279311180115\n",
            "bi=50, loss=0.2625562846660614\n",
            "bi=50, loss=0.3552219271659851\n",
            "bi=50, loss=0.2676975727081299\n",
            "bi=50, loss=0.3239365518093109\n",
            "bi=50, loss=0.3485989570617676\n",
            "bi=50, loss=0.24171395599842072\n",
            "bi=50, loss=0.25390133261680603\n",
            "bi=50, loss=0.49490806460380554\n",
            "bi=60, loss=0.270092636346817\n",
            "bi=60, loss=0.2729932367801666\n",
            "bi=60, loss=0.24566277861595154\n",
            "bi=60, loss=0.3238341510295868\n",
            "bi=60, loss=0.2651628851890564\n",
            "bi=60, loss=0.23122477531433105\n",
            "bi=60, loss=0.34797242283821106\n",
            "bi=60, loss=0.29583683609962463\n",
            "bi=70, loss=0.20402997732162476\n",
            "bi=70, loss=0.3535996973514557\n",
            "bi=70, loss=0.279376357793808\n",
            "bi=70, loss=0.4319813847541809\n",
            "bi=70, loss=0.2387445569038391\n",
            "bi=70, loss=0.3224516212940216\n",
            "bi=70, loss=0.29400143027305603\n",
            "bi=70, loss=0.2684365510940552\n",
            "bi=80, loss=0.2703936696052551\n",
            "bi=80, loss=0.25975242257118225\n",
            "bi=80, loss=0.19343605637550354\n",
            "bi=80, loss=0.23315392434597015\n",
            "bi=80, loss=0.25196585059165955\n",
            "bi=80, loss=0.3019214868545532\n",
            "bi=80, loss=0.2637839913368225\n",
            "bi=80, loss=0.24842782318592072\n",
            "bi=90, loss=0.4017348289489746\n",
            "bi=90, loss=0.34099334478378296\n",
            "bi=90, loss=0.31472352147102356\n",
            "bi=90, loss=0.23768481612205505\n",
            "bi=90, loss=0.28443726897239685\n",
            "bi=90, loss=0.35177093744277954\n",
            "bi=90, loss=0.2256862372159958\n",
            "bi=90, loss=0.2992091476917267\n",
            "bi=100, loss=0.2566792368888855\n",
            "bi=100, loss=0.225637286901474\n",
            "bi=100, loss=0.24704095721244812\n",
            "bi=100, loss=0.3081563115119934\n",
            "bi=100, loss=0.22407415509223938\n",
            "bi=100, loss=0.24490401148796082\n",
            "bi=100, loss=0.30206066370010376\n",
            "bi=100, loss=0.30948498845100403\n",
            "bi=110, loss=0.2369559109210968\n",
            "bi=110, loss=0.2634793519973755\n",
            "bi=110, loss=0.2961181402206421\n",
            "bi=110, loss=0.2931614816188812\n",
            "bi=110, loss=0.30323895812034607\n",
            "bi=110, loss=0.29077914357185364\n",
            "bi=110, loss=0.256093829870224\n",
            "bi=110, loss=0.2484181523323059\n",
            "bi=120, loss=0.32693353295326233\n",
            "bi=120, loss=0.365189790725708\n",
            "bi=120, loss=0.3566020429134369\n",
            "bi=120, loss=0.23240569233894348\n",
            "bi=120, loss=0.36244997382164\n",
            "bi=120, loss=0.2597261965274811\n",
            "bi=120, loss=0.24957908689975739\n",
            "bi=120, loss=0.2116563320159912\n",
            "bi=130, loss=0.3444191813468933\n",
            "bi=130, loss=0.3119206726551056\n",
            "bi=130, loss=0.22883784770965576\n",
            "bi=130, loss=0.24367475509643555\n",
            "bi=130, loss=0.23060119152069092\n",
            "bi=130, loss=0.2506178319454193\n",
            "bi=130, loss=0.33191925287246704\n",
            "bi=130, loss=0.35764092206954956\n",
            "bi=140, loss=0.3159672021865845\n",
            "bi=140, loss=0.2824874520301819\n",
            "bi=140, loss=0.24335139989852905\n",
            "bi=140, loss=0.2310667335987091\n",
            "bi=140, loss=0.2692837417125702\n",
            "bi=140, loss=0.30256879329681396\n",
            "bi=140, loss=0.3193132281303406\n",
            "bi=140, loss=0.27990826964378357\n",
            "bi=150, loss=0.19291208684444427\n",
            "bi=150, loss=0.1973554641008377\n",
            "bi=150, loss=0.2747550904750824\n",
            "bi=150, loss=0.2852409780025482\n",
            "bi=150, loss=0.2884373366832733\n",
            "bi=150, loss=0.26933225989341736\n",
            "bi=150, loss=0.32353803515434265\n",
            "bi=150, loss=0.25116100907325745\n",
            "bi=160, loss=0.34628748893737793\n",
            "bi=160, loss=0.3321508765220642\n",
            "bi=160, loss=0.2263880968093872\n",
            "bi=160, loss=0.29787173867225647\n",
            "bi=160, loss=0.248392716050148\n",
            "bi=160, loss=0.3082689642906189\n",
            "bi=160, loss=0.2959997355937958\n",
            "bi=160, loss=0.2812383472919464\n",
            "bi=170, loss=0.28737378120422363\n",
            "bi=170, loss=0.2920248806476593\n",
            "bi=170, loss=0.3204975426197052\n",
            "bi=170, loss=0.27896061539649963\n",
            "bi=170, loss=0.2597041130065918\n",
            "bi=170, loss=0.25889721512794495\n",
            "bi=170, loss=0.29592737555503845\n",
            "bi=170, loss=0.2084352821111679\n",
            "epoch = 6, spearman = 0.09697906570710456\n",
            "epoch = 6, spearman = 0.043033148291193514\n",
            "epoch = 6, spearman = 0.18703971301477265\n",
            "epoch = 6, spearman = 0.03673265809943363\n",
            "epoch = 6, spearman = 0.20363504412357353\n",
            "epoch = 6, spearman = 0.1973345539318137\n",
            "epoch = 6, spearman = 0.16920852549061877\n",
            "epoch = 6, spearman = 0.12679330540710174\n",
            "bi=0, loss=0.22808530926704407\n",
            "bi=0, loss=0.210256427526474\n",
            "bi=0, loss=0.24049746990203857\n",
            "bi=0, loss=0.268873006105423\n",
            "bi=0, loss=0.2689378559589386\n",
            "bi=0, loss=0.222878098487854\n",
            "bi=0, loss=0.252957284450531\n",
            "bi=0, loss=0.28563350439071655\n",
            "bi=10, loss=0.3249170780181885\n",
            "bi=10, loss=0.22415786981582642\n",
            "bi=10, loss=0.38526129722595215\n",
            "bi=10, loss=0.21380576491355896\n",
            "bi=10, loss=0.2560780942440033\n",
            "bi=10, loss=0.2234463393688202\n",
            "bi=10, loss=0.17218077182769775\n",
            "bi=10, loss=0.27957209944725037\n",
            "bi=20, loss=0.26209789514541626\n",
            "bi=20, loss=0.18023259937763214\n",
            "bi=20, loss=0.35550692677497864\n",
            "bi=20, loss=0.31655099987983704\n",
            "bi=20, loss=0.2695741057395935\n",
            "bi=20, loss=0.2827000319957733\n",
            "bi=20, loss=0.2313740849494934\n",
            "bi=20, loss=0.261410653591156\n",
            "bi=30, loss=0.19813494384288788\n",
            "bi=30, loss=0.3070131838321686\n",
            "bi=30, loss=0.23121456801891327\n",
            "bi=30, loss=0.28093329071998596\n",
            "bi=30, loss=0.3068411648273468\n",
            "bi=30, loss=0.4543052315711975\n",
            "bi=30, loss=0.29129624366760254\n",
            "bi=30, loss=0.2611706852912903\n",
            "bi=40, loss=0.27522823214530945\n",
            "bi=40, loss=0.2584221065044403\n",
            "bi=40, loss=0.2781231701374054\n",
            "bi=40, loss=0.4548439383506775\n",
            "bi=40, loss=0.23720096051692963\n",
            "bi=40, loss=0.38200291991233826\n",
            "bi=40, loss=0.3069339990615845\n",
            "bi=40, loss=0.26464906334877014\n",
            "bi=50, loss=0.3326704204082489\n",
            "bi=50, loss=0.27138420939445496\n",
            "bi=50, loss=0.34128686785697937\n",
            "bi=50, loss=0.2662901282310486\n",
            "bi=50, loss=0.49949708580970764\n",
            "bi=50, loss=0.26937395334243774\n",
            "bi=50, loss=0.3108225464820862\n",
            "bi=50, loss=0.26407942175865173\n",
            "bi=60, loss=0.27093973755836487\n",
            "bi=60, loss=0.39172467589378357\n",
            "bi=60, loss=0.2226433902978897\n",
            "bi=60, loss=0.29978859424591064\n",
            "bi=60, loss=0.27477943897247314\n",
            "bi=60, loss=0.21138231456279755\n",
            "bi=60, loss=0.3301689326763153\n",
            "bi=60, loss=0.19915656745433807\n",
            "bi=70, loss=0.2766224443912506\n",
            "bi=70, loss=0.19074247777462006\n",
            "bi=70, loss=0.35996198654174805\n",
            "bi=70, loss=0.2659650444984436\n",
            "bi=70, loss=0.2939547002315521\n",
            "bi=70, loss=0.2750183045864105\n",
            "bi=70, loss=0.38578134775161743\n",
            "bi=70, loss=0.33791735768318176\n",
            "bi=80, loss=0.2536369264125824\n",
            "bi=80, loss=0.2229692041873932\n",
            "bi=80, loss=0.17629653215408325\n",
            "bi=80, loss=0.24686911702156067\n",
            "bi=80, loss=0.22394119203090668\n",
            "bi=80, loss=0.23168613016605377\n",
            "bi=80, loss=0.2653690278530121\n",
            "bi=80, loss=0.21628062427043915\n",
            "bi=90, loss=0.23605018854141235\n",
            "bi=90, loss=0.31407830119132996\n",
            "bi=90, loss=0.23200836777687073\n",
            "bi=90, loss=0.3952014148235321\n",
            "bi=90, loss=0.30654531717300415\n",
            "bi=90, loss=0.21151618659496307\n",
            "bi=90, loss=0.2980997562408447\n",
            "bi=90, loss=0.27319106459617615\n",
            "bi=100, loss=0.2663641571998596\n",
            "bi=100, loss=0.21541082859039307\n",
            "bi=100, loss=0.19368627667427063\n",
            "bi=100, loss=0.24334180355072021\n",
            "bi=100, loss=0.2185075581073761\n",
            "bi=100, loss=0.23542997241020203\n",
            "bi=100, loss=0.26074597239494324\n",
            "bi=100, loss=0.24709998071193695\n",
            "bi=110, loss=0.2299603521823883\n",
            "bi=110, loss=0.2856612801551819\n",
            "bi=110, loss=0.2675530016422272\n",
            "bi=110, loss=0.2548598647117615\n",
            "bi=110, loss=0.26617759466171265\n",
            "bi=110, loss=0.2486879527568817\n",
            "bi=110, loss=0.2672025263309479\n",
            "bi=110, loss=0.2734507620334625\n",
            "bi=120, loss=0.3537868559360504\n",
            "bi=120, loss=0.24038130044937134\n",
            "bi=120, loss=0.23530562222003937\n",
            "bi=120, loss=0.2872939705848694\n",
            "bi=120, loss=0.22753193974494934\n",
            "bi=120, loss=0.31520724296569824\n",
            "bi=120, loss=0.314231812953949\n",
            "bi=120, loss=0.23325882852077484\n",
            "bi=130, loss=0.293425977230072\n",
            "bi=130, loss=0.36708515882492065\n",
            "bi=130, loss=0.36010661721229553\n",
            "bi=130, loss=0.3120114803314209\n",
            "bi=130, loss=0.24453237652778625\n",
            "bi=130, loss=0.20833134651184082\n",
            "bi=130, loss=0.21262961626052856\n",
            "bi=130, loss=0.21034836769104004\n",
            "bi=140, loss=0.3189220726490021\n",
            "bi=140, loss=0.2058907300233841\n",
            "bi=140, loss=0.23682552576065063\n",
            "bi=140, loss=0.3139723837375641\n",
            "bi=140, loss=0.2924599349498749\n",
            "bi=140, loss=0.2513614892959595\n",
            "bi=140, loss=0.2464456409215927\n",
            "bi=140, loss=0.2777731716632843\n",
            "bi=150, loss=0.21577408909797668\n",
            "bi=150, loss=0.2463243305683136\n",
            "bi=150, loss=0.2589363157749176\n",
            "bi=150, loss=0.22865794599056244\n",
            "bi=150, loss=0.3052762448787689\n",
            "bi=150, loss=0.1724170744419098\n",
            "bi=150, loss=0.23892933130264282\n",
            "bi=150, loss=0.1966598480939865\n",
            "bi=160, loss=0.2511255741119385\n",
            "bi=160, loss=0.25069013237953186\n",
            "bi=160, loss=0.34580695629119873\n",
            "bi=160, loss=0.23670251667499542\n",
            "bi=160, loss=0.2539588510990143\n",
            "bi=160, loss=0.29344719648361206\n",
            "bi=160, loss=0.2140345722436905\n",
            "bi=160, loss=0.32473820447921753\n",
            "bi=170, loss=0.25851312279701233\n",
            "bi=170, loss=0.20313769578933716\n",
            "bi=170, loss=0.2553401291370392\n",
            "bi=170, loss=0.34723907709121704\n",
            "bi=170, loss=0.24661730229854584\n",
            "bi=170, loss=0.2929985523223877\n",
            "bi=170, loss=0.2660716772079468\n",
            "bi=170, loss=0.25401148200035095\n",
            "epoch = 7, spearman = 0.09467292624062576\n",
            "epoch = 7, spearman = 0.16121982404005655\n",
            "epoch = 7, spearman = 0.2983079703641993\n",
            "epoch = 7, spearman = 0.1377060745318193\n",
            "epoch = 7, spearman = 0.17151466495709755\n",
            "epoch = 7, spearman = 3.7007434154171884e-18\n",
            "epoch = 7, spearman = 0.28047678284004535\n",
            "epoch = 7, spearman = 0.14400656472357917\n",
            "bi=0, loss=0.2112998068332672\n",
            "bi=0, loss=0.24431060254573822\n",
            "bi=0, loss=0.23308944702148438\n",
            "bi=0, loss=0.23658719658851624\n",
            "bi=0, loss=0.20133322477340698\n",
            "bi=0, loss=0.2195587307214737\n",
            "bi=0, loss=0.1981179565191269\n",
            "bi=0, loss=0.2727651596069336\n",
            "bi=10, loss=0.2501734793186188\n",
            "bi=10, loss=0.1795257329940796\n",
            "bi=10, loss=0.28031229972839355\n",
            "bi=10, loss=0.30867794156074524\n",
            "bi=10, loss=0.2854519784450531\n",
            "bi=10, loss=0.3008114695549011\n",
            "bi=10, loss=0.21125559508800507\n",
            "bi=10, loss=0.1857614368200302\n",
            "bi=20, loss=0.22838307917118073\n",
            "bi=20, loss=0.21922951936721802\n",
            "bi=20, loss=0.20062461495399475\n",
            "bi=20, loss=0.3152157664299011\n",
            "bi=20, loss=0.31570637226104736\n",
            "bi=20, loss=0.22029468417167664\n",
            "bi=20, loss=0.22302600741386414\n",
            "bi=20, loss=0.28756749629974365\n",
            "bi=30, loss=0.24255265295505524\n",
            "bi=30, loss=0.2597993314266205\n",
            "bi=30, loss=0.40368905663490295\n",
            "bi=30, loss=0.17471913993358612\n",
            "bi=30, loss=0.23996463418006897\n",
            "bi=30, loss=0.25846725702285767\n",
            "bi=30, loss=0.24653305113315582\n",
            "bi=30, loss=0.19342803955078125\n",
            "bi=40, loss=0.2710554301738739\n",
            "bi=40, loss=0.3011723458766937\n",
            "bi=40, loss=0.20418471097946167\n",
            "bi=40, loss=0.29165494441986084\n",
            "bi=40, loss=0.2874964475631714\n",
            "bi=40, loss=0.3503643572330475\n",
            "bi=40, loss=0.45374050736427307\n",
            "bi=40, loss=0.25334516167640686\n",
            "bi=50, loss=0.22413888573646545\n",
            "bi=50, loss=0.30444759130477905\n",
            "bi=50, loss=0.33059531450271606\n",
            "bi=50, loss=0.3050082325935364\n",
            "bi=50, loss=0.21809372305870056\n",
            "bi=50, loss=0.3952641487121582\n",
            "bi=50, loss=0.23690706491470337\n",
            "bi=50, loss=0.25248241424560547\n",
            "bi=60, loss=0.3522106409072876\n",
            "bi=60, loss=0.2548178732395172\n",
            "bi=60, loss=0.18147654831409454\n",
            "bi=60, loss=0.1909569948911667\n",
            "bi=60, loss=0.22740979492664337\n",
            "bi=60, loss=0.27891436219215393\n",
            "bi=60, loss=0.22948069870471954\n",
            "bi=60, loss=0.17952193319797516\n",
            "bi=70, loss=0.24298202991485596\n",
            "bi=70, loss=0.30678969621658325\n",
            "bi=70, loss=0.23793567717075348\n",
            "bi=70, loss=0.33434948325157166\n",
            "bi=70, loss=0.2127666175365448\n",
            "bi=70, loss=0.19919072091579437\n",
            "bi=70, loss=0.2615184187889099\n",
            "bi=70, loss=0.3328806757926941\n",
            "bi=80, loss=0.21513301134109497\n",
            "bi=80, loss=0.23999467492103577\n",
            "bi=80, loss=0.2685040831565857\n",
            "bi=80, loss=0.16381049156188965\n",
            "bi=80, loss=0.21311677992343903\n",
            "bi=80, loss=0.22630298137664795\n",
            "bi=80, loss=0.1970115602016449\n",
            "bi=80, loss=0.22875051200389862\n",
            "bi=90, loss=0.2426467388868332\n",
            "bi=90, loss=0.2784580588340759\n",
            "bi=90, loss=0.35430482029914856\n",
            "bi=90, loss=0.20478665828704834\n",
            "bi=90, loss=0.21677587926387787\n",
            "bi=90, loss=0.2477864921092987\n",
            "bi=90, loss=0.2963240146636963\n",
            "bi=90, loss=0.21409593522548676\n",
            "bi=100, loss=0.26044273376464844\n",
            "bi=100, loss=0.2114829421043396\n",
            "bi=100, loss=0.20135001838207245\n",
            "bi=100, loss=0.24237297475337982\n",
            "bi=100, loss=0.19632674753665924\n",
            "bi=100, loss=0.18515940010547638\n",
            "bi=100, loss=0.23224717378616333\n",
            "bi=100, loss=0.26029881834983826\n",
            "bi=110, loss=0.23991091549396515\n",
            "bi=110, loss=0.2413962483406067\n",
            "bi=110, loss=0.2260180413722992\n",
            "bi=110, loss=0.26162204146385193\n",
            "bi=110, loss=0.2117437720298767\n",
            "bi=110, loss=0.23275388777256012\n",
            "bi=110, loss=0.18224148452281952\n",
            "bi=110, loss=0.2673946022987366\n",
            "bi=120, loss=0.18167217075824738\n",
            "bi=120, loss=0.21081671118736267\n",
            "bi=120, loss=0.2531605660915375\n",
            "bi=120, loss=0.19973032176494598\n",
            "bi=120, loss=0.29213136434555054\n",
            "bi=120, loss=0.2875799834728241\n",
            "bi=120, loss=0.3296067714691162\n",
            "bi=120, loss=0.25511881709098816\n",
            "bi=130, loss=0.2691470682621002\n",
            "bi=130, loss=0.19416336715221405\n",
            "bi=130, loss=0.23474209010601044\n",
            "bi=130, loss=0.40520092844963074\n",
            "bi=130, loss=0.240483358502388\n",
            "bi=130, loss=0.23737630248069763\n",
            "bi=130, loss=0.27117469906806946\n",
            "bi=130, loss=0.28290432691574097\n",
            "bi=140, loss=0.27314937114715576\n",
            "bi=140, loss=0.25732332468032837\n",
            "bi=140, loss=0.21979354321956635\n",
            "bi=140, loss=0.30809295177459717\n",
            "bi=140, loss=0.28318625688552856\n",
            "bi=140, loss=0.20480774343013763\n",
            "bi=140, loss=0.2480454444885254\n",
            "bi=140, loss=0.2693030536174774\n",
            "bi=150, loss=0.2019360363483429\n",
            "bi=150, loss=0.19642764329910278\n",
            "bi=150, loss=0.28875842690467834\n",
            "bi=150, loss=0.23730051517486572\n",
            "bi=150, loss=0.16524121165275574\n",
            "bi=150, loss=0.21007433533668518\n",
            "bi=150, loss=0.23602786660194397\n",
            "bi=150, loss=0.2605804204940796\n",
            "bi=160, loss=0.2179366499185562\n",
            "bi=160, loss=0.18804366886615753\n",
            "bi=160, loss=0.21210694313049316\n",
            "bi=160, loss=0.21269552409648895\n",
            "bi=160, loss=0.21332475543022156\n",
            "bi=160, loss=0.23885829746723175\n",
            "bi=160, loss=0.20418810844421387\n",
            "bi=160, loss=0.2806054353713989\n",
            "bi=170, loss=0.29449111223220825\n",
            "bi=170, loss=0.1959829479455948\n",
            "bi=170, loss=0.2541431784629822\n",
            "bi=170, loss=0.23238927125930786\n",
            "bi=170, loss=0.1976337879896164\n",
            "bi=170, loss=0.25850725173950195\n",
            "bi=170, loss=0.2163962423801422\n",
            "bi=170, loss=0.21195951104164124\n",
            "epoch = 8, spearman = 0.12909944487358055\n",
            "epoch = 8, spearman = 0.008606629658238699\n",
            "epoch = 8, spearman = -0.0046122789329576174\n",
            "epoch = 8, spearman = 0.10558569536534326\n",
            "epoch = 8, spearman = 0.20132890465709474\n",
            "epoch = 8, spearman = 0.24605026420709056\n",
            "epoch = 8, spearman = 0.19165199194773033\n",
            "epoch = 8, spearman = 0.15891368457357777\n",
            "bi=0, loss=0.18504345417022705\n",
            "bi=0, loss=0.1954350769519806\n",
            "bi=0, loss=0.24084964394569397\n",
            "bi=0, loss=0.1925109326839447\n",
            "bi=0, loss=0.25130486488342285\n",
            "bi=0, loss=0.2335362583398819\n",
            "bi=0, loss=0.20963647961616516\n",
            "bi=0, loss=0.2939285337924957\n",
            "bi=10, loss=0.25484633445739746\n",
            "bi=10, loss=0.31714335083961487\n",
            "bi=10, loss=0.2660658359527588\n",
            "bi=10, loss=0.2319125384092331\n",
            "bi=10, loss=0.1991809457540512\n",
            "bi=10, loss=0.23617301881313324\n",
            "bi=10, loss=0.3079279363155365\n",
            "bi=10, loss=0.14552928507328033\n",
            "bi=20, loss=0.21546153724193573\n",
            "bi=20, loss=0.3123108744621277\n",
            "bi=20, loss=0.16672873497009277\n",
            "bi=20, loss=0.3049074709415436\n",
            "bi=20, loss=0.22539648413658142\n",
            "bi=20, loss=0.20874957740306854\n",
            "bi=20, loss=0.15023724734783173\n",
            "bi=20, loss=0.2507045269012451\n",
            "bi=30, loss=0.28296229243278503\n",
            "bi=30, loss=0.19562213122844696\n",
            "bi=30, loss=0.24206291139125824\n",
            "bi=30, loss=0.2512415647506714\n",
            "bi=30, loss=0.14677052199840546\n",
            "bi=30, loss=0.18742600083351135\n",
            "bi=30, loss=0.3410198390483856\n",
            "bi=30, loss=0.23311035335063934\n",
            "bi=40, loss=0.30384597182273865\n",
            "bi=40, loss=0.20655012130737305\n",
            "bi=40, loss=0.22692859172821045\n",
            "bi=40, loss=0.3779292106628418\n",
            "bi=40, loss=0.2712419331073761\n",
            "bi=40, loss=0.2564907371997833\n",
            "bi=40, loss=0.30945053696632385\n",
            "bi=40, loss=0.22077739238739014\n",
            "bi=50, loss=0.15761904418468475\n",
            "bi=50, loss=0.24274283647537231\n",
            "bi=50, loss=0.34186673164367676\n",
            "bi=50, loss=0.26651206612586975\n",
            "bi=50, loss=0.28057926893234253\n",
            "bi=50, loss=0.2136349380016327\n",
            "bi=50, loss=0.32564622163772583\n",
            "bi=50, loss=0.23135188221931458\n",
            "bi=60, loss=0.2679612934589386\n",
            "bi=60, loss=0.15487737953662872\n",
            "bi=60, loss=0.19777846336364746\n",
            "bi=60, loss=0.32705098390579224\n",
            "bi=60, loss=0.2127714306116104\n",
            "bi=60, loss=0.13007457554340363\n",
            "bi=60, loss=0.17841248214244843\n",
            "bi=60, loss=0.19778446853160858\n",
            "bi=70, loss=0.17577874660491943\n",
            "bi=70, loss=0.32772624492645264\n",
            "bi=70, loss=0.2368231564760208\n",
            "bi=70, loss=0.35471463203430176\n",
            "bi=70, loss=0.24687276780605316\n",
            "bi=70, loss=0.23887327313423157\n",
            "bi=70, loss=0.27877119183540344\n",
            "bi=70, loss=0.23212110996246338\n",
            "bi=80, loss=0.19897012412548065\n",
            "bi=80, loss=0.253438264131546\n",
            "bi=80, loss=0.18764519691467285\n",
            "bi=80, loss=0.20317670702934265\n",
            "bi=80, loss=0.2134087085723877\n",
            "bi=80, loss=0.21969327330589294\n",
            "bi=80, loss=0.13643181324005127\n",
            "bi=80, loss=0.1626492589712143\n",
            "bi=90, loss=0.21606069803237915\n",
            "bi=90, loss=0.20232048630714417\n",
            "bi=90, loss=0.20627884566783905\n",
            "bi=90, loss=0.2655811905860901\n",
            "bi=90, loss=0.24425196647644043\n",
            "bi=90, loss=0.21867774426937103\n",
            "bi=90, loss=0.3016813397407532\n",
            "bi=90, loss=0.22027559578418732\n",
            "bi=100, loss=0.16763053834438324\n",
            "bi=100, loss=0.2373451441526413\n",
            "bi=100, loss=0.22333133220672607\n",
            "bi=100, loss=0.18373273313045502\n",
            "bi=100, loss=0.1624414026737213\n",
            "bi=100, loss=0.20092634856700897\n",
            "bi=100, loss=0.15922404825687408\n",
            "bi=100, loss=0.2344168722629547\n",
            "bi=110, loss=0.2060490846633911\n",
            "bi=110, loss=0.19551341235637665\n",
            "bi=110, loss=0.16505023837089539\n",
            "bi=110, loss=0.18831022083759308\n",
            "bi=110, loss=0.24520207941532135\n",
            "bi=110, loss=0.2652251124382019\n",
            "bi=110, loss=0.27546048164367676\n",
            "bi=110, loss=0.23593124747276306\n",
            "bi=120, loss=0.2373466044664383\n",
            "bi=120, loss=0.16235335171222687\n",
            "bi=120, loss=0.26200148463249207\n",
            "bi=120, loss=0.1750379502773285\n",
            "bi=120, loss=0.19448091089725494\n",
            "bi=120, loss=0.2519740164279938\n",
            "bi=120, loss=0.17294356226921082\n",
            "bi=120, loss=0.29988646507263184\n",
            "bi=130, loss=0.4370768368244171\n",
            "bi=130, loss=0.20075929164886475\n",
            "bi=130, loss=0.18364915251731873\n",
            "bi=130, loss=0.14903555810451508\n",
            "bi=130, loss=0.2557893991470337\n",
            "bi=130, loss=0.22363069653511047\n",
            "bi=130, loss=0.2656906843185425\n",
            "bi=130, loss=0.28494927287101746\n",
            "bi=140, loss=0.23206676542758942\n",
            "bi=140, loss=0.2031988501548767\n",
            "bi=140, loss=0.22228623926639557\n",
            "bi=140, loss=0.2439732551574707\n",
            "bi=140, loss=0.2755087614059448\n",
            "bi=140, loss=0.2806079685688019\n",
            "bi=140, loss=0.30739638209342957\n",
            "bi=140, loss=0.23007717728614807\n",
            "bi=150, loss=0.22014625370502472\n",
            "bi=150, loss=0.21660730242729187\n",
            "bi=150, loss=0.2578847110271454\n",
            "bi=150, loss=0.18904322385787964\n",
            "bi=150, loss=0.1862138956785202\n",
            "bi=150, loss=0.16868381202220917\n",
            "bi=150, loss=0.16784538328647614\n",
            "bi=150, loss=0.19299601018428802\n",
            "bi=160, loss=0.2072056531906128\n",
            "bi=160, loss=0.19462861120700836\n",
            "bi=160, loss=0.19170024991035461\n",
            "bi=160, loss=0.15986645221710205\n",
            "bi=160, loss=0.17853528261184692\n",
            "bi=160, loss=0.2691333591938019\n",
            "bi=160, loss=0.24989333748817444\n",
            "bi=160, loss=0.1985849142074585\n",
            "bi=170, loss=0.25961217284202576\n",
            "bi=170, loss=0.1598675400018692\n",
            "bi=170, loss=0.1420626938343048\n",
            "bi=170, loss=0.21551743149757385\n",
            "bi=170, loss=0.20092757046222687\n",
            "bi=170, loss=0.18031519651412964\n",
            "bi=170, loss=0.21328213810920715\n",
            "bi=170, loss=0.2236008495092392\n",
            "epoch = 9, spearman = 0.08837243604886585\n",
            "epoch = 9, spearman = 0.12909944487358058\n",
            "epoch = 9, spearman = 0.20363504412357356\n",
            "epoch = 9, spearman = 0.06255254707414974\n",
            "epoch = 9, spearman = 0.1618377522477331\n",
            "epoch = 9, spearman = 0.20132890465709471\n",
            "epoch = 9, spearman = -0.002306139466478807\n",
            "epoch = 9, spearman = 0.14170042525710033\n",
            "bi=0, loss=0.16733615100383759\n",
            "bi=0, loss=0.22174061834812164\n",
            "bi=0, loss=0.2285975217819214\n",
            "bi=0, loss=0.16183917224407196\n",
            "bi=0, loss=0.2173873484134674\n",
            "bi=0, loss=0.1920238584280014\n",
            "bi=0, loss=0.18106083571910858\n",
            "bi=0, loss=0.2307075709104538\n",
            "bi=10, loss=0.2766856551170349\n",
            "bi=10, loss=0.16836446523666382\n",
            "bi=10, loss=0.2000921368598938\n",
            "bi=10, loss=0.21028491854667664\n",
            "bi=10, loss=0.2564321756362915\n",
            "bi=10, loss=0.23129431903362274\n",
            "bi=10, loss=0.18638332188129425\n",
            "bi=10, loss=0.12143152207136154\n",
            "bi=20, loss=0.18732424080371857\n",
            "bi=20, loss=0.23095187544822693\n",
            "bi=20, loss=0.12953601777553558\n",
            "bi=20, loss=0.1800880879163742\n",
            "bi=20, loss=0.14787720143795013\n",
            "bi=20, loss=0.3271940350532532\n",
            "bi=20, loss=0.1677807867527008\n",
            "bi=20, loss=0.29372087121009827\n",
            "bi=30, loss=0.22233331203460693\n",
            "bi=30, loss=0.2128499299287796\n",
            "bi=30, loss=0.1768636405467987\n",
            "bi=30, loss=0.12431547790765762\n",
            "bi=30, loss=0.19235782325267792\n",
            "bi=30, loss=0.18550078570842743\n",
            "bi=30, loss=0.3220323622226715\n",
            "bi=30, loss=0.22617755830287933\n",
            "bi=40, loss=0.22200213372707367\n",
            "bi=40, loss=0.17980995774269104\n",
            "bi=40, loss=0.21937863528728485\n",
            "bi=40, loss=0.25077641010284424\n",
            "bi=40, loss=0.2666575014591217\n",
            "bi=40, loss=0.34006166458129883\n",
            "bi=40, loss=0.16654402017593384\n",
            "bi=40, loss=0.19217921793460846\n",
            "bi=50, loss=0.2617870569229126\n",
            "bi=50, loss=0.19837383925914764\n",
            "bi=50, loss=0.25564396381378174\n",
            "bi=50, loss=0.28358760476112366\n",
            "bi=50, loss=0.3500289022922516\n",
            "bi=50, loss=0.14118003845214844\n",
            "bi=50, loss=0.2325167953968048\n",
            "bi=50, loss=0.21086977422237396\n",
            "bi=60, loss=0.14541061222553253\n",
            "bi=60, loss=0.18515996634960175\n",
            "bi=60, loss=0.24214878678321838\n",
            "bi=60, loss=0.2195364236831665\n",
            "bi=60, loss=0.24280807375907898\n",
            "bi=60, loss=0.32077038288116455\n",
            "bi=60, loss=0.10896768420934677\n",
            "bi=60, loss=0.17086830735206604\n",
            "bi=70, loss=0.22365054488182068\n",
            "bi=70, loss=0.3780677616596222\n",
            "bi=70, loss=0.15319578349590302\n",
            "bi=70, loss=0.2284184992313385\n",
            "bi=70, loss=0.2804558277130127\n",
            "bi=70, loss=0.2510029673576355\n",
            "bi=70, loss=0.21114176511764526\n",
            "bi=70, loss=0.25298696756362915\n",
            "bi=80, loss=0.13929644227027893\n",
            "bi=80, loss=0.21316801011562347\n",
            "bi=80, loss=0.1861494481563568\n",
            "bi=80, loss=0.21214735507965088\n",
            "bi=80, loss=0.19149400293827057\n",
            "bi=80, loss=0.1788703352212906\n",
            "bi=80, loss=0.2077914923429489\n",
            "bi=80, loss=0.22047816216945648\n",
            "bi=90, loss=0.18761424720287323\n",
            "bi=90, loss=0.23506779968738556\n",
            "bi=90, loss=0.20396855473518372\n",
            "bi=90, loss=0.18154695630073547\n",
            "bi=90, loss=0.281758576631546\n",
            "bi=90, loss=0.2008664458990097\n",
            "bi=90, loss=0.203997403383255\n",
            "bi=90, loss=0.17845968902111053\n",
            "bi=100, loss=0.22036708891391754\n",
            "bi=100, loss=0.15878011286258698\n",
            "bi=100, loss=0.15664054453372955\n",
            "bi=100, loss=0.195633664727211\n",
            "bi=100, loss=0.1880074292421341\n",
            "bi=100, loss=0.16484439373016357\n",
            "bi=100, loss=0.20008529722690582\n",
            "bi=100, loss=0.14044146239757538\n",
            "bi=110, loss=0.14326757192611694\n",
            "bi=110, loss=0.2613426148891449\n",
            "bi=110, loss=0.2640262246131897\n",
            "bi=110, loss=0.21708039939403534\n",
            "bi=110, loss=0.16438913345336914\n",
            "bi=110, loss=0.16913366317749023\n",
            "bi=110, loss=0.251516729593277\n",
            "bi=110, loss=0.17804500460624695\n",
            "bi=120, loss=0.25445839762687683\n",
            "bi=120, loss=0.20748284459114075\n",
            "bi=120, loss=0.16323842108249664\n",
            "bi=120, loss=0.31982654333114624\n",
            "bi=120, loss=0.18508177995681763\n",
            "bi=120, loss=0.2096068561077118\n",
            "bi=120, loss=0.18425586819648743\n",
            "bi=120, loss=0.28034693002700806\n",
            "bi=130, loss=0.2170279324054718\n",
            "bi=130, loss=0.20826585590839386\n",
            "bi=130, loss=0.18998080492019653\n",
            "bi=130, loss=0.30647745728492737\n",
            "bi=130, loss=0.2589662969112396\n",
            "bi=130, loss=0.23569488525390625\n",
            "bi=130, loss=0.20542430877685547\n",
            "bi=130, loss=0.15976782143115997\n",
            "bi=140, loss=0.2381509691476822\n",
            "bi=140, loss=0.273574560880661\n",
            "bi=140, loss=0.20880798995494843\n",
            "bi=140, loss=0.17229552567005157\n",
            "bi=140, loss=0.2623634934425354\n",
            "bi=140, loss=0.27031540870666504\n",
            "bi=140, loss=0.21629570424556732\n",
            "bi=140, loss=0.1974480003118515\n",
            "bi=150, loss=0.17427559196949005\n",
            "bi=150, loss=0.21161210536956787\n",
            "bi=150, loss=0.1536177396774292\n",
            "bi=150, loss=0.17707423865795135\n",
            "bi=150, loss=0.16611891984939575\n",
            "bi=150, loss=0.20459073781967163\n",
            "bi=150, loss=0.190585196018219\n",
            "bi=150, loss=0.22586263716220856\n",
            "bi=160, loss=0.1746862381696701\n",
            "bi=160, loss=0.13991814851760864\n",
            "bi=160, loss=0.20179304480552673\n",
            "bi=160, loss=0.1889515370130539\n",
            "bi=160, loss=0.18372808396816254\n",
            "bi=160, loss=0.17550799250602722\n",
            "bi=160, loss=0.23706626892089844\n",
            "bi=160, loss=0.20541752874851227\n",
            "bi=170, loss=0.18784047663211823\n",
            "bi=170, loss=0.31703925132751465\n",
            "bi=170, loss=0.1950676441192627\n",
            "bi=170, loss=0.22317920625209808\n",
            "bi=170, loss=0.2051304578781128\n",
            "bi=170, loss=0.22802302241325378\n",
            "bi=170, loss=0.22669488191604614\n",
            "bi=170, loss=0.17333614826202393\n",
            "epoch = 10, spearman = 0.10558569536534326\n",
            "epoch = 10, spearman = 0.010912769124717519\n",
            "epoch = 10, spearman = 0.09467292624062575\n",
            "epoch = 10, spearman = 0.012600980383519792\n",
            "epoch = 10, spearman = 0.12510509414829948\n",
            "epoch = 10, spearman = 0.25758096153948457\n",
            "epoch = 10, spearman = 0.15430140564062012\n",
            "epoch = 10, spearman = 0.21055346252301\n",
            "bi=0, loss=0.1382170170545578\n",
            "bi=0, loss=0.1730073243379593\n",
            "bi=0, loss=0.23548419773578644\n",
            "bi=0, loss=0.24832750856876373\n",
            "bi=0, loss=0.16818781197071075\n",
            "bi=0, loss=0.24935348331928253\n",
            "bi=0, loss=0.22120556235313416\n",
            "bi=0, loss=0.18788497149944305\n",
            "bi=10, loss=0.1277046799659729\n",
            "bi=10, loss=0.16944582760334015\n",
            "bi=10, loss=0.3094157576560974\n",
            "bi=10, loss=0.27857452630996704\n",
            "bi=10, loss=0.2207481861114502\n",
            "bi=10, loss=0.12423205375671387\n",
            "bi=10, loss=0.22176417708396912\n",
            "bi=10, loss=0.15341918170452118\n",
            "bi=20, loss=0.18995730578899384\n",
            "bi=20, loss=0.2506603002548218\n",
            "bi=20, loss=0.11983150243759155\n",
            "bi=20, loss=0.19197089970111847\n",
            "bi=20, loss=0.153774231672287\n",
            "bi=20, loss=0.12245231866836548\n",
            "bi=20, loss=0.1890951246023178\n",
            "bi=20, loss=0.2638647258281708\n",
            "bi=30, loss=0.20800721645355225\n",
            "bi=30, loss=0.1828118860721588\n",
            "bi=30, loss=0.18670010566711426\n",
            "bi=30, loss=0.12818334996700287\n",
            "bi=30, loss=0.21099531650543213\n",
            "bi=30, loss=0.14409151673316956\n",
            "bi=30, loss=0.23768197000026703\n",
            "bi=30, loss=0.31141430139541626\n",
            "bi=40, loss=0.15020549297332764\n",
            "bi=40, loss=0.19839848577976227\n",
            "bi=40, loss=0.23129019141197205\n",
            "bi=40, loss=0.31987854838371277\n",
            "bi=40, loss=0.24320311844348907\n",
            "bi=40, loss=0.20511986315250397\n",
            "bi=40, loss=0.2386515587568283\n",
            "bi=40, loss=0.1534312665462494\n",
            "bi=50, loss=0.14944963157176971\n",
            "bi=50, loss=0.1923816055059433\n",
            "bi=50, loss=0.2559506893157959\n",
            "bi=50, loss=0.23461414873600006\n",
            "bi=50, loss=0.11307939141988754\n",
            "bi=50, loss=0.2703779339790344\n",
            "bi=50, loss=0.20642143487930298\n",
            "bi=50, loss=0.28218644857406616\n",
            "bi=60, loss=0.2599712908267975\n",
            "bi=60, loss=0.18004748225212097\n",
            "bi=60, loss=0.10162755101919174\n",
            "bi=60, loss=0.21259567141532898\n",
            "bi=60, loss=0.15820783376693726\n",
            "bi=60, loss=0.17590034008026123\n",
            "bi=60, loss=0.1884995698928833\n",
            "bi=60, loss=0.1937716156244278\n",
            "bi=70, loss=0.3023695647716522\n",
            "bi=70, loss=0.17174680531024933\n",
            "bi=70, loss=0.14621832966804504\n",
            "bi=70, loss=0.14845190942287445\n",
            "bi=70, loss=0.1573086977005005\n",
            "bi=70, loss=0.2557324767112732\n",
            "bi=70, loss=0.22957582771778107\n",
            "bi=70, loss=0.2625257074832916\n",
            "bi=80, loss=0.16309145092964172\n",
            "bi=80, loss=0.2065517157316208\n",
            "bi=80, loss=0.1230083703994751\n",
            "bi=80, loss=0.19736959040164948\n",
            "bi=80, loss=0.17513282597064972\n",
            "bi=80, loss=0.20441025495529175\n",
            "bi=80, loss=0.2029065489768982\n",
            "bi=80, loss=0.1824599951505661\n",
            "bi=90, loss=0.20559507608413696\n",
            "bi=90, loss=0.23781919479370117\n",
            "bi=90, loss=0.17263182997703552\n",
            "bi=90, loss=0.15880154073238373\n",
            "bi=90, loss=0.187278151512146\n",
            "bi=90, loss=0.16735167801380157\n",
            "bi=90, loss=0.16605789959430695\n",
            "bi=90, loss=0.22121205925941467\n",
            "bi=100, loss=0.16361278295516968\n",
            "bi=100, loss=0.14644744992256165\n",
            "bi=100, loss=0.170343816280365\n",
            "bi=100, loss=0.17284263670444489\n",
            "bi=100, loss=0.19156646728515625\n",
            "bi=100, loss=0.18372906744480133\n",
            "bi=100, loss=0.22281375527381897\n",
            "bi=100, loss=0.18942882120609283\n",
            "bi=110, loss=0.19593793153762817\n",
            "bi=110, loss=0.2221958339214325\n",
            "bi=110, loss=0.18070088326931\n",
            "bi=110, loss=0.11909347027540207\n",
            "bi=110, loss=0.1482778638601303\n",
            "bi=110, loss=0.23902487754821777\n",
            "bi=110, loss=0.18995343148708344\n",
            "bi=110, loss=0.22675201296806335\n",
            "bi=120, loss=0.1886235922574997\n",
            "bi=120, loss=0.16435988247394562\n",
            "bi=120, loss=0.15186621248722076\n",
            "bi=120, loss=0.17526327073574066\n",
            "bi=120, loss=0.20509302616119385\n",
            "bi=120, loss=0.11394292861223221\n",
            "bi=120, loss=0.20692555606365204\n",
            "bi=120, loss=0.19784188270568848\n",
            "bi=130, loss=0.2132790982723236\n",
            "bi=130, loss=0.1431836187839508\n",
            "bi=130, loss=0.2237800806760788\n",
            "bi=130, loss=0.1542390137910843\n",
            "bi=130, loss=0.22427411377429962\n",
            "bi=130, loss=0.19350583851337433\n",
            "bi=130, loss=0.14913342893123627\n",
            "bi=130, loss=0.2709292769432068\n",
            "bi=140, loss=0.2081441879272461\n",
            "bi=140, loss=0.24660083651542664\n",
            "bi=140, loss=0.17694693803787231\n",
            "bi=140, loss=0.2072768658399582\n",
            "bi=140, loss=0.23779700696468353\n",
            "bi=140, loss=0.17251981794834137\n",
            "bi=140, loss=0.15695856511592865\n",
            "bi=140, loss=0.17201197147369385\n",
            "bi=150, loss=0.16467797756195068\n",
            "bi=150, loss=0.18225862085819244\n",
            "bi=150, loss=0.14447985589504242\n",
            "bi=150, loss=0.18660838901996613\n",
            "bi=150, loss=0.21351252496242523\n",
            "bi=150, loss=0.14700140058994293\n",
            "bi=150, loss=0.1416121870279312\n",
            "bi=150, loss=0.18880018591880798\n",
            "bi=160, loss=0.15340273082256317\n",
            "bi=160, loss=0.16977882385253906\n",
            "bi=160, loss=0.1950896978378296\n",
            "bi=160, loss=0.17234618961811066\n",
            "bi=160, loss=0.17430813610553741\n",
            "bi=160, loss=0.12476056814193726\n",
            "bi=160, loss=0.17580100893974304\n",
            "bi=160, loss=0.166040301322937\n",
            "bi=170, loss=0.1627972424030304\n",
            "bi=170, loss=0.14494337141513824\n",
            "bi=170, loss=0.18658410012722015\n",
            "bi=170, loss=0.19541752338409424\n",
            "bi=170, loss=0.16204454004764557\n",
            "bi=170, loss=0.16748051345348358\n",
            "bi=170, loss=0.15434713661670685\n",
            "bi=170, loss=0.16636008024215698\n",
            "epoch = 11, spearman = 0.20824732305653118\n",
            "epoch = 11, spearman = 0.12909944487358058\n",
            "epoch = 11, spearman = 0.06255254707414974\n",
            "epoch = 11, spearman = 0.07115917673238846\n",
            "epoch = 11, spearman = -0.004612278932957622\n",
            "epoch = 11, spearman = 0.21685395271476987\n",
            "epoch = 11, spearman = 0.16920852549061877\n",
            "epoch = 11, spearman = 0.21055346252301\n",
            "bi=0, loss=0.11027519404888153\n",
            "bi=0, loss=0.12380371987819672\n",
            "bi=0, loss=0.1641581952571869\n",
            "bi=0, loss=0.17394320666790009\n",
            "bi=0, loss=0.1312946081161499\n",
            "bi=0, loss=0.13740842044353485\n",
            "bi=0, loss=0.1364711970090866\n",
            "bi=0, loss=0.19072850048542023\n",
            "bi=10, loss=0.10378279536962509\n",
            "bi=10, loss=0.1407376527786255\n",
            "bi=10, loss=0.18726582825183868\n",
            "bi=10, loss=0.17334310710430145\n",
            "bi=10, loss=0.20954003930091858\n",
            "bi=10, loss=0.19819499552249908\n",
            "bi=10, loss=0.17768630385398865\n",
            "bi=10, loss=0.13713377714157104\n",
            "bi=20, loss=0.22492343187332153\n",
            "bi=20, loss=0.11627849191427231\n",
            "bi=20, loss=0.2049780637025833\n",
            "bi=20, loss=0.1611911654472351\n",
            "bi=20, loss=0.26800113916397095\n",
            "bi=20, loss=0.17608022689819336\n",
            "bi=20, loss=0.09889204800128937\n",
            "bi=20, loss=0.17596407234668732\n",
            "bi=30, loss=0.1591065227985382\n",
            "bi=30, loss=0.14831003546714783\n",
            "bi=30, loss=0.11418567597866058\n",
            "bi=30, loss=0.14150765538215637\n",
            "bi=30, loss=0.22188334167003632\n",
            "bi=30, loss=0.1467284858226776\n",
            "bi=30, loss=0.16403517127037048\n",
            "bi=30, loss=0.3289717435836792\n",
            "bi=40, loss=0.1664448380470276\n",
            "bi=40, loss=0.1457865685224533\n",
            "bi=40, loss=0.22185549139976501\n",
            "bi=40, loss=0.1809118688106537\n",
            "bi=40, loss=0.21408763527870178\n",
            "bi=40, loss=0.23955275118350983\n",
            "bi=40, loss=0.2072332501411438\n",
            "bi=40, loss=0.16193567216396332\n",
            "bi=50, loss=0.22083278000354767\n",
            "bi=50, loss=0.2136419415473938\n",
            "bi=50, loss=0.22884580492973328\n",
            "bi=50, loss=0.13499756157398224\n",
            "bi=50, loss=0.28021663427352905\n",
            "bi=50, loss=0.23641125857830048\n",
            "bi=50, loss=0.115355484187603\n",
            "bi=50, loss=0.17561475932598114\n",
            "bi=60, loss=0.1274753212928772\n",
            "bi=60, loss=0.18503445386886597\n",
            "bi=60, loss=0.14565818011760712\n",
            "bi=60, loss=0.091148741543293\n",
            "bi=60, loss=0.2074202299118042\n",
            "bi=60, loss=0.13616521656513214\n",
            "bi=60, loss=0.2023562490940094\n",
            "bi=60, loss=0.1483946591615677\n",
            "bi=70, loss=0.12196042388677597\n",
            "bi=70, loss=0.18163834512233734\n",
            "bi=70, loss=0.1956605315208435\n",
            "bi=70, loss=0.1993829607963562\n",
            "bi=70, loss=0.12610439956188202\n",
            "bi=70, loss=0.11252287030220032\n",
            "bi=70, loss=0.143068328499794\n",
            "bi=70, loss=0.21858035027980804\n",
            "bi=80, loss=0.19023211300373077\n",
            "bi=80, loss=0.10822215676307678\n",
            "bi=80, loss=0.1474057137966156\n",
            "bi=80, loss=0.17148980498313904\n",
            "bi=80, loss=0.13832485675811768\n",
            "bi=80, loss=0.12103879451751709\n",
            "bi=80, loss=0.13602781295776367\n",
            "bi=80, loss=0.1696544885635376\n",
            "bi=90, loss=0.23713019490242004\n",
            "bi=90, loss=0.20862449705600739\n",
            "bi=90, loss=0.15401498973369598\n",
            "bi=90, loss=0.13896751403808594\n",
            "bi=90, loss=0.16561879217624664\n",
            "bi=90, loss=0.1571548879146576\n",
            "bi=90, loss=0.14727754890918732\n",
            "bi=90, loss=0.16516971588134766\n",
            "bi=100, loss=0.12124902755022049\n",
            "bi=100, loss=0.16409511864185333\n",
            "bi=100, loss=0.1523493528366089\n",
            "bi=100, loss=0.1802038550376892\n",
            "bi=100, loss=0.18109512329101562\n",
            "bi=100, loss=0.1318659484386444\n",
            "bi=100, loss=0.19162563979625702\n",
            "bi=100, loss=0.200456902384758\n",
            "bi=110, loss=0.15836744010448456\n",
            "bi=110, loss=0.12355882674455643\n",
            "bi=110, loss=0.16655613481998444\n",
            "bi=110, loss=0.1954277753829956\n",
            "bi=110, loss=0.1959097981452942\n",
            "bi=110, loss=0.19704096019268036\n",
            "bi=110, loss=0.15803779661655426\n",
            "bi=110, loss=0.15715129673480988\n",
            "bi=120, loss=0.13912229239940643\n",
            "bi=120, loss=0.18703021109104156\n",
            "bi=120, loss=0.19047388434410095\n",
            "bi=120, loss=0.10751820355653763\n",
            "bi=120, loss=0.16497549414634705\n",
            "bi=120, loss=0.11723174899816513\n",
            "bi=120, loss=0.13757096230983734\n",
            "bi=120, loss=0.16713227331638336\n",
            "bi=130, loss=0.21759375929832458\n",
            "bi=130, loss=0.12413856387138367\n",
            "bi=130, loss=0.11414562165737152\n",
            "bi=130, loss=0.14364762604236603\n",
            "bi=130, loss=0.16550640761852264\n",
            "bi=130, loss=0.1718224436044693\n",
            "bi=130, loss=0.1852838099002838\n",
            "bi=130, loss=0.13844966888427734\n",
            "bi=140, loss=0.14330942928791046\n",
            "bi=140, loss=0.1167539581656456\n",
            "bi=140, loss=0.1879643201828003\n",
            "bi=140, loss=0.1315658986568451\n",
            "bi=140, loss=0.2107887715101242\n",
            "bi=140, loss=0.15229405462741852\n",
            "bi=140, loss=0.1431550234556198\n",
            "bi=140, loss=0.16902227699756622\n",
            "bi=150, loss=0.1417342573404312\n",
            "bi=150, loss=0.17124751210212708\n",
            "bi=150, loss=0.1374722272157669\n",
            "bi=150, loss=0.12556761503219604\n",
            "bi=150, loss=0.19806990027427673\n",
            "bi=150, loss=0.17161494493484497\n",
            "bi=150, loss=0.16296164691448212\n",
            "bi=150, loss=0.12920086085796356\n",
            "bi=160, loss=0.14307771623134613\n",
            "bi=160, loss=0.17430835962295532\n",
            "bi=160, loss=0.17574511468410492\n",
            "bi=160, loss=0.1468208134174347\n",
            "bi=160, loss=0.1650424301624298\n",
            "bi=160, loss=0.15324513614177704\n",
            "bi=160, loss=0.19498330354690552\n",
            "bi=160, loss=0.1709214150905609\n",
            "bi=170, loss=0.1104477047920227\n",
            "bi=170, loss=0.19099992513656616\n",
            "bi=170, loss=0.17946994304656982\n",
            "bi=170, loss=0.1430901736021042\n",
            "bi=170, loss=0.1335209310054779\n",
            "bi=170, loss=0.1312791258096695\n",
            "bi=170, loss=0.16435325145721436\n",
            "bi=170, loss=0.16717524826526642\n",
            "epoch = 12, spearman = 0.02581988897471611\n",
            "epoch = 12, spearman = 0.12909944487358058\n",
            "epoch = 12, spearman = 0.11588053628238423\n",
            "epoch = 12, spearman = -0.019519398782956218\n",
            "epoch = 12, spearman = 0.2065591117977289\n",
            "epoch = 12, spearman = 0.22315444290652975\n",
            "epoch = 12, spearman = 0.1818095058741385\n",
            "epoch = 12, spearman = 0.21055346252301\n",
            "bi=0, loss=0.1544865071773529\n",
            "bi=0, loss=0.13523000478744507\n",
            "bi=0, loss=0.10165303945541382\n",
            "bi=0, loss=0.18934419751167297\n",
            "bi=0, loss=0.09826858341693878\n",
            "bi=0, loss=0.13811028003692627\n",
            "bi=0, loss=0.12693719565868378\n",
            "bi=0, loss=0.16516147553920746\n",
            "bi=10, loss=0.14115867018699646\n",
            "bi=10, loss=0.17605872452259064\n",
            "bi=10, loss=0.20643463730812073\n",
            "bi=10, loss=0.13843579590320587\n",
            "bi=10, loss=0.07944457232952118\n",
            "bi=10, loss=0.12793497741222382\n",
            "bi=10, loss=0.14761517941951752\n",
            "bi=10, loss=0.174162819981575\n",
            "bi=20, loss=0.09250849485397339\n",
            "bi=20, loss=0.14318332076072693\n",
            "bi=20, loss=0.2037307471036911\n",
            "bi=20, loss=0.1067308560013771\n",
            "bi=20, loss=0.15510539710521698\n",
            "bi=20, loss=0.1144346296787262\n",
            "bi=20, loss=0.19690406322479248\n",
            "bi=20, loss=0.1995629072189331\n",
            "bi=30, loss=0.1458919793367386\n",
            "bi=30, loss=0.2286331206560135\n",
            "bi=30, loss=0.11213993281126022\n",
            "bi=30, loss=0.13074257969856262\n",
            "bi=30, loss=0.17466208338737488\n",
            "bi=30, loss=0.16817481815814972\n",
            "bi=30, loss=0.14922772347927094\n",
            "bi=30, loss=0.09791821241378784\n",
            "bi=40, loss=0.14192059636116028\n",
            "bi=40, loss=0.20023544132709503\n",
            "bi=40, loss=0.20487259328365326\n",
            "bi=40, loss=0.21135710179805756\n",
            "bi=40, loss=0.12214667350053787\n",
            "bi=40, loss=0.1341048628091812\n",
            "bi=40, loss=0.17067594826221466\n",
            "bi=40, loss=0.21046067774295807\n",
            "bi=50, loss=0.19955497980117798\n",
            "bi=50, loss=0.15447454154491425\n",
            "bi=50, loss=0.18537449836730957\n",
            "bi=50, loss=0.21229678392410278\n",
            "bi=50, loss=0.13258567452430725\n",
            "bi=50, loss=0.14801715314388275\n",
            "bi=50, loss=0.09920287877321243\n",
            "bi=50, loss=0.20139583945274353\n",
            "bi=60, loss=0.10612114518880844\n",
            "bi=60, loss=0.2024499475955963\n",
            "bi=60, loss=0.13766522705554962\n",
            "bi=60, loss=0.07712464034557343\n",
            "bi=60, loss=0.1695246398448944\n",
            "bi=60, loss=0.12011066824197769\n",
            "bi=60, loss=0.1547556221485138\n",
            "bi=60, loss=0.22089508175849915\n",
            "bi=70, loss=0.2278641313314438\n",
            "bi=70, loss=0.1745782345533371\n",
            "bi=70, loss=0.17036330699920654\n",
            "bi=70, loss=0.1122049018740654\n",
            "bi=70, loss=0.1658632755279541\n",
            "bi=70, loss=0.08467298746109009\n",
            "bi=70, loss=0.11563535034656525\n",
            "bi=70, loss=0.15759189426898956\n",
            "bi=80, loss=0.1586841195821762\n",
            "bi=80, loss=0.13337072730064392\n",
            "bi=80, loss=0.11804567277431488\n",
            "bi=80, loss=0.12420154362916946\n",
            "bi=80, loss=0.1281987726688385\n",
            "bi=80, loss=0.166697695851326\n",
            "bi=80, loss=0.13138605654239655\n",
            "bi=80, loss=0.10323924571275711\n",
            "bi=90, loss=0.14053376019001007\n",
            "bi=90, loss=0.15570591390132904\n",
            "bi=90, loss=0.09477823972702026\n",
            "bi=90, loss=0.12165180593729019\n",
            "bi=90, loss=0.10769031941890717\n",
            "bi=90, loss=0.14545950293540955\n",
            "bi=90, loss=0.1479388028383255\n",
            "bi=90, loss=0.2176946997642517\n",
            "bi=100, loss=0.1335391402244568\n",
            "bi=100, loss=0.12065663188695908\n",
            "bi=100, loss=0.12720099091529846\n",
            "bi=100, loss=0.09746381640434265\n",
            "bi=100, loss=0.09661824256181717\n",
            "bi=100, loss=0.14647823572158813\n",
            "bi=100, loss=0.13837547600269318\n",
            "bi=100, loss=0.16620156168937683\n",
            "bi=110, loss=0.17615282535552979\n",
            "bi=110, loss=0.1284732073545456\n",
            "bi=110, loss=0.0894600972533226\n",
            "bi=110, loss=0.14291508495807648\n",
            "bi=110, loss=0.13241910934448242\n",
            "bi=110, loss=0.14803040027618408\n",
            "bi=110, loss=0.17172886431217194\n",
            "bi=110, loss=0.10380575060844421\n",
            "bi=120, loss=0.18310463428497314\n",
            "bi=120, loss=0.13953740894794464\n",
            "bi=120, loss=0.11199728399515152\n",
            "bi=120, loss=0.10737615823745728\n",
            "bi=120, loss=0.14255736768245697\n",
            "bi=120, loss=0.10416131466627121\n",
            "bi=120, loss=0.16453592479228973\n",
            "bi=120, loss=0.11194654554128647\n",
            "bi=130, loss=0.11113680154085159\n",
            "bi=130, loss=0.16461479663848877\n",
            "bi=130, loss=0.17601153254508972\n",
            "bi=130, loss=0.11099688708782196\n",
            "bi=130, loss=0.14280888438224792\n",
            "bi=130, loss=0.10518133640289307\n",
            "bi=130, loss=0.09785664081573486\n",
            "bi=130, loss=0.16994941234588623\n",
            "bi=140, loss=0.12275589257478714\n",
            "bi=140, loss=0.16168391704559326\n",
            "bi=140, loss=0.14415380358695984\n",
            "bi=140, loss=0.13620895147323608\n",
            "bi=140, loss=0.1961437612771988\n",
            "bi=140, loss=0.15267314016819\n",
            "bi=140, loss=0.21457068622112274\n",
            "bi=140, loss=0.14002342522144318\n",
            "bi=150, loss=0.12118186801671982\n",
            "bi=150, loss=0.13157439231872559\n",
            "bi=150, loss=0.1525236815214157\n",
            "bi=150, loss=0.10022762417793274\n",
            "bi=150, loss=0.12329910695552826\n",
            "bi=150, loss=0.19918805360794067\n",
            "bi=150, loss=0.13826504349708557\n",
            "bi=150, loss=0.1354323774576187\n",
            "bi=160, loss=0.17112210392951965\n",
            "bi=160, loss=0.12235667556524277\n",
            "bi=160, loss=0.15496759116649628\n",
            "bi=160, loss=0.11438668519258499\n",
            "bi=160, loss=0.09024067223072052\n",
            "bi=160, loss=0.10798335820436478\n",
            "bi=160, loss=0.14259113371372223\n",
            "bi=160, loss=0.12524756789207458\n",
            "bi=170, loss=0.12032455205917358\n",
            "bi=170, loss=0.07903013378381729\n",
            "bi=170, loss=0.13909149169921875\n",
            "bi=170, loss=0.11534193903207779\n",
            "bi=170, loss=0.12379556149244308\n",
            "bi=170, loss=0.13931505382061005\n",
            "bi=170, loss=0.13393911719322205\n",
            "bi=170, loss=0.09134586900472641\n",
            "epoch = 13, spearman = 0.09467292624062575\n",
            "epoch = 13, spearman = 0.11588053628238423\n",
            "epoch = 13, spearman = 0.032120379166476004\n",
            "epoch = 13, spearman = 0.10958004609062434\n",
            "epoch = 13, spearman = 0.11250411376477969\n",
            "epoch = 13, spearman = 0.23806156275652832\n",
            "epoch = 13, spearman = 0.1841156453406173\n",
            "epoch = 13, spearman = 0.17612694389005515\n",
            "bi=0, loss=0.0640469565987587\n",
            "bi=0, loss=0.09952760487794876\n",
            "bi=0, loss=0.10014909505844116\n",
            "bi=0, loss=0.13836845755577087\n",
            "bi=0, loss=0.1316595822572708\n",
            "bi=0, loss=0.10049208253622055\n",
            "bi=0, loss=0.11065590381622314\n",
            "bi=0, loss=0.14661329984664917\n",
            "bi=10, loss=0.1341560184955597\n",
            "bi=10, loss=0.13843782246112823\n",
            "bi=10, loss=0.19212469458580017\n",
            "bi=10, loss=0.1344800889492035\n",
            "bi=10, loss=0.08057478815317154\n",
            "bi=10, loss=0.18674568831920624\n",
            "bi=10, loss=0.09348169714212418\n",
            "bi=10, loss=0.1443382352590561\n",
            "bi=20, loss=0.12514911592006683\n",
            "bi=20, loss=0.0719624012708664\n",
            "bi=20, loss=0.15920226275920868\n",
            "bi=20, loss=0.16805000603199005\n",
            "bi=20, loss=0.1528865545988083\n",
            "bi=20, loss=0.08369915932416916\n",
            "bi=20, loss=0.12531514465808868\n",
            "bi=20, loss=0.08411074429750443\n",
            "bi=30, loss=0.11291752010583878\n",
            "bi=30, loss=0.13999198377132416\n",
            "bi=30, loss=0.10198589414358139\n",
            "bi=30, loss=0.09941117465496063\n",
            "bi=30, loss=0.08527103811502457\n",
            "bi=30, loss=0.25419360399246216\n",
            "bi=30, loss=0.14644405245780945\n",
            "bi=30, loss=0.08166000247001648\n",
            "bi=40, loss=0.19900262355804443\n",
            "bi=40, loss=0.19595547020435333\n",
            "bi=40, loss=0.12437453120946884\n",
            "bi=40, loss=0.1560160517692566\n",
            "bi=40, loss=0.11407367885112762\n",
            "bi=40, loss=0.13571374118328094\n",
            "bi=40, loss=0.09105759859085083\n",
            "bi=40, loss=0.11848630011081696\n",
            "bi=50, loss=0.07259991765022278\n",
            "bi=50, loss=0.12603335082530975\n",
            "bi=50, loss=0.1879735141992569\n",
            "bi=50, loss=0.14303456246852875\n",
            "bi=50, loss=0.1441241204738617\n",
            "bi=50, loss=0.2246120274066925\n",
            "bi=50, loss=0.16002236306667328\n",
            "bi=50, loss=0.16884452104568481\n",
            "bi=60, loss=0.08667971938848495\n",
            "bi=60, loss=0.08716581761837006\n",
            "bi=60, loss=0.15820133686065674\n",
            "bi=60, loss=0.06650838255882263\n",
            "bi=60, loss=0.14294081926345825\n",
            "bi=60, loss=0.10044459253549576\n",
            "bi=60, loss=0.153604194521904\n",
            "bi=60, loss=0.09726471453905106\n",
            "bi=70, loss=0.10752995312213898\n",
            "bi=70, loss=0.12096595019102097\n",
            "bi=70, loss=0.07786513864994049\n",
            "bi=70, loss=0.1602342575788498\n",
            "bi=70, loss=0.16268722712993622\n",
            "bi=70, loss=0.15273956954479218\n",
            "bi=70, loss=0.10789015144109726\n",
            "bi=70, loss=0.196571946144104\n",
            "bi=80, loss=0.12484408169984818\n",
            "bi=80, loss=0.13218866288661957\n",
            "bi=80, loss=0.10239808261394501\n",
            "bi=80, loss=0.10561949014663696\n",
            "bi=80, loss=0.11245439201593399\n",
            "bi=80, loss=0.09391950815916061\n",
            "bi=80, loss=0.08587352931499481\n",
            "bi=80, loss=0.1346389353275299\n",
            "bi=90, loss=0.14395876228809357\n",
            "bi=90, loss=0.15044274926185608\n",
            "bi=90, loss=0.10412156581878662\n",
            "bi=90, loss=0.14031004905700684\n",
            "bi=90, loss=0.09974627941846848\n",
            "bi=90, loss=0.10089410841464996\n",
            "bi=90, loss=0.09448353946208954\n",
            "bi=90, loss=0.08307001739740372\n",
            "bi=100, loss=0.08309391885995865\n",
            "bi=100, loss=0.09617820382118225\n",
            "bi=100, loss=0.09689687937498093\n",
            "bi=100, loss=0.10455198585987091\n",
            "bi=100, loss=0.13251902163028717\n",
            "bi=100, loss=0.1280192881822586\n",
            "bi=100, loss=0.10475458204746246\n",
            "bi=100, loss=0.07284805178642273\n",
            "bi=110, loss=0.10442786663770676\n",
            "bi=110, loss=0.12473513931035995\n",
            "bi=110, loss=0.09786136448383331\n",
            "bi=110, loss=0.13845320045948029\n",
            "bi=110, loss=0.1565598100423813\n",
            "bi=110, loss=0.0727400928735733\n",
            "bi=110, loss=0.09631001204252243\n",
            "bi=110, loss=0.11060851067304611\n",
            "bi=120, loss=0.0940883457660675\n",
            "bi=120, loss=0.12435957789421082\n",
            "bi=120, loss=0.10732085257768631\n",
            "bi=120, loss=0.10617178678512573\n",
            "bi=120, loss=0.09174331277608871\n",
            "bi=120, loss=0.09886505454778671\n",
            "bi=120, loss=0.1445464938879013\n",
            "bi=120, loss=0.1661105453968048\n",
            "bi=130, loss=0.1392972320318222\n",
            "bi=130, loss=0.1952430158853531\n",
            "bi=130, loss=0.1501999944448471\n",
            "bi=130, loss=0.09003991633653641\n",
            "bi=130, loss=0.07020815461874008\n",
            "bi=130, loss=0.10299904644489288\n",
            "bi=130, loss=0.1771591603755951\n",
            "bi=130, loss=0.10296948999166489\n",
            "bi=140, loss=0.08951602131128311\n",
            "bi=140, loss=0.10999834537506104\n",
            "bi=140, loss=0.142257958650589\n",
            "bi=140, loss=0.12986353039741516\n",
            "bi=140, loss=0.08324100822210312\n",
            "bi=140, loss=0.10195109248161316\n",
            "bi=140, loss=0.18046708405017853\n",
            "bi=140, loss=0.09743120521306992\n",
            "bi=150, loss=0.15151768922805786\n",
            "bi=150, loss=0.11809588223695755\n",
            "bi=150, loss=0.09729224443435669\n",
            "bi=150, loss=0.09779238700866699\n",
            "bi=150, loss=0.09826400876045227\n",
            "bi=150, loss=0.104405477643013\n",
            "bi=150, loss=0.10753845423460007\n",
            "bi=150, loss=0.0921521931886673\n",
            "bi=160, loss=0.1098715141415596\n",
            "bi=160, loss=0.11050975322723389\n",
            "bi=160, loss=0.1271161288022995\n",
            "bi=160, loss=0.1054418683052063\n",
            "bi=160, loss=0.09249070286750793\n",
            "bi=160, loss=0.14659345149993896\n",
            "bi=160, loss=0.08338792622089386\n",
            "bi=160, loss=0.13092197477817535\n",
            "bi=170, loss=0.1060776636004448\n",
            "bi=170, loss=0.09649661928415298\n",
            "bi=170, loss=0.11587369441986084\n",
            "bi=170, loss=0.12066242843866348\n",
            "bi=170, loss=0.09301712363958359\n",
            "bi=170, loss=0.1233605295419693\n",
            "bi=170, loss=0.06243685260415077\n",
            "bi=170, loss=0.10525775700807571\n",
            "epoch = 14, spearman = 0.11188618555710315\n",
            "epoch = 14, spearman = 0.12049281521534186\n",
            "epoch = 14, spearman = 0.24036770222300718\n",
            "epoch = 14, spearman = 0.11588053628238425\n",
            "epoch = 14, spearman = 0.12679330540710174\n",
            "epoch = 14, spearman = 0.2065591117977289\n",
            "epoch = 14, spearman = 0.19671662572413712\n",
            "epoch = 14, spearman = 0.17612694389005515\n",
            "bi=0, loss=0.09156931936740875\n",
            "bi=0, loss=0.0810982882976532\n",
            "bi=0, loss=0.12865112721920013\n",
            "bi=0, loss=0.07803569734096527\n",
            "bi=0, loss=0.11762060225009918\n",
            "bi=0, loss=0.08738045394420624\n",
            "bi=0, loss=0.11018125712871552\n",
            "bi=0, loss=0.12546195089817047\n",
            "bi=10, loss=0.0988100990653038\n",
            "bi=10, loss=0.15848220884799957\n",
            "bi=10, loss=0.10749081522226334\n",
            "bi=10, loss=0.1392325460910797\n",
            "bi=10, loss=0.0992874875664711\n",
            "bi=10, loss=0.09559649229049683\n",
            "bi=10, loss=0.0999869853258133\n",
            "bi=10, loss=0.06233969330787659\n",
            "bi=20, loss=0.04841136559844017\n",
            "bi=20, loss=0.07767664641141891\n",
            "bi=20, loss=0.12608659267425537\n",
            "bi=20, loss=0.07742224633693695\n",
            "bi=20, loss=0.12984931468963623\n",
            "bi=20, loss=0.10242358595132828\n",
            "bi=20, loss=0.10020887851715088\n",
            "bi=20, loss=0.1457774043083191\n",
            "bi=30, loss=0.06896904110908508\n",
            "bi=30, loss=0.11795294284820557\n",
            "bi=30, loss=0.08071326464414597\n",
            "bi=30, loss=0.08922021090984344\n",
            "bi=30, loss=0.1402253359556198\n",
            "bi=30, loss=0.08718342334032059\n",
            "bi=30, loss=0.2888220250606537\n",
            "bi=30, loss=0.12403116375207901\n",
            "bi=40, loss=0.12700530886650085\n",
            "bi=40, loss=0.06798839569091797\n",
            "bi=40, loss=0.09888926148414612\n",
            "bi=40, loss=0.12644687294960022\n",
            "bi=40, loss=0.17063239216804504\n",
            "bi=40, loss=0.10809498280286789\n",
            "bi=40, loss=0.17903009057044983\n",
            "bi=40, loss=0.09720674157142639\n",
            "bi=50, loss=0.10926306992769241\n",
            "bi=50, loss=0.16181232035160065\n",
            "bi=50, loss=0.10045725852251053\n",
            "bi=50, loss=0.1709650605916977\n",
            "bi=50, loss=0.06370585411787033\n",
            "bi=50, loss=0.1522524654865265\n",
            "bi=50, loss=0.11871165037155151\n",
            "bi=50, loss=0.1464391052722931\n",
            "bi=60, loss=0.06974727660417557\n",
            "bi=60, loss=0.12024842947721481\n",
            "bi=60, loss=0.1026700884103775\n",
            "bi=60, loss=0.06446263194084167\n",
            "bi=60, loss=0.056700315326452255\n",
            "bi=60, loss=0.0483032651245594\n",
            "bi=60, loss=0.07233782857656479\n",
            "bi=60, loss=0.124130018055439\n",
            "bi=70, loss=0.08642368763685226\n",
            "bi=70, loss=0.046019960194826126\n",
            "bi=70, loss=0.07242938876152039\n",
            "bi=70, loss=0.08736054599285126\n",
            "bi=70, loss=0.13095365464687347\n",
            "bi=70, loss=0.1284535676240921\n",
            "bi=70, loss=0.1373295783996582\n",
            "bi=70, loss=0.09330350160598755\n",
            "bi=80, loss=0.07629754394292831\n",
            "bi=80, loss=0.08480048179626465\n",
            "bi=80, loss=0.11379285156726837\n",
            "bi=80, loss=0.09386459738016129\n",
            "bi=80, loss=0.06719301640987396\n",
            "bi=80, loss=0.10003934800624847\n",
            "bi=80, loss=0.07588811963796616\n",
            "bi=80, loss=0.10725737363100052\n",
            "bi=90, loss=0.12391296029090881\n",
            "bi=90, loss=0.08665753901004791\n",
            "bi=90, loss=0.09842915087938309\n",
            "bi=90, loss=0.09307203441858292\n",
            "bi=90, loss=0.07796141505241394\n",
            "bi=90, loss=0.08329617977142334\n",
            "bi=90, loss=0.07147516310214996\n",
            "bi=90, loss=0.12716849148273468\n",
            "bi=100, loss=0.11301426589488983\n",
            "bi=100, loss=0.06548353284597397\n",
            "bi=100, loss=0.09118258953094482\n",
            "bi=100, loss=0.09438490122556686\n",
            "bi=100, loss=0.07510200887918472\n",
            "bi=100, loss=0.06491509079933167\n",
            "bi=100, loss=0.09533600509166718\n",
            "bi=100, loss=0.07698136568069458\n",
            "bi=110, loss=0.06741563975811005\n",
            "bi=110, loss=0.1206379160284996\n",
            "bi=110, loss=0.07766411453485489\n",
            "bi=110, loss=0.08548398315906525\n",
            "bi=110, loss=0.06562775373458862\n",
            "bi=110, loss=0.10075511038303375\n",
            "bi=110, loss=0.09895515441894531\n",
            "bi=110, loss=0.09189549088478088\n",
            "bi=120, loss=0.06813759356737137\n",
            "bi=120, loss=0.07072272151708603\n",
            "bi=120, loss=0.1228797510266304\n",
            "bi=120, loss=0.10960527509450912\n",
            "bi=120, loss=0.08206655085086823\n",
            "bi=120, loss=0.09319137781858444\n",
            "bi=120, loss=0.08856457471847534\n",
            "bi=120, loss=0.12083376199007034\n",
            "bi=130, loss=0.09540832042694092\n",
            "bi=130, loss=0.12974902987480164\n",
            "bi=130, loss=0.11340340226888657\n",
            "bi=130, loss=0.09835498034954071\n",
            "bi=130, loss=0.060227878391742706\n",
            "bi=130, loss=0.16671067476272583\n",
            "bi=130, loss=0.12027820944786072\n",
            "bi=130, loss=0.07139486819505692\n",
            "bi=140, loss=0.0985405445098877\n",
            "bi=140, loss=0.10211304575204849\n",
            "bi=140, loss=0.07181017100811005\n",
            "bi=140, loss=0.06532543897628784\n",
            "bi=140, loss=0.07791613787412643\n",
            "bi=140, loss=0.08929090201854706\n",
            "bi=140, loss=0.08965978026390076\n",
            "bi=140, loss=0.1574411541223526\n",
            "bi=150, loss=0.10209503769874573\n",
            "bi=150, loss=0.07286610454320908\n",
            "bi=150, loss=0.07714495807886124\n",
            "bi=150, loss=0.08125276863574982\n",
            "bi=150, loss=0.07741405814886093\n",
            "bi=150, loss=0.12773601710796356\n",
            "bi=150, loss=0.08424414694309235\n",
            "bi=150, loss=0.06766527146100998\n",
            "bi=160, loss=0.0613684356212616\n",
            "bi=160, loss=0.08694801479578018\n",
            "bi=160, loss=0.06349437683820724\n",
            "bi=160, loss=0.08622375130653381\n",
            "bi=160, loss=0.09204304963350296\n",
            "bi=160, loss=0.08534480631351471\n",
            "bi=160, loss=0.07621970027685165\n",
            "bi=160, loss=0.11157255619764328\n",
            "bi=170, loss=0.07792100310325623\n",
            "bi=170, loss=0.10123106837272644\n",
            "bi=170, loss=0.0806318148970604\n",
            "bi=170, loss=0.08138200640678406\n",
            "bi=170, loss=0.04767909273505211\n",
            "bi=170, loss=0.09699578583240509\n",
            "bi=170, loss=0.07247932255268097\n",
            "bi=170, loss=0.09876612573862076\n",
            "epoch = 15, spearman = 0.10558569536534326\n",
            "epoch = 15, spearman = 0.06654689779943082\n",
            "epoch = 15, spearman = 0.25758096153948457\n",
            "epoch = 15, spearman = 0.11250411376477969\n",
            "epoch = 15, spearman = 0.12909944487358058\n",
            "epoch = 15, spearman = 0.07745966692414834\n",
            "epoch = 15, spearman = 0.14968912670766252\n",
            "epoch = 15, spearman = 0.19334020320653256\n",
            "bi=0, loss=0.06372389197349548\n",
            "bi=0, loss=0.0581006184220314\n",
            "bi=0, loss=0.04107529670000076\n",
            "bi=0, loss=0.11135609447956085\n",
            "bi=0, loss=0.09891871362924576\n",
            "bi=0, loss=0.07714230567216873\n",
            "bi=0, loss=0.06670589745044708\n",
            "bi=0, loss=0.10948764532804489\n",
            "bi=10, loss=0.1353149116039276\n",
            "bi=10, loss=0.08149797469377518\n",
            "bi=10, loss=0.06287188082933426\n",
            "bi=10, loss=0.07499668002128601\n",
            "bi=10, loss=0.04890470206737518\n",
            "bi=10, loss=0.09242387115955353\n",
            "bi=10, loss=0.10597282648086548\n",
            "bi=10, loss=0.116368368268013\n",
            "bi=20, loss=0.09565740823745728\n",
            "bi=20, loss=0.10234569013118744\n",
            "bi=20, loss=0.07163930684328079\n",
            "bi=20, loss=0.050067316740751266\n",
            "bi=20, loss=0.09358638525009155\n",
            "bi=20, loss=0.053358688950538635\n",
            "bi=20, loss=0.12487698346376419\n",
            "bi=20, loss=0.1412625014781952\n",
            "bi=30, loss=0.07496928423643112\n",
            "bi=30, loss=0.10374010354280472\n",
            "bi=30, loss=0.061345405876636505\n",
            "bi=30, loss=0.17081445455551147\n",
            "bi=30, loss=0.05649698153138161\n",
            "bi=30, loss=0.060673244297504425\n",
            "bi=30, loss=0.0842331051826477\n",
            "bi=30, loss=0.04546990990638733\n",
            "bi=40, loss=0.08370316028594971\n",
            "bi=40, loss=0.10843883454799652\n",
            "bi=40, loss=0.07460229098796844\n",
            "bi=40, loss=0.07938021421432495\n",
            "bi=40, loss=0.09795928746461868\n",
            "bi=40, loss=0.11851447075605392\n",
            "bi=40, loss=0.14113853871822357\n",
            "bi=40, loss=0.1008886992931366\n",
            "bi=50, loss=0.13289432227611542\n",
            "bi=50, loss=0.11299839615821838\n",
            "bi=50, loss=0.09964945912361145\n",
            "bi=50, loss=0.13901901245117188\n",
            "bi=50, loss=0.10230843722820282\n",
            "bi=50, loss=0.08535105735063553\n",
            "bi=50, loss=0.0452297180891037\n",
            "bi=50, loss=0.1429096907377243\n",
            "bi=60, loss=0.10298915207386017\n",
            "bi=60, loss=0.04632952809333801\n",
            "bi=60, loss=0.056846607476472855\n",
            "bi=60, loss=0.043866902589797974\n",
            "bi=60, loss=0.07238192856311798\n",
            "bi=60, loss=0.054052308201789856\n",
            "bi=60, loss=0.10159524530172348\n",
            "bi=60, loss=0.08740091323852539\n",
            "bi=70, loss=0.09822538495063782\n",
            "bi=70, loss=0.06783608347177505\n",
            "bi=70, loss=0.10880107432603836\n",
            "bi=70, loss=0.06522222608327866\n",
            "bi=70, loss=0.07190253585577011\n",
            "bi=70, loss=0.11541081219911575\n",
            "bi=70, loss=0.04321754723787308\n",
            "bi=70, loss=0.06548435986042023\n",
            "bi=80, loss=0.06488136947154999\n",
            "bi=80, loss=0.05434713512659073\n",
            "bi=80, loss=0.08710038661956787\n",
            "bi=80, loss=0.04936649277806282\n",
            "bi=80, loss=0.07519607245922089\n",
            "bi=80, loss=0.05598068609833717\n",
            "bi=80, loss=0.07919208705425262\n",
            "bi=80, loss=0.07802985608577728\n",
            "bi=90, loss=0.05209556594491005\n",
            "bi=90, loss=0.1039053201675415\n",
            "bi=90, loss=0.07978831976652145\n",
            "bi=90, loss=0.0644913762807846\n",
            "bi=90, loss=0.04690086841583252\n",
            "bi=90, loss=0.1081797331571579\n",
            "bi=90, loss=0.060433316975831985\n",
            "bi=90, loss=0.07820618897676468\n",
            "bi=100, loss=0.08959618955850601\n",
            "bi=100, loss=0.0769100934267044\n",
            "bi=100, loss=0.047411635518074036\n",
            "bi=100, loss=0.06994844973087311\n",
            "bi=100, loss=0.05326853692531586\n",
            "bi=100, loss=0.0643066018819809\n",
            "bi=100, loss=0.0574396550655365\n",
            "bi=100, loss=0.07614385336637497\n",
            "bi=110, loss=0.07335319370031357\n",
            "bi=110, loss=0.06676206737756729\n",
            "bi=110, loss=0.10153399407863617\n",
            "bi=110, loss=0.06840484589338303\n",
            "bi=110, loss=0.0741230919957161\n",
            "bi=110, loss=0.08443430811166763\n",
            "bi=110, loss=0.05338340625166893\n",
            "bi=110, loss=0.05317109823226929\n",
            "bi=120, loss=0.056189265102148056\n",
            "bi=120, loss=0.09888438880443573\n",
            "bi=120, loss=0.07140037417411804\n",
            "bi=120, loss=0.08050233125686646\n",
            "bi=120, loss=0.057196587324142456\n",
            "bi=120, loss=0.06982558220624924\n",
            "bi=120, loss=0.08187577873468399\n",
            "bi=120, loss=0.043643850833177567\n",
            "bi=130, loss=0.05248609557747841\n",
            "bi=130, loss=0.08973770588636398\n",
            "bi=130, loss=0.08432725071907043\n",
            "bi=130, loss=0.11184147000312805\n",
            "bi=130, loss=0.06675553321838379\n",
            "bi=130, loss=0.12294778972864151\n",
            "bi=130, loss=0.06076313555240631\n",
            "bi=130, loss=0.0566149577498436\n",
            "bi=140, loss=0.06853878498077393\n",
            "bi=140, loss=0.07128287851810455\n",
            "bi=140, loss=0.05451616644859314\n",
            "bi=140, loss=0.06974083185195923\n",
            "bi=140, loss=0.0993705466389656\n",
            "bi=140, loss=0.07832472026348114\n",
            "bi=140, loss=0.16505783796310425\n",
            "bi=140, loss=0.06402764469385147\n",
            "bi=150, loss=0.050455473363399506\n",
            "bi=150, loss=0.053620606660842896\n",
            "bi=150, loss=0.07767432183027267\n",
            "bi=150, loss=0.06045198068022728\n",
            "bi=150, loss=0.08415207266807556\n",
            "bi=150, loss=0.06950873136520386\n",
            "bi=150, loss=0.05255040526390076\n",
            "bi=150, loss=0.0659027099609375\n",
            "bi=160, loss=0.06308726966381073\n",
            "bi=160, loss=0.0996631309390068\n",
            "bi=160, loss=0.07151336967945099\n",
            "bi=160, loss=0.074757419526577\n",
            "bi=160, loss=0.06264536827802658\n",
            "bi=160, loss=0.049969397485256195\n",
            "bi=160, loss=0.07384831458330154\n",
            "bi=160, loss=0.05657074972987175\n",
            "bi=170, loss=0.03605640307068825\n",
            "bi=170, loss=0.06823330372571945\n",
            "bi=170, loss=0.07819214463233948\n",
            "bi=170, loss=0.06384500116109848\n",
            "bi=170, loss=0.05160714313387871\n",
            "bi=170, loss=0.07039397954940796\n",
            "bi=170, loss=0.07652433216571808\n",
            "bi=170, loss=0.07366509735584259\n",
            "epoch = 16, spearman = 0.15030705491533905\n",
            "epoch = 16, spearman = 0.12909944487358058\n",
            "epoch = 16, spearman = 0.07745966692414834\n",
            "epoch = 16, spearman = 0.051639777949432225\n",
            "epoch = 16, spearman = 0.19564634267301137\n",
            "epoch = 16, spearman = 0.1297173730812571\n",
            "epoch = 16, spearman = 0.20132890465709471\n",
            "epoch = 16, spearman = 0.17612694389005518\n",
            "bi=0, loss=0.06486652791500092\n",
            "bi=0, loss=0.04576354846358299\n",
            "bi=0, loss=0.07723703980445862\n",
            "bi=0, loss=0.03311514854431152\n",
            "bi=0, loss=0.05730240419507027\n",
            "bi=0, loss=0.08884824067354202\n",
            "bi=0, loss=0.06271031498908997\n",
            "bi=0, loss=0.08918597549200058\n",
            "bi=10, loss=0.1077808141708374\n",
            "bi=10, loss=0.05928120017051697\n",
            "bi=10, loss=0.04795711115002632\n",
            "bi=10, loss=0.08247435092926025\n",
            "bi=10, loss=0.033403828740119934\n",
            "bi=10, loss=0.07524654269218445\n",
            "bi=10, loss=0.11166933923959732\n",
            "bi=10, loss=0.05514044687151909\n",
            "bi=20, loss=0.059421855956315994\n",
            "bi=20, loss=0.11952580511569977\n",
            "bi=20, loss=0.05754981189966202\n",
            "bi=20, loss=0.08140294253826141\n",
            "bi=20, loss=0.041909586638212204\n",
            "bi=20, loss=0.08474381268024445\n",
            "bi=20, loss=0.034689947962760925\n",
            "bi=20, loss=0.10898444056510925\n",
            "bi=30, loss=0.13096170127391815\n",
            "bi=30, loss=0.0595734640955925\n",
            "bi=30, loss=0.0539679192006588\n",
            "bi=30, loss=0.06468437612056732\n",
            "bi=30, loss=0.09280228614807129\n",
            "bi=30, loss=0.04764145612716675\n",
            "bi=30, loss=0.05428755655884743\n",
            "bi=30, loss=0.03630855306982994\n",
            "bi=40, loss=0.10716325789690018\n",
            "bi=40, loss=0.08922966569662094\n",
            "bi=40, loss=0.0794731006026268\n",
            "bi=40, loss=0.04582589492201805\n",
            "bi=40, loss=0.0641908273100853\n",
            "bi=40, loss=0.08739548921585083\n",
            "bi=40, loss=0.05799616128206253\n",
            "bi=40, loss=0.07223173975944519\n",
            "bi=50, loss=0.08440311253070831\n",
            "bi=50, loss=0.05194826051592827\n",
            "bi=50, loss=0.10511694848537445\n",
            "bi=50, loss=0.07217006385326385\n",
            "bi=50, loss=0.11703987419605255\n",
            "bi=50, loss=0.09587045013904572\n",
            "bi=50, loss=0.03823068365454674\n",
            "bi=50, loss=0.11527898162603378\n",
            "bi=60, loss=0.03482785075902939\n",
            "bi=60, loss=0.07453557848930359\n",
            "bi=60, loss=0.03821099177002907\n",
            "bi=60, loss=0.08382966369390488\n",
            "bi=60, loss=0.05058324709534645\n",
            "bi=60, loss=0.03446849063038826\n",
            "bi=60, loss=0.05039109289646149\n",
            "bi=60, loss=0.06968779861927032\n",
            "bi=70, loss=0.09930550307035446\n",
            "bi=70, loss=0.04820168390870094\n",
            "bi=70, loss=0.05464860796928406\n",
            "bi=70, loss=0.03611215204000473\n",
            "bi=70, loss=0.08240939676761627\n",
            "bi=70, loss=0.054640550166368484\n",
            "bi=70, loss=0.08652123808860779\n",
            "bi=70, loss=0.06261752545833588\n",
            "bi=80, loss=0.045034512877464294\n",
            "bi=80, loss=0.048466842621564865\n",
            "bi=80, loss=0.058128472417593\n",
            "bi=80, loss=0.08471985161304474\n",
            "bi=80, loss=0.03506961092352867\n",
            "bi=80, loss=0.045319125056266785\n",
            "bi=80, loss=0.057591576129198074\n",
            "bi=80, loss=0.04171944409608841\n",
            "bi=90, loss=0.07361841946840286\n",
            "bi=90, loss=0.05798625573515892\n",
            "bi=90, loss=0.05486626550555229\n",
            "bi=90, loss=0.03767719119787216\n",
            "bi=90, loss=0.057077713310718536\n",
            "bi=90, loss=0.0523214153945446\n",
            "bi=90, loss=0.09040084481239319\n",
            "bi=90, loss=0.042606789618730545\n",
            "bi=100, loss=0.040822938084602356\n",
            "bi=100, loss=0.04937633126974106\n",
            "bi=100, loss=0.055383168160915375\n",
            "bi=100, loss=0.0629693865776062\n",
            "bi=100, loss=0.03462587669491768\n",
            "bi=100, loss=0.04178871586918831\n",
            "bi=100, loss=0.0650831013917923\n",
            "bi=100, loss=0.05106910690665245\n",
            "bi=110, loss=0.041659895330667496\n",
            "bi=110, loss=0.06577542424201965\n",
            "bi=110, loss=0.033648233860731125\n",
            "bi=110, loss=0.07531320303678513\n",
            "bi=110, loss=0.06451454013586044\n",
            "bi=110, loss=0.057399943470954895\n",
            "bi=110, loss=0.04739678278565407\n",
            "bi=110, loss=0.08590901643037796\n",
            "bi=120, loss=0.04838743433356285\n",
            "bi=120, loss=0.0385226346552372\n",
            "bi=120, loss=0.044573020190000534\n",
            "bi=120, loss=0.07525114715099335\n",
            "bi=120, loss=0.05471982806921005\n",
            "bi=120, loss=0.07577447593212128\n",
            "bi=120, loss=0.05102933570742607\n",
            "bi=120, loss=0.08629822731018066\n",
            "bi=130, loss=0.07908398658037186\n",
            "bi=130, loss=0.10475167632102966\n",
            "bi=130, loss=0.09516587108373642\n",
            "bi=130, loss=0.040780793875455856\n",
            "bi=130, loss=0.07513190805912018\n",
            "bi=130, loss=0.04813900589942932\n",
            "bi=130, loss=0.03836316242814064\n",
            "bi=130, loss=0.04959329217672348\n",
            "bi=140, loss=0.052823323756456375\n",
            "bi=140, loss=0.044156815856695175\n",
            "bi=140, loss=0.12453069537878036\n",
            "bi=140, loss=0.08833469450473785\n",
            "bi=140, loss=0.06406950950622559\n",
            "bi=140, loss=0.0684388279914856\n",
            "bi=140, loss=0.06277167797088623\n",
            "bi=140, loss=0.05761772021651268\n",
            "bi=150, loss=0.04948347806930542\n",
            "bi=150, loss=0.048546768724918365\n",
            "bi=150, loss=0.04768220707774162\n",
            "bi=150, loss=0.06346376240253448\n",
            "bi=150, loss=0.05672988295555115\n",
            "bi=150, loss=0.035014938563108444\n",
            "bi=150, loss=0.058751724660396576\n",
            "bi=150, loss=0.07196052372455597\n",
            "bi=160, loss=0.07339315116405487\n",
            "bi=160, loss=0.04512295126914978\n",
            "bi=160, loss=0.060611482709646225\n",
            "bi=160, loss=0.0538754016160965\n",
            "bi=160, loss=0.05841323733329773\n",
            "bi=160, loss=0.051153190433979034\n",
            "bi=160, loss=0.04154724255204201\n",
            "bi=160, loss=0.05855787545442581\n",
            "bi=170, loss=0.0595262385904789\n",
            "bi=170, loss=0.06385110318660736\n",
            "bi=170, loss=0.028189899399876595\n",
            "bi=170, loss=0.0645093098282814\n",
            "bi=170, loss=0.06076863035559654\n",
            "bi=170, loss=0.04719666391611099\n",
            "bi=170, loss=0.05343108996748924\n",
            "bi=170, loss=0.054664935916662216\n",
            "epoch = 17, spearman = 0.13539993506534045\n",
            "epoch = 17, spearman = 0.12909944487358058\n",
            "epoch = 17, spearman = 0.09467292624062575\n",
            "epoch = 17, spearman = 0.1297173730812571\n",
            "epoch = 17, spearman = 0.06654689779943082\n",
            "epoch = 17, spearman = 0.20824732305653118\n",
            "epoch = 17, spearman = 0.23344928382357072\n",
            "epoch = 17, spearman = 0.15891368457357777\n",
            "bi=0, loss=0.047800756990909576\n",
            "bi=0, loss=0.03665986284613609\n",
            "bi=0, loss=0.02939663454890251\n",
            "bi=0, loss=0.06853057444095612\n",
            "bi=0, loss=0.05916541442275047\n",
            "bi=0, loss=0.04603622108697891\n",
            "bi=0, loss=0.05133148282766342\n",
            "bi=0, loss=0.0705462396144867\n",
            "bi=10, loss=0.0968761220574379\n",
            "bi=10, loss=0.04934784024953842\n",
            "bi=10, loss=0.05188532918691635\n",
            "bi=10, loss=0.08397544920444489\n",
            "bi=10, loss=0.0378306582570076\n",
            "bi=10, loss=0.04679924249649048\n",
            "bi=10, loss=0.06379131227731705\n",
            "bi=10, loss=0.026567749679088593\n",
            "bi=20, loss=0.05088323354721069\n",
            "bi=20, loss=0.03232875093817711\n",
            "bi=20, loss=0.041103508323431015\n",
            "bi=20, loss=0.02674044854938984\n",
            "bi=20, loss=0.06178835406899452\n",
            "bi=20, loss=0.09305085241794586\n",
            "bi=20, loss=0.06447363644838333\n",
            "bi=20, loss=0.0976218655705452\n",
            "bi=30, loss=0.03902186080813408\n",
            "bi=30, loss=0.041377805173397064\n",
            "bi=30, loss=0.05285004526376724\n",
            "bi=30, loss=0.07199717313051224\n",
            "bi=30, loss=0.028838254511356354\n",
            "bi=30, loss=0.028498688712716103\n",
            "bi=30, loss=0.048128966242074966\n",
            "bi=30, loss=0.12049010396003723\n",
            "bi=40, loss=0.08809667080640793\n",
            "bi=40, loss=0.04033578187227249\n",
            "bi=40, loss=0.07335668057203293\n",
            "bi=40, loss=0.05949210003018379\n",
            "bi=40, loss=0.07177525758743286\n",
            "bi=40, loss=0.07529841363430023\n",
            "bi=40, loss=0.046559374779462814\n",
            "bi=40, loss=0.04506907984614372\n",
            "bi=50, loss=0.056741442531347275\n",
            "bi=50, loss=0.08908538520336151\n",
            "bi=50, loss=0.10495060682296753\n",
            "bi=50, loss=0.09322309494018555\n",
            "bi=50, loss=0.05963018164038658\n",
            "bi=50, loss=0.09161338955163956\n",
            "bi=50, loss=0.04053784906864166\n",
            "bi=50, loss=0.03001103363931179\n",
            "bi=60, loss=0.062400925904512405\n",
            "bi=60, loss=0.02948176860809326\n",
            "bi=60, loss=0.05805068463087082\n",
            "bi=60, loss=0.043002497404813766\n",
            "bi=60, loss=0.07426649332046509\n",
            "bi=60, loss=0.036097683012485504\n",
            "bi=60, loss=0.041232503950595856\n",
            "bi=60, loss=0.03192573040723801\n",
            "bi=70, loss=0.04605533182621002\n",
            "bi=70, loss=0.05509618669748306\n",
            "bi=70, loss=0.046851422637701035\n",
            "bi=70, loss=0.06813420355319977\n",
            "bi=70, loss=0.07327228784561157\n",
            "bi=70, loss=0.04299718886613846\n",
            "bi=70, loss=0.08943841606378555\n",
            "bi=70, loss=0.030553165823221207\n",
            "bi=80, loss=0.050486836582422256\n",
            "bi=80, loss=0.041561342775821686\n",
            "bi=80, loss=0.036520134657621384\n",
            "bi=80, loss=0.05827772989869118\n",
            "bi=80, loss=0.0379275344312191\n",
            "bi=80, loss=0.0369003526866436\n",
            "bi=80, loss=0.05112145096063614\n",
            "bi=80, loss=0.03603252023458481\n",
            "bi=90, loss=0.04560315981507301\n",
            "bi=90, loss=0.039940547198057175\n",
            "bi=90, loss=0.06768510490655899\n",
            "bi=90, loss=0.04764919355511665\n",
            "bi=90, loss=0.06107360124588013\n",
            "bi=90, loss=0.032306890934705734\n",
            "bi=90, loss=0.0455595925450325\n",
            "bi=90, loss=0.03224305808544159\n",
            "bi=100, loss=0.041595377027988434\n",
            "bi=100, loss=0.05904272943735123\n",
            "bi=100, loss=0.05276406928896904\n",
            "bi=100, loss=0.038213033229112625\n",
            "bi=100, loss=0.04917798191308975\n",
            "bi=100, loss=0.0494513139128685\n",
            "bi=100, loss=0.03624590486288071\n",
            "bi=100, loss=0.03414487838745117\n",
            "bi=110, loss=0.04536671191453934\n",
            "bi=110, loss=0.05746626853942871\n",
            "bi=110, loss=0.041758064180612564\n",
            "bi=110, loss=0.030871599912643433\n",
            "bi=110, loss=0.04478716850280762\n",
            "bi=110, loss=0.029904887080192566\n",
            "bi=110, loss=0.07029493898153305\n",
            "bi=110, loss=0.05806946009397507\n",
            "bi=120, loss=0.04701023921370506\n",
            "bi=120, loss=0.07620956003665924\n",
            "bi=120, loss=0.033810149878263474\n",
            "bi=120, loss=0.06543788313865662\n",
            "bi=120, loss=0.048402223736047745\n",
            "bi=120, loss=0.059442199766635895\n",
            "bi=120, loss=0.036567170172929764\n",
            "bi=120, loss=0.03458193689584732\n",
            "bi=130, loss=0.08629652857780457\n",
            "bi=130, loss=0.03623094782233238\n",
            "bi=130, loss=0.0776984915137291\n",
            "bi=130, loss=0.06696819514036179\n",
            "bi=130, loss=0.06938707828521729\n",
            "bi=130, loss=0.04371200129389763\n",
            "bi=130, loss=0.03330516070127487\n",
            "bi=130, loss=0.0431552454829216\n",
            "bi=140, loss=0.050327152013778687\n",
            "bi=140, loss=0.058507040143013\n",
            "bi=140, loss=0.04110761731863022\n",
            "bi=140, loss=0.07086494565010071\n",
            "bi=140, loss=0.036854539066553116\n",
            "bi=140, loss=0.04296542704105377\n",
            "bi=140, loss=0.10489508509635925\n",
            "bi=140, loss=0.04256288707256317\n",
            "bi=150, loss=0.030921118333935738\n",
            "bi=150, loss=0.053388241678476334\n",
            "bi=150, loss=0.05143493041396141\n",
            "bi=150, loss=0.06239137426018715\n",
            "bi=150, loss=0.05253487825393677\n",
            "bi=150, loss=0.04232456907629967\n",
            "bi=150, loss=0.037879928946495056\n",
            "bi=150, loss=0.042847175151109695\n",
            "bi=160, loss=0.05418812483549118\n",
            "bi=160, loss=0.04766819253563881\n",
            "bi=160, loss=0.03623870387673378\n",
            "bi=160, loss=0.07017693668603897\n",
            "bi=160, loss=0.045007895678281784\n",
            "bi=160, loss=0.043023206293582916\n",
            "bi=160, loss=0.04823872447013855\n",
            "bi=160, loss=0.05585244297981262\n",
            "bi=170, loss=0.052684783935546875\n",
            "bi=170, loss=0.050750963389873505\n",
            "bi=170, loss=0.05427725240588188\n",
            "bi=170, loss=0.04781368747353554\n",
            "bi=170, loss=0.05680951848626137\n",
            "bi=170, loss=0.023699162527918816\n",
            "bi=170, loss=0.03939489647746086\n",
            "bi=170, loss=0.04609886556863785\n",
            "epoch = 18, spearman = 0.12909944487358058\n",
            "epoch = 18, spearman = 0.23344928382357072\n",
            "epoch = 18, spearman = 0.15030705491533905\n",
            "epoch = 18, spearman = 0.20824732305653118\n",
            "epoch = 18, spearman = 0.06255254707414973\n",
            "epoch = 18, spearman = 0.04933363848295342\n",
            "epoch = 18, spearman = 0.1125041137647797\n",
            "epoch = 18, spearman = 0.19334020320653256\n",
            "bi=0, loss=0.041147779673337936\n",
            "bi=0, loss=0.03013290837407112\n",
            "bi=0, loss=0.06004093959927559\n",
            "bi=0, loss=0.04007561504840851\n",
            "bi=0, loss=0.021582841873168945\n",
            "bi=0, loss=0.048712361603975296\n",
            "bi=0, loss=0.04382646828889847\n",
            "bi=0, loss=0.057560164481401443\n",
            "bi=10, loss=0.08640795946121216\n",
            "bi=10, loss=0.03958471491932869\n",
            "bi=10, loss=0.036867137998342514\n",
            "bi=10, loss=0.07039393484592438\n",
            "bi=10, loss=0.03163571283221245\n",
            "bi=10, loss=0.023746155202388763\n",
            "bi=10, loss=0.05538511648774147\n",
            "bi=10, loss=0.04438009485602379\n",
            "bi=20, loss=0.023317746818065643\n",
            "bi=20, loss=0.05852833017706871\n",
            "bi=20, loss=0.05504094436764717\n",
            "bi=20, loss=0.03644321858882904\n",
            "bi=20, loss=0.08357633650302887\n",
            "bi=20, loss=0.028658851981163025\n",
            "bi=20, loss=0.08842727541923523\n",
            "bi=20, loss=0.05150602012872696\n",
            "bi=30, loss=0.024586761370301247\n",
            "bi=30, loss=0.06140780448913574\n",
            "bi=30, loss=0.048297204077243805\n",
            "bi=30, loss=0.032610729336738586\n",
            "bi=30, loss=0.04296156018972397\n",
            "bi=30, loss=0.035078030079603195\n",
            "bi=30, loss=0.09917618334293365\n",
            "bi=30, loss=0.024951046332716942\n",
            "bi=40, loss=0.035162974148988724\n",
            "bi=40, loss=0.040407564491033554\n",
            "bi=40, loss=0.038176387548446655\n",
            "bi=40, loss=0.07600904256105423\n",
            "bi=40, loss=0.064017653465271\n",
            "bi=40, loss=0.051607802510261536\n",
            "bi=40, loss=0.06600632518529892\n",
            "bi=40, loss=0.06224699690937996\n",
            "bi=50, loss=0.0858587920665741\n",
            "bi=50, loss=0.07797753065824509\n",
            "bi=50, loss=0.05745483189821243\n",
            "bi=50, loss=0.053569868206977844\n",
            "bi=50, loss=0.08742496371269226\n",
            "bi=50, loss=0.02679269015789032\n",
            "bi=50, loss=0.09217653423547745\n",
            "bi=50, loss=0.036065150052309036\n",
            "bi=60, loss=0.05008247122168541\n",
            "bi=60, loss=0.027104470878839493\n",
            "bi=60, loss=0.05151883885264397\n",
            "bi=60, loss=0.038060374557971954\n",
            "bi=60, loss=0.024650095030665398\n",
            "bi=60, loss=0.03172137960791588\n",
            "bi=60, loss=0.028040017932653427\n",
            "bi=60, loss=0.06260482966899872\n",
            "bi=70, loss=0.04518385976552963\n",
            "bi=70, loss=0.06609651446342468\n",
            "bi=70, loss=0.024607591331005096\n",
            "bi=70, loss=0.03704860061407089\n",
            "bi=70, loss=0.05693948268890381\n",
            "bi=70, loss=0.07902734726667404\n",
            "bi=70, loss=0.040521759539842606\n",
            "bi=70, loss=0.03609246760606766\n",
            "bi=80, loss=0.041437938809394836\n",
            "bi=80, loss=0.03179376944899559\n",
            "bi=80, loss=0.037495505064725876\n",
            "bi=80, loss=0.052644092589616776\n",
            "bi=80, loss=0.030717188492417336\n",
            "bi=80, loss=0.04394450783729553\n",
            "bi=80, loss=0.03012744151055813\n",
            "bi=80, loss=0.032376669347286224\n",
            "bi=90, loss=0.04354065656661987\n",
            "bi=90, loss=0.03559862822294235\n",
            "bi=90, loss=0.03030654415488243\n",
            "bi=90, loss=0.04334559664130211\n",
            "bi=90, loss=0.02819807268679142\n",
            "bi=90, loss=0.0435790941119194\n",
            "bi=90, loss=0.06069106608629227\n",
            "bi=90, loss=0.05454706400632858\n",
            "bi=100, loss=0.04768822342157364\n",
            "bi=100, loss=0.044078581035137177\n",
            "bi=100, loss=0.0428553931415081\n",
            "bi=100, loss=0.04703322425484657\n",
            "bi=100, loss=0.027519259601831436\n",
            "bi=100, loss=0.0372258797287941\n",
            "bi=100, loss=0.029638320207595825\n",
            "bi=100, loss=0.03298325836658478\n",
            "bi=110, loss=0.052979469299316406\n",
            "bi=110, loss=0.042856018990278244\n",
            "bi=110, loss=0.04113033041357994\n",
            "bi=110, loss=0.03876081854104996\n",
            "bi=110, loss=0.0644616112112999\n",
            "bi=110, loss=0.05618588998913765\n",
            "bi=110, loss=0.028851697221398354\n",
            "bi=110, loss=0.027897203341126442\n",
            "bi=120, loss=0.04647189751267433\n",
            "bi=120, loss=0.029972586780786514\n",
            "bi=120, loss=0.06516945362091064\n",
            "bi=120, loss=0.0525415800511837\n",
            "bi=120, loss=0.029373211786150932\n",
            "bi=120, loss=0.04115913435816765\n",
            "bi=120, loss=0.030040957033634186\n",
            "bi=120, loss=0.05787027254700661\n",
            "bi=130, loss=0.06625522673130035\n",
            "bi=130, loss=0.08017324656248093\n",
            "bi=130, loss=0.06723502278327942\n",
            "bi=130, loss=0.06413954496383667\n",
            "bi=130, loss=0.041162021458148956\n",
            "bi=130, loss=0.03052305057644844\n",
            "bi=130, loss=0.033004239201545715\n",
            "bi=130, loss=0.04058632254600525\n",
            "bi=140, loss=0.03474830836057663\n",
            "bi=140, loss=0.05530041828751564\n",
            "bi=140, loss=0.0475650317966938\n",
            "bi=140, loss=0.0374104268848896\n",
            "bi=140, loss=0.03856876492500305\n",
            "bi=140, loss=0.041695062071084976\n",
            "bi=140, loss=0.06349915266036987\n",
            "bi=140, loss=0.0953204557299614\n",
            "bi=150, loss=0.041310131549835205\n",
            "bi=150, loss=0.03870094195008278\n",
            "bi=150, loss=0.03689131885766983\n",
            "bi=150, loss=0.02696269564330578\n",
            "bi=150, loss=0.0488569438457489\n",
            "bi=150, loss=0.03215337544679642\n",
            "bi=150, loss=0.04647506773471832\n",
            "bi=150, loss=0.05598246678709984\n",
            "bi=160, loss=0.039179835468530655\n",
            "bi=160, loss=0.03510284051299095\n",
            "bi=160, loss=0.041524890810251236\n",
            "bi=160, loss=0.06238148361444473\n",
            "bi=160, loss=0.04527045413851738\n",
            "bi=160, loss=0.04129580035805702\n",
            "bi=160, loss=0.04216346889734268\n",
            "bi=160, loss=0.04186831787228584\n",
            "bi=170, loss=0.04924862086772919\n",
            "bi=170, loss=0.022040145471692085\n",
            "bi=170, loss=0.045771658420562744\n",
            "bi=170, loss=0.052347421646118164\n",
            "bi=170, loss=0.04245063289999962\n",
            "bi=170, loss=0.03508804738521576\n",
            "bi=170, loss=0.050737954676151276\n",
            "bi=170, loss=0.049120429903268814\n",
            "epoch = 19, spearman = 0.19334020320653256\n",
            "epoch = 19, spearman = 0.12909944487358058\n",
            "epoch = 19, spearman = 0.06654689779943082\n",
            "epoch = 19, spearman = 0.13539993506534045\n",
            "epoch = 19, spearman = 0.23344928382357072\n",
            "epoch = 19, spearman = 0.045339287757672334\n",
            "epoch = 19, spearman = 0.1446244929312557\n",
            "epoch = 19, spearman = 0.19334020320653256\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}