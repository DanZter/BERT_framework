{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of BERT_on_steroids X multicore_tpu_training (time)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanZter/BERT_framework/blob/master/Copy_of_BERT_on_steroids_X_multicore_tpu_training_(time).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqZ3T1puyVjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TEtC_xlyjsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "05232bfe-2000-498d-fb73-dff9efdfcb80"
      },
      "source": [
        "pip install torch===1.5.1 torchvision===0.6.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch===1.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/01/457b49d790b6c4b9720e6f9dbbb617692f6ce8afdaadf425c055c41a7416/torch-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (753.2MB)\n",
            "\u001b[K     |████████████████████████████████| 753.2MB 21kB/s \n",
            "\u001b[?25hCollecting torchvision===0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/f1/535a407b4a265adf2dd7c2c2458217e37c5fe83ec97234e66c564592a9a0/torchvision-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 26.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch===1.5.1) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch===1.5.1) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision===0.6.1) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Successfully installed torch-1.5.1 torchvision-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iqGn5_vyju1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a33a7a12-6a9b-4077-8cda-cbc4a04b3ea5"
      },
      "source": [
        "VERSION = \"1.5\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4994  100  4994    0     0  71342      0 --:--:-- --:--:-- --:--:-- 71342\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-1.5 ...\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Uninstalling torch-1.5.1:\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.12.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.17.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (4.6)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
            "  Successfully uninstalled torch-1.5.1\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.10.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (47.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.52.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "\u001b[31mERROR: Error checking for conflicts.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3012, in _parsed_pkg_info\n",
            "    return self._pkg_info\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _pkg_info\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py\", line 568, in _warn_about_conflicts\n",
            "    package_set, _dep_info = check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/operations/check.py\", line 114, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/operations/check.py\", line 53, in create_package_set_from_installed\n",
            "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3032, in _compute_dependencies\n",
            "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3014, in _parsed_pkg_info\n",
            "    metadata = self.get_metadata(self.PKG_INFO)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 1420, in get_metadata\n",
            "    value = self._get(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 1616, in _get\n",
            "    with open(path, 'rb') as stream:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/usr/local/lib/python3.6/dist-packages/torch-1.5.1.dist-info/METADATA'\u001b[0m\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Found existing installation: google-api-python-client 1.7.12\n",
            "    Uninstalling google-api-python-client-1.7.12:\n",
            "      Successfully uninstalled google-api-python-client-1.7.12\n",
            "Uninstalling torchvision-0.6.1:\n",
            "  Successfully uninstalled torchvision-0.6.1\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "Copying gs://tpu-pytorch/wheels/torch-1.5-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 79.0 MiB/ 79.0 MiB]                                                \n",
            "Operation completed over 1 objects/79.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-1.5-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][106.6 MiB/106.6 MiB]                                                \n",
            "Operation completed over 1 objects/106.6 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-1.5-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.5 MiB/  2.5 MiB]                                                \n",
            "Operation completed over 1 objects/2.5 MiB.                                      \n",
            "Processing ./torch-1.5-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (0.16.0)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.5.0a0+ab660ae\n",
            "Processing ./torch_xla-1.5-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.5\n",
            "Processing ./torchvision-1.5-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (7.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (1.5.0a0+ab660ae)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==1.5) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==1.5) (0.16.0)\n",
            "Done updating TPU runtime\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.6.0a0+3c254fb\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (331 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BxVOCV-yjxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports pytorch\n",
        "import torch\n",
        "\n",
        "# imports the torch_xla package\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.distributed.parallel_loader as pl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxSVJbaPyj29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "766fc257-f078-4303-dc76-224dcba08f84"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0\n",
            "Running on TPU  ['10.125.38.186:8470']\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6uuwYBAyj8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "f93bd052-e8aa-4c51-cdfe-57a223408090"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 2.9MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 3.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 9.8MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 32.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 41.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=ed86addfb0374aeb7c05802795aa3f27c20e2f31bbdbe08be5ad9fec8659201d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNF8lAXqykBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch.nn as nn\n",
        "from sklearn import model_selection\n",
        "from scipy import stats\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# import logging\n",
        "# logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBv-kEJNykFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8eea2e41-a9b3-4c46-ccf8-1c09cc2c2ada"
      },
      "source": [
        "class BERTBaseUncased(nn.Module):\n",
        "    def __init__(self, bert_path):\n",
        "        super(BERTBaseUncased, self).__init__()\n",
        "        self.bert_path = bert_path\n",
        "        self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n",
        "        self.bert_drop = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(768, 30)       # pool output has 768 features, 30 targets\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, o2 = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)  # not using o1 - Sequential Output\n",
        "        bo = self.bert_drop(o2)                                                     # using o2 - Pooled Output\n",
        "        return self.out(bo)\n",
        "\n",
        "class BERTDatasetTraining:\n",
        "    def __init__(self, qtitle, qbody, answer, targets, tokenizer, max_len):\n",
        "        self.qtitle = qtitle\n",
        "        self.qbody = qbody\n",
        "        self.answer = answer\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.targets = targets                   # numpy array of size: no. of samples * 30(targets)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.answer)                  # returns length of title or body or answer\n",
        "\n",
        "    def __getitem__(self, item):                 # takes in index and returns output\n",
        "        question_title = str(self.qtitle[item])\n",
        "        question_body = str(self.qbody[item])\n",
        "        answer = str(self.answer[item])\n",
        "\n",
        "        # [CLS] [Q-TITLE] [Q-BODY] [SEP] [ANSWER] [SEP]\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            question_title + \" \" + question_body,\n",
        "            answer,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True \n",
        "        )\n",
        "\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "\n",
        "        padding_len = self.max_len - len(ids)\n",
        "        ids = ids + ([0] * padding_len)\n",
        "        token_type_ids = token_type_ids + ([0] * padding_len)\n",
        "        mask = mask + ([0] * padding_len)\n",
        "\n",
        "        return {\n",
        "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
        "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
        "            \"targets\": torch.tensor(self.targets[item, :], dtype=torch.float)\n",
        "        }\n",
        "\n",
        "def loss_fn(outputs, targets):\n",
        "    return nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "def train_loop_fn(data_loader, model, optimizer, device, scheduler=None):\n",
        "    model.train()\n",
        "    for bi, d in tqdm(enumerate(data_loader), total=5):\n",
        "        ids = d[\"ids\"]\n",
        "        mask = d[\"mask\"]\n",
        "        token_type_ids = d[\"token_type_ids\"]\n",
        "        targets = d[\"targets\"]\n",
        "\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        # optimizer.step()                                         # cuda\n",
        "        xm.optimizer_step(optimizer)                              # tpu\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        # if bi % 10 == 0:\n",
        "        #     xm.master_print(f\"batch_index={bi}, loss={loss}\")\n",
        "\n",
        "def eval_loop_fn(data_loader, model, device):\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    for bi, d in enumerate(data_loader):\n",
        "        ids = d[\"ids\"]\n",
        "        mask = d[\"mask\"]\n",
        "        token_type_ids = d[\"token_type_ids\"]\n",
        "        targets = d[\"targets\"]\n",
        "\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "        outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        fin_targets.append(targets.cpu().detach().numpy())\n",
        "        fin_outputs.append(outputs.cpu().detach().numpy())        # Linear Layer: can apply sigmoid here\n",
        "\n",
        "        return np.vstack(fin_outputs), np.vstack(fin_targets)\n",
        "\n",
        "def run(index, flags):\n",
        "\n",
        "    # MAX_LEN = 512\n",
        "    # TRAIN_BATCH_SIZE = 4\n",
        "    # EPOCHS = 20\n",
        "\n",
        "    flags['TRAIN_BATCH_SIZE'] = 16\n",
        "    flags['TEST_BATCH_SIZE'] = 16\n",
        "    flags['MAX_LEN'] = 512\n",
        "    flags['EPOCHS'] = 20\n",
        "    flags['seed'] = 1234  \n",
        "    torch.manual_seed(flags['seed'])\n",
        "\n",
        "    dfx = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/input/google_quest_train.csv\").fillna(\"none\")\n",
        "    df_train, df_valid = model_selection.train_test_split(dfx, random_state = 42, test_size = 0.1)\n",
        "    df_train = df_train.reset_index(drop=True)\n",
        "    df_valid = df_valid.reset_index(drop=True)\n",
        "\n",
        "    sample = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/input/google_quest_sample_submission.csv\")\n",
        "    target_cols = list(sample.drop(\"qa_id\", axis=1).columns)\n",
        "    train_targets = df_train[target_cols].values\n",
        "    valid_targets = df_valid[target_cols].values\n",
        "\n",
        "    tokenizer =transformers.BertTokenizer.from_pretrained(\"/content/drive/My Drive/Colab Notebooks/input/bert_base_uncased\")\n",
        "\n",
        "    train_dataset = BERTDatasetTraining(\n",
        "        qtitle=df_train.question_title.values,\n",
        "        qbody=df_train.question_body.values,\n",
        "        answer=df_train.answer.values,\n",
        "        targets=train_targets,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=flags['MAX_LEN']\n",
        "    )\n",
        "    train_sampler = torch.utils.data.DistributedSampler(\n",
        "       train_dataset,\n",
        "       num_replicas=xm.xrt_world_size(),\n",
        "       rank=xm.get_ordinal(),\n",
        "       shuffle=True \n",
        "    )\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size= flags['TRAIN_BATCH_SIZE'],\n",
        "        sampler=train_sampler\n",
        "    )\n",
        "    ############\n",
        "    valid_dataset = BERTDatasetTraining(\n",
        "        qtitle=df_valid.question_title.values,\n",
        "        qbody=df_valid.question_body.values,\n",
        "        answer=df_valid.answer.values,\n",
        "        targets=valid_targets,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=flags['MAX_LEN']\n",
        "    )\n",
        "    valid_sampler = torch.utils.data.DistributedSampler(\n",
        "       valid_dataset,\n",
        "       num_replicas=xm.xrt_world_size(),\n",
        "       rank=xm.get_ordinal()\n",
        "    )\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=flags['TEST_BATCH_SIZE'],\n",
        "        sampler=valid_sampler\n",
        "    )\n",
        "\n",
        "    # device = \"cuda\"                   # cuda\n",
        "    device = xm.xla_device()            # tpu\n",
        "    lr = 3e-5 *xm.xrt_world_size()\n",
        "    num_train_steps = int(len(train_dataset)/ flags['TRAIN_BATCH_SIZE'] / xm.xrt_world_size() * flags['EPOCHS'])\n",
        "    model = BERTBaseUncased(\"/content/drive/My Drive/Colab Notebooks/input/bert_base_uncased\").to(device)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_train_steps\n",
        "    )\n",
        "    for epoch in range(flags['EPOCHS']):\n",
        "      para_loader = pl.ParallelLoader(train_data_loader, [device])\n",
        "      train_loop_fn(para_loader.per_device_loader(device), model, optimizer, device, scheduler)\n",
        "\n",
        "      para_loader = pl.ParallelLoader(valid_data_loader, [device])\n",
        "      o, t = eval_loop_fn(para_loader.per_device_loader(device), model, device)\n",
        "\n",
        "      spear = []\n",
        "      for jj in range(t.shape[1]):\n",
        "          p1 = list(t[:,jj])\n",
        "          p2 = list(o[:, jj])\n",
        "          coef, _ = np.nan_to_num(stats.spearmanr(p1,p2))\n",
        "          spear.append(coef)\n",
        "      spear = np.mean(spear)\n",
        "      xm.master_print(f\"epoch = {epoch}, spearman = {spear}\")\n",
        "      # torch.save(model.state_dict(), \"model.bin\")         # cuda\n",
        "      # xm.save(model.state_dict(), \"/content/drive/My Drive/Colab Notebooks/models/bert_on_steroids_multi_tpu_model.bin\")          # tpu\n",
        "\n",
        "# if __name__==\"__main__\":\n",
        "#   xmp.spawn(run, nprocs=1)\n",
        "\n",
        "# # Spawns eight of the map functions, one for each of the eight cores on\n",
        "# # the Cloud TPU\n",
        "flags = {}\n",
        "xmp.spawn(run, args=(flags,), nprocs=8, start_method='fork')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.7311074733734131\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=10, loss=0.4630187451839447\n",
            "batch_index=20, loss=0.4470966160297394\n",
            "batch_index=30, loss=0.415610671043396\n",
            "batch_index=40, loss=0.41608381271362305\n",
            "epoch = 0, spearman = 0.14000572152720162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 1/20 [00:58<18:27, 58.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.42432701587677\n",
            "batch_index=10, loss=0.4191043972969055\n",
            "batch_index=20, loss=0.4123692214488983\n",
            "batch_index=30, loss=0.38350507616996765\n",
            "batch_index=40, loss=0.40034469962120056\n",
            "epoch = 1, spearman = 0.2594959403731799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 2/20 [01:52<17:05, 56.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.40632331371307373\n",
            "batch_index=10, loss=0.4075978696346283\n",
            "batch_index=20, loss=0.3949287533760071\n",
            "batch_index=30, loss=0.3648183047771454\n",
            "batch_index=40, loss=0.38531264662742615\n",
            "epoch = 2, spearman = 0.24248214276707822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 3/20 [02:46<15:56, 56.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.38568663597106934\n",
            "batch_index=10, loss=0.3908398449420929\n",
            "batch_index=20, loss=0.3787156641483307\n",
            "batch_index=30, loss=0.3650217354297638\n",
            "batch_index=40, loss=0.36035048961639404\n",
            "epoch = 3, spearman = 0.289909617395271\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 4/20 [03:41<14:51, 55.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.3694344460964203\n",
            "batch_index=10, loss=0.3909229338169098\n",
            "batch_index=20, loss=0.3708615303039551\n",
            "batch_index=30, loss=0.35661154985427856\n",
            "batch_index=40, loss=0.3579031229019165\n",
            "epoch = 4, spearman = 0.28613781048861675\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 5/20 [04:41<14:15, 57.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.3559066355228424\n",
            "batch_index=10, loss=0.3771797716617584\n",
            "batch_index=20, loss=0.35319778323173523\n",
            "batch_index=30, loss=0.3450600504875183\n",
            "batch_index=40, loss=0.3482525944709778\n",
            "epoch = 5, spearman = 0.3090578637537174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|███       | 6/20 [05:38<13:20, 57.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.344120055437088\n",
            "batch_index=10, loss=0.3551595211029053\n",
            "batch_index=20, loss=0.3469870388507843\n",
            "batch_index=30, loss=0.3452039062976837\n",
            "batch_index=40, loss=0.34067660570144653\n",
            "epoch = 6, spearman = 0.2904733653753333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 7/20 [06:33<12:14, 56.53s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.3482655882835388\n",
            "batch_index=10, loss=0.3522326350212097\n",
            "batch_index=20, loss=0.3446875214576721\n",
            "batch_index=30, loss=0.34312742948532104\n",
            "batch_index=40, loss=0.31950056552886963\n",
            "epoch = 7, spearman = 0.3137842502167164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 8/20 [07:28<11:11, 55.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.3408571779727936\n",
            "batch_index=10, loss=0.33973249793052673\n",
            "batch_index=20, loss=0.34010499715805054\n",
            "batch_index=30, loss=0.3267429769039154\n",
            "batch_index=40, loss=0.31681281328201294\n",
            "epoch = 8, spearman = 0.30065214727316264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 9/20 [08:22<10:10, 55.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.3219510614871979\n",
            "batch_index=10, loss=0.33733081817626953\n",
            "batch_index=20, loss=0.31947770714759827\n",
            "batch_index=30, loss=0.3193790018558502\n",
            "batch_index=40, loss=0.3039214313030243\n",
            "epoch = 9, spearman = 0.34874415292852895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 10/20 [09:17<09:11, 55.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.3165797293186188\n",
            "batch_index=10, loss=0.3244767189025879\n",
            "batch_index=20, loss=0.3099150061607361\n",
            "batch_index=30, loss=0.30107080936431885\n",
            "batch_index=40, loss=0.2991732656955719\n",
            "epoch = 10, spearman = 0.3583283926544198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 11/20 [10:12<08:15, 55.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.30950576066970825\n",
            "batch_index=10, loss=0.31448468565940857\n",
            "batch_index=20, loss=0.2996372580528259\n",
            "batch_index=30, loss=0.2993661165237427\n",
            "batch_index=40, loss=0.2925785481929779\n",
            "epoch = 11, spearman = 0.37326608138523937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 12/20 [11:06<07:19, 54.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.30573078989982605\n",
            "batch_index=10, loss=0.3110891580581665\n",
            "batch_index=20, loss=0.2929588556289673\n",
            "batch_index=30, loss=0.2947358191013336\n",
            "batch_index=40, loss=0.28685155510902405\n",
            "epoch = 12, spearman = 0.3678618293229965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 13/20 [12:01<06:23, 54.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.30828219652175903\n",
            "batch_index=10, loss=0.30840495228767395\n",
            "batch_index=20, loss=0.294878751039505\n",
            "batch_index=30, loss=0.2910240888595581\n",
            "batch_index=40, loss=0.2850459814071655\n",
            "epoch = 13, spearman = 0.36742313471644095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 14/20 [12:55<05:27, 54.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.3021218180656433\n",
            "batch_index=10, loss=0.30209094285964966\n",
            "batch_index=20, loss=0.28075510263442993\n",
            "batch_index=30, loss=0.28610584139823914\n",
            "batch_index=40, loss=0.2792847454547882\n",
            "epoch = 14, spearman = 0.3606983545592414\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 15/20 [13:50<04:33, 54.65s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.29911690950393677\n",
            "batch_index=10, loss=0.30224648118019104\n",
            "batch_index=20, loss=0.2795100808143616\n",
            "batch_index=30, loss=0.28176507353782654\n",
            "batch_index=40, loss=0.27346348762512207\n",
            "epoch = 15, spearman = 0.3378429536234299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 16/20 [14:44<03:38, 54.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.29326701164245605\n",
            "batch_index=10, loss=0.292610764503479\n",
            "batch_index=20, loss=0.26959869265556335\n",
            "batch_index=30, loss=0.2793651819229126\n",
            "batch_index=40, loss=0.2729871869087219\n",
            "epoch = 16, spearman = 0.3570014787268549\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 17/20 [15:38<02:43, 54.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.29063835740089417\n",
            "batch_index=10, loss=0.2904578447341919\n",
            "batch_index=20, loss=0.2659001648426056\n",
            "batch_index=30, loss=0.27242058515548706\n",
            "batch_index=40, loss=0.268084853887558\n",
            "epoch = 17, spearman = 0.3478657498176692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 18/20 [16:33<01:48, 54.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.2869316041469574\n",
            "batch_index=10, loss=0.2856258451938629\n",
            "batch_index=20, loss=0.2631031572818756\n",
            "batch_index=30, loss=0.2703392505645752\n",
            "batch_index=40, loss=0.26506662368774414\n",
            "epoch = 18, spearman = 0.3494674659206098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 19/20 [17:27<00:54, 54.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_index=0, loss=0.2840501666069031\n",
            "batch_index=10, loss=0.2838706076145172\n",
            "batch_index=20, loss=0.26182156801223755\n",
            "batch_index=30, loss=0.26925498247146606\n",
            "batch_index=40, loss=0.26447224617004395\n",
            "epoch = 19, spearman = 0.3575525847144326\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [19:16<00:00, 57.81s/it]\n",
            "100%|██████████| 20/20 [19:18<00:00, 57.90s/it]\n",
            "\n",
            "100%|██████████| 20/20 [19:17<00:00, 71.91s/it]\n",
            "\n",
            "\n",
            "100%|██████████| 20/20 [19:17<00:00, 57.86s/it]\n",
            "100%|██████████| 20/20 [19:20<00:00, 58.02s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}